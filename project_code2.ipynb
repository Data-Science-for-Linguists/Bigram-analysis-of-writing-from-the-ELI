{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project_Code 2: Clean up and analysis of ELI Data #\n",
    "## Ben Naismith ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes since 'Project_Code1' ###\n",
    "\n",
    "This new document has been created as a number of significant changes have been made to the original code. Based on discussions with other members of the ELI Data Mining Group, the following points were determined:\n",
    "\n",
    "- For the sake of efficiency, it is better not to merge the different data frames into one big one\n",
    "- A 'sanitization' step of the data was completed which duplicated some of the steps of my initial code. These duplications include removing unwanted apostrophes, changing all 'null' and 'ull' to NaN, and removing empty or unreal students (who were most likely teachers). As such, the dataset is now ready for more in-depth cleaning and analysis, i.e. the purpose of this notebook. The code for the sanitization step is in a private repository of the ELI Data Mining Groups 'convert_0_to_1.ipynb'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sharing Plan ###\n",
    "\n",
    "The full ELI data set (see project_plan.md) is private at this time. Below is a workbook with the current code for organizing and cleaning that data. In order to see how the code works, snippets of data have been displayed throughout.\n",
    "\n",
    "A sample of the 'sanitized' data is included in the 'data' folder in this same repository. It contains samples of the four CSV files referred to in this code, consisting of 1000 answers, in order to allow for testing and reproducibility by others of the code. These 1000 answers are the first 1000 from the answer_csv file and correspond to user_file_id 7505 to 10108.\n",
    "\n",
    "Ultimately, it is the intention of the dataset's authors for the entire dataset to be made public, with a CC license. Please see the LICENSE_notes.md for details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setup ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "#Import necesary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%pprint #turn off pretty printing\n",
    "\n",
    "#return every shell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#Create short-hand for directory root\n",
    "cor_dir = \"/Users/Benjamin's/Documents/ELI_Data_Mining/Data-Archive/1_sanitized/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 48384 entries, 1 to 48420\n",
      "Data columns (total 8 columns):\n",
      "question_id        48384 non-null int64\n",
      "anon_id            48353 non-null object\n",
      "user_file_id       48384 non-null int64\n",
      "text               47175 non-null object\n",
      "directory          14 non-null object\n",
      "is_doublespaced    48384 non-null int64\n",
      "is_plagiarized     48384 non-null int64\n",
      "is_deleted         48384 non-null int64\n",
      "dtypes: int64(5), object(3)\n",
      "memory usage: 3.3+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 920 entries, ez9 to aq6\n",
      "Data columns (total 20 columns):\n",
      "gender                       920 non-null object\n",
      "birth_year                   920 non-null int64\n",
      "native_language              920 non-null object\n",
      "language_used_at_home        919 non-null object\n",
      "language_used_at_home_now    860 non-null object\n",
      "non_native_language_1        864 non-null object\n",
      "yrs_of_study_lang1           869 non-null object\n",
      "study_in_classroom_lang1     869 non-null float64\n",
      "ways_of_study_lang1          869 non-null object\n",
      "non_native_language_2        311 non-null object\n",
      "yrs_of_study_lang2           314 non-null object\n",
      "study_in_classroom_lang2     869 non-null float64\n",
      "ways_of_study_lang2          869 non-null object\n",
      "non_native_language_3        55 non-null object\n",
      "yrs_of_study_lang3           59 non-null object\n",
      "study_in_classroom_lang3     869 non-null float64\n",
      "ways_of_study_lang3          869 non-null object\n",
      "createddate                  920 non-null object\n",
      "modifieddate                 916 non-null object\n",
      "course_history               919 non-null object\n",
      "dtypes: float64(3), int64(1), object(16)\n",
      "memory usage: 150.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#Add starter code created by Na-Rae Han for the ELI research group\n",
    "from elitools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student information (S_info_csv and S_info_df) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>native_language</th>\n",
       "      <th>language_used_at_home</th>\n",
       "      <th>language_used_at_home_now</th>\n",
       "      <th>non_native_language_1</th>\n",
       "      <th>yrs_of_study_lang1</th>\n",
       "      <th>study_in_classroom_lang1</th>\n",
       "      <th>ways_of_study_lang1</th>\n",
       "      <th>non_native_language_2</th>\n",
       "      <th>yrs_of_study_lang2</th>\n",
       "      <th>study_in_classroom_lang2</th>\n",
       "      <th>ways_of_study_lang2</th>\n",
       "      <th>non_native_language_3</th>\n",
       "      <th>yrs_of_study_lang3</th>\n",
       "      <th>study_in_classroom_lang3</th>\n",
       "      <th>ways_of_study_lang3</th>\n",
       "      <th>createddate</th>\n",
       "      <th>modifieddate</th>\n",
       "      <th>course_history</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anon_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ez9</th>\n",
       "      <td>Male</td>\n",
       "      <td>1978</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Studied...</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Studied by myself</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2006-01-30 15:07:18</td>\n",
       "      <td>2006-03-14 15:13:37</td>\n",
       "      <td>6;12;18;24;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gm3</th>\n",
       "      <td>Male</td>\n",
       "      <td>1980</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Had a native-speaker teacher;S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2006-01-30 15:07:28</td>\n",
       "      <td>2006-03-14 15:12:49</td>\n",
       "      <td>6;12;24;30;38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fg5</th>\n",
       "      <td>Male</td>\n",
       "      <td>1938</td>\n",
       "      <td>Nepali</td>\n",
       "      <td>Nepali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Had a n...</td>\n",
       "      <td>French</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Had a n...</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Studied by myself</td>\n",
       "      <td>2006-01-30 15:07:45</td>\n",
       "      <td>2006-03-14 15:11:36</td>\n",
       "      <td>18;24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ce5</th>\n",
       "      <td>Female</td>\n",
       "      <td>1984</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Had a n...</td>\n",
       "      <td>German</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Listened to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2006-01-30 15:07:49</td>\n",
       "      <td>2006-03-14 15:12:24</td>\n",
       "      <td>6;12;24;30;38;56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fi7</th>\n",
       "      <td>Female</td>\n",
       "      <td>1982</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean;Japanese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Had a native-speaker teacher;S...</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Listened to...</td>\n",
       "      <td>French</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Listened to...</td>\n",
       "      <td>2006-01-30 15:07:52</td>\n",
       "      <td>2006-03-14 15:12:17</td>\n",
       "      <td>6;12;24;30;38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gender  birth_year native_language language_used_at_home  \\\n",
       "anon_id                                                             \n",
       "ez9        Male        1978          Arabic                Arabic   \n",
       "gm3        Male        1980          Arabic                Arabic   \n",
       "fg5        Male        1938          Nepali                Nepali   \n",
       "ce5      Female        1984          Korean                Korean   \n",
       "fi7      Female        1982          Korean       Korean;Japanese   \n",
       "\n",
       "        language_used_at_home_now non_native_language_1 yrs_of_study_lang1  \\\n",
       "anon_id                                                                      \n",
       "ez9                           NaN               English  more than 5 years   \n",
       "gm3                           NaN               English  more than 5 years   \n",
       "fg5                           NaN               English  more than 5 years   \n",
       "ce5                           NaN               English  more than 5 years   \n",
       "fi7                           NaN               English  more than 5 years   \n",
       "\n",
       "         study_in_classroom_lang1  \\\n",
       "anon_id                             \n",
       "ez9                           1.0   \n",
       "gm3                           1.0   \n",
       "fg5                           1.0   \n",
       "ce5                           1.0   \n",
       "fi7                           1.0   \n",
       "\n",
       "                                       ways_of_study_lang1  \\\n",
       "anon_id                                                      \n",
       "ez9      Studied grammar;Worked in pairs/groups;Studied...   \n",
       "gm3      Studied grammar;Had a native-speaker teacher;S...   \n",
       "fg5      Studied grammar;Worked in pairs/groups;Had a n...   \n",
       "ce5      Studied grammar;Worked in pairs/groups;Had a n...   \n",
       "fi7      Studied grammar;Had a native-speaker teacher;S...   \n",
       "\n",
       "        non_native_language_2 yrs_of_study_lang2  study_in_classroom_lang2  \\\n",
       "anon_id                                                                      \n",
       "ez9                   Turkish   less than 1 year                       0.0   \n",
       "gm3                       NaN                NaN                       0.0   \n",
       "fg5                    French   less than 1 year                       1.0   \n",
       "ce5                    German          1-2 years                       1.0   \n",
       "fi7                  Japanese   less than 1 year                       1.0   \n",
       "\n",
       "                                       ways_of_study_lang2  \\\n",
       "anon_id                                                      \n",
       "ez9                                      Studied by myself   \n",
       "gm3                                                  other   \n",
       "fg5      Studied grammar;Worked in pairs/groups;Had a n...   \n",
       "ce5      Studied grammar;Studied vocabulary;Listened to...   \n",
       "fi7      Studied grammar;Studied vocabulary;Listened to...   \n",
       "\n",
       "        non_native_language_3 yrs_of_study_lang3  study_in_classroom_lang3  \\\n",
       "anon_id                                                                      \n",
       "ez9                       NaN                NaN                       0.0   \n",
       "gm3                       NaN                NaN                       0.0   \n",
       "fg5                     Hindi  more than 5 years                       0.0   \n",
       "ce5                       NaN                NaN                       0.0   \n",
       "fi7                    French          1-2 years                       1.0   \n",
       "\n",
       "                                       ways_of_study_lang3  \\\n",
       "anon_id                                                      \n",
       "ez9                                                  other   \n",
       "gm3                                                  other   \n",
       "fg5                                      Studied by myself   \n",
       "ce5                                                  other   \n",
       "fi7      Studied grammar;Studied vocabulary;Listened to...   \n",
       "\n",
       "                 createddate         modifieddate    course_history  \n",
       "anon_id                                                              \n",
       "ez9      2006-01-30 15:07:18  2006-03-14 15:13:37     6;12;18;24;30  \n",
       "gm3      2006-01-30 15:07:28  2006-03-14 15:12:49     6;12;24;30;38  \n",
       "fg5      2006-01-30 15:07:45  2006-03-14 15:11:36             18;24  \n",
       "ce5      2006-01-30 15:07:49  2006-03-14 15:12:24  6;12;24;30;38;56  \n",
       "fi7      2006-01-30 15:07:52  2006-03-14 15:12:17     6;12;24;30;38  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>native_language</th>\n",
       "      <th>language_used_at_home</th>\n",
       "      <th>language_used_at_home_now</th>\n",
       "      <th>non_native_language_1</th>\n",
       "      <th>yrs_of_study_lang1</th>\n",
       "      <th>study_in_classroom_lang1</th>\n",
       "      <th>ways_of_study_lang1</th>\n",
       "      <th>non_native_language_2</th>\n",
       "      <th>yrs_of_study_lang2</th>\n",
       "      <th>study_in_classroom_lang2</th>\n",
       "      <th>ways_of_study_lang2</th>\n",
       "      <th>non_native_language_3</th>\n",
       "      <th>yrs_of_study_lang3</th>\n",
       "      <th>study_in_classroom_lang3</th>\n",
       "      <th>ways_of_study_lang3</th>\n",
       "      <th>createddate</th>\n",
       "      <th>modifieddate</th>\n",
       "      <th>course_history</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anon_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cy2</th>\n",
       "      <td>Male</td>\n",
       "      <td>1988</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>English</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Had a n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:09:05</td>\n",
       "      <td>2011-06-20 14:11:31</td>\n",
       "      <td>845;846;847;871;872;927;928;931;949;950;1008;1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>br9</th>\n",
       "      <td>Female</td>\n",
       "      <td>1981</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Studied...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:09:15</td>\n",
       "      <td>2011-06-20 14:12:02</td>\n",
       "      <td>868;869;870;871;872;947;951;953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cl5</th>\n",
       "      <td>Male</td>\n",
       "      <td>1987</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>English</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Practiced s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:09:23</td>\n",
       "      <td>2011-06-20 14:13:16</td>\n",
       "      <td>770;771;778;779;781;856;857;859;861;871;952;95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de1</th>\n",
       "      <td>Male</td>\n",
       "      <td>1983</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Teacher spo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:09:27</td>\n",
       "      <td>2011-06-20 14:12:02</td>\n",
       "      <td>850;851;852;871;872;926;932;933;944;945;1008;1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ap0</th>\n",
       "      <td>Male</td>\n",
       "      <td>1978</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Listened to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:09:33</td>\n",
       "      <td>2011-06-20 14:12:52</td>\n",
       "      <td>845;846;847;871;872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gu4</th>\n",
       "      <td>Male</td>\n",
       "      <td>1983</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Studied by myself;I lived in a country where t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:09:34</td>\n",
       "      <td>2011-06-20 14:13:04</td>\n",
       "      <td>772;773;774;775;776;868;869;870;871;872;922;92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hb0</th>\n",
       "      <td>Female</td>\n",
       "      <td>1980</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>English</td>\n",
       "      <td>3-5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Had a native-speaker teacher;T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:09:38</td>\n",
       "      <td>2011-06-20 14:13:01</td>\n",
       "      <td>851;869;870;871;872;923;942;944;945;946;1008;1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dp8</th>\n",
       "      <td>Male</td>\n",
       "      <td>1991</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>English</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Had a n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:10:15</td>\n",
       "      <td>2011-06-20 14:13:57</td>\n",
       "      <td>868;869;870;871;872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bn6</th>\n",
       "      <td>Male</td>\n",
       "      <td>1986</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Teacher spo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:11:17</td>\n",
       "      <td>2011-06-20 14:15:51</td>\n",
       "      <td>860;861;862;871;872;930;947;948;949;951;998;99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aq6</th>\n",
       "      <td>Female</td>\n",
       "      <td>1964</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-09-14 14:05:38</td>\n",
       "      <td>2012-09-14 14:09:19</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gender  birth_year native_language language_used_at_home  \\\n",
       "anon_id                                                             \n",
       "cy2        Male        1988          Arabic                Arabic   \n",
       "br9      Female        1981         Chinese               Chinese   \n",
       "cl5        Male        1987          Arabic                Arabic   \n",
       "de1        Male        1983          Arabic                Arabic   \n",
       "ap0        Male        1978        Japanese              Japanese   \n",
       "gu4        Male        1983          Arabic                Arabic   \n",
       "hb0      Female        1980          Arabic                Arabic   \n",
       "dp8        Male        1991          Arabic        Arabic;English   \n",
       "bn6        Male        1986          Arabic        Arabic;English   \n",
       "aq6      Female        1964         English               English   \n",
       "\n",
       "        language_used_at_home_now non_native_language_1 yrs_of_study_lang1  \\\n",
       "anon_id                                                                      \n",
       "cy2                        Arabic               English   less than 1 year   \n",
       "br9                       Chinese               English  more than 5 years   \n",
       "cl5                Arabic;English               English   less than 1 year   \n",
       "de1                        Arabic               English  more than 5 years   \n",
       "ap0                      Japanese               English  more than 5 years   \n",
       "gu4                Arabic;English                Arabic  more than 5 years   \n",
       "hb0                        Arabic               English          3-5 years   \n",
       "dp8                Arabic;English               English          1-2 years   \n",
       "bn6                Arabic;English               English  more than 5 years   \n",
       "aq6                       English                   NaN                NaN   \n",
       "\n",
       "         study_in_classroom_lang1  \\\n",
       "anon_id                             \n",
       "cy2                           1.0   \n",
       "br9                           1.0   \n",
       "cl5                           1.0   \n",
       "de1                           1.0   \n",
       "ap0                           1.0   \n",
       "gu4                           0.0   \n",
       "hb0                           1.0   \n",
       "dp8                           1.0   \n",
       "bn6                           1.0   \n",
       "aq6                           NaN   \n",
       "\n",
       "                                       ways_of_study_lang1  \\\n",
       "anon_id                                                      \n",
       "cy2      Studied grammar;Worked in pairs/groups;Had a n...   \n",
       "br9      Studied grammar;Worked in pairs/groups;Studied...   \n",
       "cl5      Studied grammar;Studied vocabulary;Practiced s...   \n",
       "de1      Studied grammar;Studied vocabulary;Teacher spo...   \n",
       "ap0      Studied grammar;Studied vocabulary;Listened to...   \n",
       "gu4      Studied by myself;I lived in a country where t...   \n",
       "hb0      Studied grammar;Had a native-speaker teacher;T...   \n",
       "dp8      Studied grammar;Worked in pairs/groups;Had a n...   \n",
       "bn6      Studied grammar;Studied vocabulary;Teacher spo...   \n",
       "aq6                                                    NaN   \n",
       "\n",
       "        non_native_language_2 yrs_of_study_lang2  study_in_classroom_lang2  \\\n",
       "anon_id                                                                      \n",
       "cy2                       NaN                NaN                       0.0   \n",
       "br9                       NaN                NaN                       0.0   \n",
       "cl5                       NaN                NaN                       0.0   \n",
       "de1                       NaN                NaN                       0.0   \n",
       "ap0                       NaN                NaN                       0.0   \n",
       "gu4                       NaN                NaN                       0.0   \n",
       "hb0                       NaN                NaN                       0.0   \n",
       "dp8                       NaN                NaN                       0.0   \n",
       "bn6                       NaN                NaN                       0.0   \n",
       "aq6                       NaN                NaN                       NaN   \n",
       "\n",
       "        ways_of_study_lang2 non_native_language_3 yrs_of_study_lang3  \\\n",
       "anon_id                                                                \n",
       "cy2                   other                   NaN                NaN   \n",
       "br9                   other                   NaN                NaN   \n",
       "cl5                   other                   NaN                NaN   \n",
       "de1                   other                   NaN                NaN   \n",
       "ap0                   other                   NaN                NaN   \n",
       "gu4                   other                   NaN                NaN   \n",
       "hb0                   other                   NaN                NaN   \n",
       "dp8                   other                   NaN                NaN   \n",
       "bn6                   other                   NaN                NaN   \n",
       "aq6                     NaN                   NaN                NaN   \n",
       "\n",
       "         study_in_classroom_lang3 ways_of_study_lang3          createddate  \\\n",
       "anon_id                                                                      \n",
       "cy2                           0.0               other  2011-06-20 14:09:05   \n",
       "br9                           0.0               other  2011-06-20 14:09:15   \n",
       "cl5                           0.0               other  2011-06-20 14:09:23   \n",
       "de1                           0.0               other  2011-06-20 14:09:27   \n",
       "ap0                           0.0               other  2011-06-20 14:09:33   \n",
       "gu4                           0.0               other  2011-06-20 14:09:34   \n",
       "hb0                           0.0               other  2011-06-20 14:09:38   \n",
       "dp8                           0.0               other  2011-06-20 14:10:15   \n",
       "bn6                           0.0               other  2011-06-20 14:11:17   \n",
       "aq6                           NaN                 NaN  2012-09-14 14:05:38   \n",
       "\n",
       "                modifieddate  \\\n",
       "anon_id                        \n",
       "cy2      2011-06-20 14:11:31   \n",
       "br9      2011-06-20 14:12:02   \n",
       "cl5      2011-06-20 14:13:16   \n",
       "de1      2011-06-20 14:12:02   \n",
       "ap0      2011-06-20 14:12:52   \n",
       "gu4      2011-06-20 14:13:04   \n",
       "hb0      2011-06-20 14:13:01   \n",
       "dp8      2011-06-20 14:13:57   \n",
       "bn6      2011-06-20 14:15:51   \n",
       "aq6      2012-09-14 14:09:19   \n",
       "\n",
       "                                            course_history  \n",
       "anon_id                                                     \n",
       "cy2      845;846;847;871;872;927;928;931;949;950;1008;1...  \n",
       "br9                        868;869;870;871;872;947;951;953  \n",
       "cl5      770;771;778;779;781;856;857;859;861;871;952;95...  \n",
       "de1      850;851;852;871;872;926;932;933;944;945;1008;1...  \n",
       "ap0                                    845;846;847;871;872  \n",
       "gu4      772;773;774;775;776;868;869;870;871;872;922;92...  \n",
       "hb0      851;869;870;871;872;923;942;944;945;946;1008;1...  \n",
       "dp8                                    868;869;870;871;872  \n",
       "bn6      860;861;862;871;872;930;947;948;949;951;998;99...  \n",
       "aq6                                                   1114  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Process the student_information.csv file\n",
    "S_info_csv = cor_dir + \"student_information.csv\"\n",
    "S_info_df = pd.read_csv(S_info_csv, index_col = 'anon_id')\n",
    "\n",
    "S_info_df.head() #Issues still apparent with integers turned into floats\n",
    "S_info_df.tail(10) #6 anon_id with no personal info - perhaps not students and to be 'pruned', as well as teachers with 'English' as the native language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>native_language</th>\n",
       "      <th>language_used_at_home</th>\n",
       "      <th>language_used_at_home_now</th>\n",
       "      <th>non_native_language_1</th>\n",
       "      <th>yrs_of_study_lang1</th>\n",
       "      <th>study_in_classroom_lang1</th>\n",
       "      <th>ways_of_study_lang1</th>\n",
       "      <th>non_native_language_2</th>\n",
       "      <th>yrs_of_study_lang2</th>\n",
       "      <th>study_in_classroom_lang2</th>\n",
       "      <th>ways_of_study_lang2</th>\n",
       "      <th>non_native_language_3</th>\n",
       "      <th>yrs_of_study_lang3</th>\n",
       "      <th>study_in_classroom_lang3</th>\n",
       "      <th>ways_of_study_lang3</th>\n",
       "      <th>createddate</th>\n",
       "      <th>modifieddate</th>\n",
       "      <th>course_history</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anon_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ez7</th>\n",
       "      <td>Male</td>\n",
       "      <td>1987</td>\n",
       "      <td>English</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I lived in a country where they spoke Arabic</td>\n",
       "      <td>English</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Studied pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2007-02-20 10:05:39</td>\n",
       "      <td>2007-03-20 10:09:23</td>\n",
       "      <td>156;167;180;191;200;212;223;234;245;256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ay4</th>\n",
       "      <td>Female</td>\n",
       "      <td>1974</td>\n",
       "      <td>English</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Had a native-speaker teacher;S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2009-06-09 12:04:22</td>\n",
       "      <td>2009-11-13 12:43:36</td>\n",
       "      <td>509;515;516;517;560;571;574;601;622;642;645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aq6</th>\n",
       "      <td>Female</td>\n",
       "      <td>1964</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-09-14 14:05:38</td>\n",
       "      <td>2012-09-14 14:09:19</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gender  birth_year native_language language_used_at_home  \\\n",
       "anon_id                                                             \n",
       "ez7        Male        1987         English                Arabic   \n",
       "ay4      Female        1974         English                Korean   \n",
       "aq6      Female        1964         English               English   \n",
       "\n",
       "        language_used_at_home_now non_native_language_1 yrs_of_study_lang1  \\\n",
       "anon_id                                                                      \n",
       "ez7                Arabic;English                Arabic  more than 5 years   \n",
       "ay4                        Korean                Korean  more than 5 years   \n",
       "aq6                       English                   NaN                NaN   \n",
       "\n",
       "         study_in_classroom_lang1  \\\n",
       "anon_id                             \n",
       "ez7                           0.0   \n",
       "ay4                           1.0   \n",
       "aq6                           NaN   \n",
       "\n",
       "                                       ways_of_study_lang1  \\\n",
       "anon_id                                                      \n",
       "ez7           I lived in a country where they spoke Arabic   \n",
       "ay4      Studied grammar;Had a native-speaker teacher;S...   \n",
       "aq6                                                    NaN   \n",
       "\n",
       "        non_native_language_2 yrs_of_study_lang2  study_in_classroom_lang2  \\\n",
       "anon_id                                                                      \n",
       "ez7                   English   less than 1 year                       1.0   \n",
       "ay4                       NaN                NaN                       0.0   \n",
       "aq6                       NaN                NaN                       NaN   \n",
       "\n",
       "                                       ways_of_study_lang2  \\\n",
       "anon_id                                                      \n",
       "ez7      Studied grammar;Studied vocabulary;Studied pro...   \n",
       "ay4                                                  other   \n",
       "aq6                                                    NaN   \n",
       "\n",
       "        non_native_language_3 yrs_of_study_lang3  study_in_classroom_lang3  \\\n",
       "anon_id                                                                      \n",
       "ez7                       NaN                NaN                       0.0   \n",
       "ay4                       NaN                NaN                       0.0   \n",
       "aq6                       NaN                NaN                       NaN   \n",
       "\n",
       "        ways_of_study_lang3          createddate         modifieddate  \\\n",
       "anon_id                                                                 \n",
       "ez7                   other  2007-02-20 10:05:39  2007-03-20 10:09:23   \n",
       "ay4                   other  2009-06-09 12:04:22  2009-11-13 12:43:36   \n",
       "aq6                     NaN  2012-09-14 14:05:38  2012-09-14 14:09:19   \n",
       "\n",
       "                                      course_history  \n",
       "anon_id                                               \n",
       "ez7          156;167;180;191;200;212;223;234;245;256  \n",
       "ay4      509;515;516;517;560;571;574;601;622;642;645  \n",
       "aq6                                             1114  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove anyone with 'English' or 'NaN' as their native_language, i.e. not students\n",
    "\n",
    "#First try to create filters\n",
    "\n",
    "Englishfilter = S_info_df['native_language'] == 'English' #first filter works\n",
    "NaNfilter = S_info_df['native_language'] == np.nan #second filter doesn't\n",
    "\n",
    "fake_Ss = S_info_df.loc[Englishfilter] #works, but...\n",
    "fake_Ss\n",
    "\n",
    "#fake_Ss = S_info_df.loc[(Englishfilter) or (NaNfilter)] #doesn't work\n",
    "#fake_Ss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student responses (answer_csv and answer_df) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>directory</th>\n",
       "      <th>is_doublespaced</th>\n",
       "      <th>is_plagiarized</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>eq0</td>\n",
       "      <td>7505</td>\n",
       "      <td>I met my friend Nife while I was studying in a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>am8</td>\n",
       "      <td>7506</td>\n",
       "      <td>Ten years ago, I met a women on the train betw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>dk5</td>\n",
       "      <td>7507</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>dk5</td>\n",
       "      <td>7507</td>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>ad1</td>\n",
       "      <td>7508</td>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\r\\r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id anon_id  user_file_id  \\\n",
       "answer_id                                      \n",
       "1                    5     eq0          7505   \n",
       "2                    5     am8          7506   \n",
       "3                   12     dk5          7507   \n",
       "4                   13     dk5          7507   \n",
       "5                   12     ad1          7508   \n",
       "\n",
       "                                                        text directory  \\\n",
       "answer_id                                                                \n",
       "1          I met my friend Nife while I was studying in a...       NaN   \n",
       "2          Ten years ago, I met a women on the train betw...       NaN   \n",
       "3          In my country we usually don't use tea bags. F...       NaN   \n",
       "4                      I organized the instructions by time.       NaN   \n",
       "5          First, prepare a port, loose tea, and cup.\\r\\r...       NaN   \n",
       "\n",
       "           is_doublespaced  is_plagiarized  is_deleted  \n",
       "answer_id                                               \n",
       "1                        0               0           0  \n",
       "2                        0               0           0  \n",
       "3                        0               0           0  \n",
       "4                        0               0           0  \n",
       "5                        0               0           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>directory</th>\n",
       "      <th>is_doublespaced</th>\n",
       "      <th>is_plagiarized</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48411</th>\n",
       "      <td>6138</td>\n",
       "      <td>dv8</td>\n",
       "      <td>100847</td>\n",
       "      <td>Early Second Language Education\\r\\r\\r\\nSaudi A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48412</th>\n",
       "      <td>6138</td>\n",
       "      <td>ce1</td>\n",
       "      <td>100848</td>\n",
       "      <td>Publicly funded health care system\\r\\r\\r\\n\\r\\r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48413</th>\n",
       "      <td>6139</td>\n",
       "      <td>fo7</td>\n",
       "      <td>100911</td>\n",
       "      <td>Happiness is the most effective feeling in peo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48414</th>\n",
       "      <td>6139</td>\n",
       "      <td>fs9</td>\n",
       "      <td>100912</td>\n",
       "      <td>everyone want to play some games. some people ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48415</th>\n",
       "      <td>6139</td>\n",
       "      <td>cl7</td>\n",
       "      <td>100913</td>\n",
       "      <td>Playing a game is fun only when you win?\\r\\r\\r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48416</th>\n",
       "      <td>6139</td>\n",
       "      <td>dr8</td>\n",
       "      <td>100914</td>\n",
       "      <td>Many people enjoy a game in their free time. B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48417</th>\n",
       "      <td>6137</td>\n",
       "      <td>fv1</td>\n",
       "      <td>100915</td>\n",
       "      <td>\\r\\r\\r\\n                           ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48418</th>\n",
       "      <td>6137</td>\n",
       "      <td>fo1</td>\n",
       "      <td>100916</td>\n",
       "      <td>Some  patients are suffering from the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48419</th>\n",
       "      <td>6119</td>\n",
       "      <td>ge8</td>\n",
       "      <td>100917</td>\n",
       "      <td>My house looks amazing and modern. I decorated...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48420</th>\n",
       "      <td>6027</td>\n",
       "      <td>ge8</td>\n",
       "      <td>100918</td>\n",
       "      <td>History and Geography a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id anon_id  user_file_id  \\\n",
       "answer_id                                      \n",
       "48411             6138     dv8        100847   \n",
       "48412             6138     ce1        100848   \n",
       "48413             6139     fo7        100911   \n",
       "48414             6139     fs9        100912   \n",
       "48415             6139     cl7        100913   \n",
       "48416             6139     dr8        100914   \n",
       "48417             6137     fv1        100915   \n",
       "48418             6137     fo1        100916   \n",
       "48419             6119     ge8        100917   \n",
       "48420             6027     ge8        100918   \n",
       "\n",
       "                                                        text directory  \\\n",
       "answer_id                                                                \n",
       "48411      Early Second Language Education\\r\\r\\r\\nSaudi A...       NaN   \n",
       "48412      Publicly funded health care system\\r\\r\\r\\n\\r\\r...       NaN   \n",
       "48413      Happiness is the most effective feeling in peo...       NaN   \n",
       "48414      everyone want to play some games. some people ...       NaN   \n",
       "48415      Playing a game is fun only when you win?\\r\\r\\r...       NaN   \n",
       "48416      Many people enjoy a game in their free time. B...       NaN   \n",
       "48417                 \\r\\r\\r\\n                           ...       NaN   \n",
       "48418               Some  patients are suffering from the...       NaN   \n",
       "48419      My house looks amazing and modern. I decorated...       NaN   \n",
       "48420                             History and Geography a...       NaN   \n",
       "\n",
       "           is_doublespaced  is_plagiarized  is_deleted  \n",
       "answer_id                                               \n",
       "48411                    1               0           0  \n",
       "48412                    0               0           0  \n",
       "48413                    1               0           0  \n",
       "48414                    1               0           0  \n",
       "48415                    1               0           0  \n",
       "48416                    1               0           0  \n",
       "48417                    0               0           0  \n",
       "48418                    0               0           0  \n",
       "48419                    0               0           0  \n",
       "48420                    0               0           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Process answer.csv file\n",
    "answer_csv = cor_dir + \"answer.csv\"\n",
    "answer_df = pd.read_csv(answer_csv, index_col = 'answer_id')\n",
    "\n",
    "answer_df.head()\n",
    "answer_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course IDs ###\n",
    "(should help with finding specific texts and linking other data frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>semester</th>\n",
       "      <th>section</th>\n",
       "      <th>course_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>course_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2064</td>\n",
       "      <td>A</td>\n",
       "      <td>Reading Pre_Intermediate 2064 A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2064</td>\n",
       "      <td>B</td>\n",
       "      <td>Reading Low_Intermediate 2064 B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>M</td>\n",
       "      <td>Reading Intermediate 2064 M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>P</td>\n",
       "      <td>Reading Intermediate 2064 P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>Q</td>\n",
       "      <td>Reading Intermediate 2064 Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           class_id  level_id  semester section  \\\n",
       "course_id                                         \n",
       "1                 1         2      2064       A   \n",
       "2                 1         3      2064       B   \n",
       "3                 1         4      2064       M   \n",
       "4                 1         4      2064       P   \n",
       "5                 1         4      2064       Q   \n",
       "\n",
       "                        course_description  \n",
       "course_id                                   \n",
       "1          Reading Pre_Intermediate 2064 A  \n",
       "2          Reading Low_Intermediate 2064 B  \n",
       "3              Reading Intermediate 2064 M  \n",
       "4              Reading Intermediate 2064 P  \n",
       "5              Reading Intermediate 2064 Q  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Process course.csv file\n",
    "course_csv = cor_dir + \"course.csv\"\n",
    "course_df = pd.read_csv(course_csv, index_col = 'course_id')\n",
    "\n",
    "course_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  user_file_internal ###\n",
    "- big csv file with a lot of information\n",
    "- should help with finding specific texts and linking other data frames\n",
    "- includes file_type_id, course_id, and paths of text and wav files (i.e. all the spoken responses I need)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>file_type_id</th>\n",
       "      <th>file_info_id</th>\n",
       "      <th>user_file_parent_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>activity</th>\n",
       "      <th>order_num</th>\n",
       "      <th>due_date</th>\n",
       "      <th>...</th>\n",
       "      <th>modifiedby</th>\n",
       "      <th>modifieddate</th>\n",
       "      <th>allow_submit_after_duedate</th>\n",
       "      <th>allow_multiple_accesses</th>\n",
       "      <th>allow_double_spacing</th>\n",
       "      <th>duration</th>\n",
       "      <th>pull_off_date</th>\n",
       "      <th>direction</th>\n",
       "      <th>grammar_qp_id</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_file_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aj8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-07 14:19:48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fg8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-07 14:19:48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>be0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-07 14:19:48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fc4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-07 14:19:48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fc4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-07 14:19:48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             anon_id  file_type_id  file_info_id  user_file_parent_id  \\\n",
       "user_file_id                                                            \n",
       "1                aj8             1           NaN                  NaN   \n",
       "2                fg8             1           NaN                  NaN   \n",
       "3                be0             1           NaN                  NaN   \n",
       "4                fc4             1           NaN                  NaN   \n",
       "5                fc4             1           NaN                  1.0   \n",
       "\n",
       "              course_id  session_id  document_id  activity  order_num  \\\n",
       "user_file_id                                                            \n",
       "1                    10         NaN          NaN        12        NaN   \n",
       "2                    10         NaN          NaN        12        NaN   \n",
       "3                    10         NaN          NaN        12        NaN   \n",
       "4                    10         NaN          NaN        12        NaN   \n",
       "5                    10         NaN          NaN        12        NaN   \n",
       "\n",
       "                         due_date    ...     modifiedby modifieddate  \\\n",
       "user_file_id                         ...                               \n",
       "1             2006-08-07 14:19:48    ...            NaN          NaN   \n",
       "2             2006-08-07 14:19:48    ...            NaN          NaN   \n",
       "3             2006-08-07 14:19:48    ...            NaN          NaN   \n",
       "4             2006-08-07 14:19:48    ...            NaN          NaN   \n",
       "5             2006-08-07 14:19:48    ...            NaN          NaN   \n",
       "\n",
       "              allow_submit_after_duedate  allow_multiple_accesses  \\\n",
       "user_file_id                                                        \n",
       "1                                      0                        0   \n",
       "2                                      0                        0   \n",
       "3                                      0                        0   \n",
       "4                                      0                        0   \n",
       "5                                      0                        0   \n",
       "\n",
       "              allow_double_spacing duration pull_off_date direction  \\\n",
       "user_file_id                                                          \n",
       "1                                0      NaN           NaN       NaN   \n",
       "2                                0      NaN           NaN       NaN   \n",
       "3                                0      NaN           NaN       NaN   \n",
       "4                                0      NaN           NaN       NaN   \n",
       "5                                0      NaN           NaN       NaN   \n",
       "\n",
       "              grammar_qp_id is_deleted  \n",
       "user_file_id                            \n",
       "1                       NaN          0  \n",
       "2                       NaN          0  \n",
       "3                       NaN          0  \n",
       "4                       NaN          0  \n",
       "5                       NaN          0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Process user_file_wavtxt.csv file\n",
    "user_csv = cor_dir + \"user_file_internal.csv\"\n",
    "user_df = pd.read_csv(user_csv, index_col = 'user_file_id')\n",
    "\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic info about dataframes ###\n",
    "\n",
    "The following information is an overview of the four dataframes/csv files currently being looked at:\n",
    "\n",
    "#### S_info_df ####\n",
    "Size:\n",
    "- there are 941 entries, i.e. students, although at least 9 need to be removed once filters can be made to work\n",
    "- 21 columns including info about languages spoken, personal data like age, and learning preferences\n",
    "- Some columns will likely be removed if deemed unhelpful/unnecessary (e.g. 4th language spoken)\n",
    "- Some data is normalized, e.g. years of study, but others was open, resulting in very varied responses\n",
    "\n",
    "Connection to other dataframes:\n",
    "- link to answer_df is anon_id\n",
    "\n",
    "Most useful columns for this project:\n",
    "- anon_id (for linking to other df)\n",
    "- L1, gender, time studying, age (for data analysis)  \n",
    "\n",
    "\n",
    "#### answer_df ####\n",
    "Size:\n",
    "- there are 47175 'text' entries, i.e. student responses, although 48384 total rows. The remaining (including many null texts need to be removed as without texts they serve no purpose\n",
    "- 9 columns including info about the question, the answer, and characteristics of the text (like if it was plagiarized)\n",
    "\n",
    "Connection to other dataframes:\n",
    "- link to S_info_df and course_df is anon_id column\n",
    "\n",
    "Most useful columns for this project:\n",
    "- answer_id (shorthand for the individual texts to be analyzed)\n",
    "- text (the most important column so far) -> to be converted into tokens, bigrams, etc.  \n",
    "- anon_id (for linking to other df)\n",
    "\n",
    "\n",
    "#### course_df ####\n",
    "Size:\n",
    "- there are 1071 entries, i.e. one row for each course\n",
    "- 6 columns including info about the course and class, both in terms of their assigned number and a description\n",
    "\n",
    "Connection to other dataframes:\n",
    "- link to user_df is course_id \n",
    "\n",
    "Most useful columns for this project:\n",
    "- only really useful as a transition for linking to other df  \n",
    "\n",
    "\n",
    "#### user_df ####\n",
    "Size:\n",
    "- there are 76371 rows, each with a file_id number. However, it is unclear how to use this informatin effectively.\n",
    "- There are 29 columns, although many are not useful for this project\n",
    "- A lot of the cells have no input\n",
    "- Some columns will likely be removed if deemed unhelpful/unnecessary\n",
    "\n",
    "Connection to other dataframes:\n",
    "- link to course_df is course_id column\n",
    "\n",
    "Most useful columns for this project:\n",
    "- course_id (to link to other DF)\n",
    "- file_type_id (for indicating the type of activity used in class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 920 entries, ez9 to aq6\n",
      "Data columns (total 20 columns):\n",
      "gender                       920 non-null object\n",
      "birth_year                   920 non-null int64\n",
      "native_language              920 non-null object\n",
      "language_used_at_home        919 non-null object\n",
      "language_used_at_home_now    860 non-null object\n",
      "non_native_language_1        864 non-null object\n",
      "yrs_of_study_lang1           869 non-null object\n",
      "study_in_classroom_lang1     869 non-null float64\n",
      "ways_of_study_lang1          869 non-null object\n",
      "non_native_language_2        311 non-null object\n",
      "yrs_of_study_lang2           314 non-null object\n",
      "study_in_classroom_lang2     869 non-null float64\n",
      "ways_of_study_lang2          869 non-null object\n",
      "non_native_language_3        55 non-null object\n",
      "yrs_of_study_lang3           59 non-null object\n",
      "study_in_classroom_lang3     869 non-null float64\n",
      "ways_of_study_lang3          869 non-null object\n",
      "createddate                  920 non-null object\n",
      "modifieddate                 916 non-null object\n",
      "course_history               919 non-null object\n",
      "dtypes: float64(3), int64(1), object(16)\n",
      "memory usage: 150.9+ KB\n"
     ]
    }
   ],
   "source": [
    "S_info_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 48384 entries, 1 to 48420\n",
      "Data columns (total 8 columns):\n",
      "question_id        48384 non-null int64\n",
      "anon_id            48353 non-null object\n",
      "user_file_id       48384 non-null int64\n",
      "text               47175 non-null object\n",
      "directory          14 non-null object\n",
      "is_doublespaced    48384 non-null int64\n",
      "is_plagiarized     48384 non-null int64\n",
      "is_deleted         48384 non-null int64\n",
      "dtypes: int64(5), object(3)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "answer_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1071 entries, 1 to 1123\n",
      "Data columns (total 5 columns):\n",
      "class_id              1071 non-null int64\n",
      "level_id              1071 non-null int64\n",
      "semester              1071 non-null int64\n",
      "section               1071 non-null object\n",
      "course_description    1058 non-null object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 50.2+ KB\n"
     ]
    }
   ],
   "source": [
    "course_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27134 entries, 1 to 100918\n",
      "Data columns (total 28 columns):\n",
      "anon_id                       26922 non-null object\n",
      "file_type_id                  27134 non-null int64\n",
      "file_info_id                  2151 non-null float64\n",
      "user_file_parent_id           25884 non-null float64\n",
      "course_id                     27134 non-null int64\n",
      "session_id                    26142 non-null float64\n",
      "document_id                   1599 non-null float64\n",
      "activity                      27134 non-null int64\n",
      "order_num                     2722 non-null float64\n",
      "due_date                      3286 non-null object\n",
      "post_date                     3714 non-null object\n",
      "assignment_name               2700 non-null object\n",
      "version                       27134 non-null int64\n",
      "directory                     0 non-null float64\n",
      "filename                      0 non-null float64\n",
      "content_text                  964 non-null object\n",
      "createdby                     24955 non-null object\n",
      "createddate                   27134 non-null object\n",
      "modifiedby                    462 non-null float64\n",
      "modifieddate                  462 non-null object\n",
      "allow_submit_after_duedate    27134 non-null int64\n",
      "allow_multiple_accesses       27134 non-null int64\n",
      "allow_double_spacing          27134 non-null int64\n",
      "duration                      406 non-null float64\n",
      "pull_off_date                 406 non-null object\n",
      "direction                     1997 non-null object\n",
      "grammar_qp_id                 0 non-null float64\n",
      "is_deleted                    27134 non-null int64\n",
      "dtypes: float64(10), int64(8), object(10)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "user_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating find_stuff function ###\n",
    "\n",
    "Goal: create a function that allows for easy retrieval within, from the various different, dataframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>semester</th>\n",
       "      <th>section</th>\n",
       "      <th>course_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>course_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2064</td>\n",
       "      <td>A</td>\n",
       "      <td>Speaking Pre_Intermediate 2064 A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2064</td>\n",
       "      <td>B</td>\n",
       "      <td>Speaking Low_Intermediate 2064 B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>M</td>\n",
       "      <td>Speaking Intermediate 2064 M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>P</td>\n",
       "      <td>Speaking Intermediate 2064 P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>Q</td>\n",
       "      <td>Speaking Intermediate 2064 Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           class_id  level_id  semester section  \\\n",
       "course_id                                         \n",
       "13                3         2      2064       A   \n",
       "14                3         3      2064       B   \n",
       "15                3         4      2064       M   \n",
       "16                3         4      2064       P   \n",
       "17                3         4      2064       Q   \n",
       "\n",
       "                         course_description  \n",
       "course_id                                    \n",
       "13         Speaking Pre_Intermediate 2064 A  \n",
       "14         Speaking Low_Intermediate 2064 B  \n",
       "15             Speaking Intermediate 2064 M  \n",
       "16             Speaking Intermediate 2064 P  \n",
       "17             Speaking Intermediate 2064 Q  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adapted from initial work of Brianna - thank you!\n",
    "\n",
    "#this works to find all the course_id entries for a particular class type, in this case '3' which == speaking\n",
    "\n",
    "def find_stuff(df, class_type):\n",
    "    class_id = df.loc[df['class_id'] == class_type]\n",
    "    return class_id\n",
    "\n",
    "test = find_stuff(course_df, 3)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>semester</th>\n",
       "      <th>section</th>\n",
       "      <th>course_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>course_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2064</td>\n",
       "      <td>A</td>\n",
       "      <td>Grammar Pre_Intermediate 2064 A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2064</td>\n",
       "      <td>B</td>\n",
       "      <td>Grammar Low_Intermediate 2064 B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>M</td>\n",
       "      <td>Grammar Intermediate 2064 M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>P</td>\n",
       "      <td>Grammar Intermediate 2064 P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>Q</td>\n",
       "      <td>Grammar Intermediate 2064 Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           class_id  level_id  semester section  \\\n",
       "course_id                                         \n",
       "25                5         2      2064       A   \n",
       "26                5         3      2064       B   \n",
       "27                5         4      2064       M   \n",
       "28                5         4      2064       P   \n",
       "29                5         4      2064       Q   \n",
       "\n",
       "                        course_description  \n",
       "course_id                                   \n",
       "25         Grammar Pre_Intermediate 2064 A  \n",
       "26         Grammar Low_Intermediate 2064 B  \n",
       "27             Grammar Intermediate 2064 M  \n",
       "28             Grammar Intermediate 2064 P  \n",
       "29             Grammar Intermediate 2064 Q  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test #2\n",
    "\n",
    "test2 = find_stuff(course_df, 5)\n",
    "test2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next step is to either expand on this function or create other similar ones to allow look up of other types of info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization of answers ###\n",
    "\n",
    "Goal: tokenize the text in answer.csv to allow for further analysis (bigrams, lexical diversity, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I met my friend Nife while I was studying in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ten years ago, I met a women on the train betw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\r\\r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text\n",
       "answer_id                                                   \n",
       "1          I met my friend Nife while I was studying in a...\n",
       "2          Ten years ago, I met a women on the train betw...\n",
       "3          In my country we usually don't use tea bags. F...\n",
       "4                      I organized the instructions by time.\n",
       "5          First, prepare a port, loose tea, and cup.\\r\\r..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find column to tokenize\n",
    "\n",
    "answer_df[['text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>directory</th>\n",
       "      <th>is_doublespaced</th>\n",
       "      <th>is_plagiarized</th>\n",
       "      <th>is_deleted</th>\n",
       "      <th>toks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>eq0</td>\n",
       "      <td>7505</td>\n",
       "      <td>I met my friend Nife while I was studying in a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, met, my, friend, Nife, while, I, was, stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>am8</td>\n",
       "      <td>7506</td>\n",
       "      <td>Ten years ago, I met a women on the train betw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Ten, years, ago, ,, I, met, a, women, on, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>dk5</td>\n",
       "      <td>7507</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[In, my, country, we, usually, do, n't, use, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>dk5</td>\n",
       "      <td>7507</td>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, organized, the, instructions, by, time, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>ad1</td>\n",
       "      <td>7508</td>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\r\\r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[First, ,, prepare, a, port, ,, loose, tea, ,,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id anon_id  user_file_id  \\\n",
       "answer_id                                      \n",
       "1                    5     eq0          7505   \n",
       "2                    5     am8          7506   \n",
       "3                   12     dk5          7507   \n",
       "4                   13     dk5          7507   \n",
       "5                   12     ad1          7508   \n",
       "\n",
       "                                                        text directory  \\\n",
       "answer_id                                                                \n",
       "1          I met my friend Nife while I was studying in a...       NaN   \n",
       "2          Ten years ago, I met a women on the train betw...       NaN   \n",
       "3          In my country we usually don't use tea bags. F...       NaN   \n",
       "4                      I organized the instructions by time.       NaN   \n",
       "5          First, prepare a port, loose tea, and cup.\\r\\r...       NaN   \n",
       "\n",
       "           is_doublespaced  is_plagiarized  is_deleted  \\\n",
       "answer_id                                                \n",
       "1                        0               0           0   \n",
       "2                        0               0           0   \n",
       "3                        0               0           0   \n",
       "4                        0               0           0   \n",
       "5                        0               0           0   \n",
       "\n",
       "                                                        toks  \n",
       "answer_id                                                     \n",
       "1          [I, met, my, friend, Nife, while, I, was, stud...  \n",
       "2          [Ten, years, ago, ,, I, met, a, women, on, the...  \n",
       "3          [In, my, country, we, usually, do, n't, use, t...  \n",
       "4             [I, organized, the, instructions, by, time, .]  \n",
       "5          [First, ,, prepare, a, port, ,, loose, tea, ,,...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#With the magic of stackoverflow, this seems to work, converting NaN to empty strings\n",
    "answer_df = answer_df[answer_df['text'].notnull()]\n",
    "answer_df['toks'] = answer_df.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\n",
    "\n",
    "answer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams###\n",
    "\n",
    "Goal: create a bigram columns from the tok column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'met', 'my', 'friend', 'Nife', 'while', 'I', 'was', 'studying', 'in', 'a', 'middle', 'school', '.', 'I', 'was', 'happy', 'when', 'I', 'met', 'him', 'because', 'he', 'was', 'a', 'good', 'student', 'in', 'our', 'school', '.', 'We', 'continued', 'the', 'middle', 'and', 'high', 'school', 'to', 'gather', 'in', 'the', 'same', 'school', '.', 'We', 'were', 'studying', 'in', 'the', 'different', 'classes', 'in', 'the', 'middle', 'school', ';', 'however', ',', 'in', 'the', 'high', 'school', 'we', 'were', 'studying', 'in', 'the', 'same', 'class', '.', 'We', 'went', 'to', 'many', 'places', 'in', 'the', 'free', 'time', 'while', 'we', 'were', 'studying', 'in', 'the', 'high', 'school', '.', 'When', 'we', 'finished', 'from', 'the', 'high', 'school', ',', 'I', 'went', 'to', 'K.S', 'University', 'and', 'he', 'went', 'to', 'I.M', 'University', '.', 'While', 'we', 'were', 'enjoying', 'in', 'academic', 'life', ',', 'we', 'made', 'many', 'achievement', 'in', 'these', 'universities', '.', 'I', 'graduated', 'when', 'Nife', 'was', 'studying', 'in', 'the', 'last', 'semester', 'in', 'the', 'university', '.', 'After', 'that', ',', 'I', 'got', 'a', 'job', '.', 'Fortunately', ',', 'it', 'was', 'nearby', 'my', 'home', '.', 'I', 'worked', 'two', 'years', 'then', 'I', 'got', 'scholarship', 'from', 'ministry', 'of', 'high', 'education', 'in', 'my', 'country', '.', 'When', 'I', 'came', 'here', 'to', 'U.S', ',', 'my', 'friend', 'Nife', 'arrange', 'some', 'documents', 'to', 'study', 'at', 'grad', 'school', 'in', 'Malaysia', '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('I', 'met'), ('met', 'my'), ('my', 'friend'), ('friend', 'Nife'), ('Nife', 'while'), ('while', 'I'), ('I', 'was'), ('was', 'studying'), ('studying', 'in'), ('in', 'a'), ('a', 'middle'), ('middle', 'school'), ('school', '.'), ('.', 'I'), ('I', 'was'), ('was', 'happy'), ('happy', 'when'), ('when', 'I'), ('I', 'met'), ('met', 'him'), ('him', 'because'), ('because', 'he'), ('he', 'was'), ('was', 'a'), ('a', 'good'), ('good', 'student'), ('student', 'in'), ('in', 'our'), ('our', 'school'), ('school', '.'), ('.', 'We'), ('We', 'continued'), ('continued', 'the'), ('the', 'middle'), ('middle', 'and'), ('and', 'high'), ('high', 'school'), ('school', 'to'), ('to', 'gather'), ('gather', 'in'), ('in', 'the'), ('the', 'same'), ('same', 'school'), ('school', '.'), ('.', 'We'), ('We', 'were'), ('were', 'studying'), ('studying', 'in'), ('in', 'the'), ('the', 'different'), ('different', 'classes'), ('classes', 'in'), ('in', 'the'), ('the', 'middle'), ('middle', 'school'), ('school', ';'), (';', 'however'), ('however', ','), (',', 'in'), ('in', 'the'), ('the', 'high'), ('high', 'school'), ('school', 'we'), ('we', 'were'), ('were', 'studying'), ('studying', 'in'), ('in', 'the'), ('the', 'same'), ('same', 'class'), ('class', '.'), ('.', 'We'), ('We', 'went'), ('went', 'to'), ('to', 'many'), ('many', 'places'), ('places', 'in'), ('in', 'the'), ('the', 'free'), ('free', 'time'), ('time', 'while'), ('while', 'we'), ('we', 'were'), ('were', 'studying'), ('studying', 'in'), ('in', 'the'), ('the', 'high'), ('high', 'school'), ('school', '.'), ('.', 'When'), ('When', 'we'), ('we', 'finished'), ('finished', 'from'), ('from', 'the'), ('the', 'high'), ('high', 'school'), ('school', ','), (',', 'I'), ('I', 'went'), ('went', 'to'), ('to', 'K.S'), ('K.S', 'University'), ('University', 'and'), ('and', 'he'), ('he', 'went'), ('went', 'to'), ('to', 'I.M'), ('I.M', 'University'), ('University', '.'), ('.', 'While'), ('While', 'we'), ('we', 'were'), ('were', 'enjoying'), ('enjoying', 'in'), ('in', 'academic'), ('academic', 'life'), ('life', ','), (',', 'we'), ('we', 'made'), ('made', 'many'), ('many', 'achievement'), ('achievement', 'in'), ('in', 'these'), ('these', 'universities'), ('universities', '.'), ('.', 'I'), ('I', 'graduated'), ('graduated', 'when'), ('when', 'Nife'), ('Nife', 'was'), ('was', 'studying'), ('studying', 'in'), ('in', 'the'), ('the', 'last'), ('last', 'semester'), ('semester', 'in'), ('in', 'the'), ('the', 'university'), ('university', '.'), ('.', 'After'), ('After', 'that'), ('that', ','), (',', 'I'), ('I', 'got'), ('got', 'a'), ('a', 'job'), ('job', '.'), ('.', 'Fortunately'), ('Fortunately', ','), (',', 'it'), ('it', 'was'), ('was', 'nearby'), ('nearby', 'my'), ('my', 'home'), ('home', '.'), ('.', 'I'), ('I', 'worked'), ('worked', 'two'), ('two', 'years'), ('years', 'then'), ('then', 'I'), ('I', 'got'), ('got', 'scholarship'), ('scholarship', 'from'), ('from', 'ministry'), ('ministry', 'of'), ('of', 'high'), ('high', 'education'), ('education', 'in'), ('in', 'my'), ('my', 'country'), ('country', '.'), ('.', 'When'), ('When', 'I'), ('I', 'came'), ('came', 'here'), ('here', 'to'), ('to', 'U.S'), ('U.S', ','), (',', 'my'), ('my', 'friend'), ('friend', 'Nife'), ('Nife', 'arrange'), ('arrange', 'some'), ('some', 'documents'), ('documents', 'to'), ('to', 'study'), ('study', 'at'), ('at', 'grad'), ('grad', 'school'), ('school', 'in'), ('in', 'Malaysia'), ('Malaysia', '.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>directory</th>\n",
       "      <th>is_doublespaced</th>\n",
       "      <th>is_plagiarized</th>\n",
       "      <th>is_deleted</th>\n",
       "      <th>toks</th>\n",
       "      <th>bigrams</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>eq0</td>\n",
       "      <td>7505</td>\n",
       "      <td>I met my friend Nife while I was studying in a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, met, my, friend, Nife, while, I, was, stud...</td>\n",
       "      <td>[(I, met), (met, my), (my, friend), (friend, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>am8</td>\n",
       "      <td>7506</td>\n",
       "      <td>Ten years ago, I met a women on the train betw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Ten, years, ago, ,, I, met, a, women, on, the...</td>\n",
       "      <td>[(Ten, years), (years, ago), (ago, ,), (,, I),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>dk5</td>\n",
       "      <td>7507</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[In, my, country, we, usually, do, n't, use, t...</td>\n",
       "      <td>[(In, my), (my, country), (country, we), (we, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>dk5</td>\n",
       "      <td>7507</td>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, organized, the, instructions, by, time, .]</td>\n",
       "      <td>[(I, organized), (organized, the), (the, instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>ad1</td>\n",
       "      <td>7508</td>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\r\\r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[First, ,, prepare, a, port, ,, loose, tea, ,,...</td>\n",
       "      <td>[(First, ,), (,, prepare), (prepare, a), (a, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id anon_id  user_file_id  \\\n",
       "answer_id                                      \n",
       "1                    5     eq0          7505   \n",
       "2                    5     am8          7506   \n",
       "3                   12     dk5          7507   \n",
       "4                   13     dk5          7507   \n",
       "5                   12     ad1          7508   \n",
       "\n",
       "                                                        text directory  \\\n",
       "answer_id                                                                \n",
       "1          I met my friend Nife while I was studying in a...       NaN   \n",
       "2          Ten years ago, I met a women on the train betw...       NaN   \n",
       "3          In my country we usually don't use tea bags. F...       NaN   \n",
       "4                      I organized the instructions by time.       NaN   \n",
       "5          First, prepare a port, loose tea, and cup.\\r\\r...       NaN   \n",
       "\n",
       "           is_doublespaced  is_plagiarized  is_deleted  \\\n",
       "answer_id                                                \n",
       "1                        0               0           0   \n",
       "2                        0               0           0   \n",
       "3                        0               0           0   \n",
       "4                        0               0           0   \n",
       "5                        0               0           0   \n",
       "\n",
       "                                                        toks  \\\n",
       "answer_id                                                      \n",
       "1          [I, met, my, friend, Nife, while, I, was, stud...   \n",
       "2          [Ten, years, ago, ,, I, met, a, women, on, the...   \n",
       "3          [In, my, country, we, usually, do, n't, use, t...   \n",
       "4             [I, organized, the, instructions, by, time, .]   \n",
       "5          [First, ,, prepare, a, port, ,, loose, tea, ,,...   \n",
       "\n",
       "                                                     bigrams  \n",
       "answer_id                                                     \n",
       "1          [(I, met), (met, my), (my, friend), (friend, N...  \n",
       "2          [(Ten, years), (years, ago), (ago, ,), (,, I),...  \n",
       "3          [(In, my), (my, country), (country, we), (we, ...  \n",
       "4          [(I, organized), (organized, the), (the, instr...  \n",
       "5          [(First, ,), (,, prepare), (prepare, a), (a, p...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mini-test to make sure I am creating bigrams correctly\n",
    "\n",
    "bigram_test = answer_df.toks[1]\n",
    "bigram_test\n",
    "list(nltk.bigrams(bigram_test))\n",
    "\n",
    "#test works, let's try on dataframe\n",
    "\n",
    "answer_df['bigrams'] = answer_df.toks.apply(lambda x: list(nltk.bigrams(x)))\n",
    "answer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create frequency dictionary for entire corpus ###\n",
    "\n",
    "Attempting to create frequency dictionary for all toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'in': 15, '.': 12, 'the': 11, 'I': 10, 'school': 9, 'to': 6, ',': 6, 'was': 5, 'studying': 5, 'high': 5, ...})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdict = nltk.FreqDist(answer_df.toks[1])\n",
    "testdict\n",
    "#looks ok, now to apply to the whole column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answer_id\n",
       "1    {'I': 10, 'met': 2, 'my': 4, 'friend': 2, 'Nif...\n",
       "2    {'Ten': 1, 'years': 1, 'ago': 1, ',': 8, 'I': ...\n",
       "3    {'In': 1, 'my': 1, 'country': 1, 'we': 5, 'usu...\n",
       "4    {'I': 1, 'organized': 1, 'the': 1, 'instructio...\n",
       "5    {'First': 1, ',': 9, 'prepare': 1, 'a': 2, 'po...\n",
       "Name: toks, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdict = answer_df.toks.apply(lambda x: nltk.FreqDist(x))\n",
    "fdict.head()\n",
    "#haha they are mini-dicts for each text rather than for the dataframe as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I met my friend Nife while I was studying in a middle school. I was happy when I met him because he '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['I', 'met', 'my', 'friend', 'Nife', 'while', 'I', 'was', 'studying', 'in', 'a', 'middle', 'school', '.', 'I', 'was', 'happy', 'when', 'I', 'met']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_corpus = ' '.join(answer_df['text'])\n",
    "answer_corpus[:100]\n",
    "answer_corpus_tok = nltk.word_tokenize(answer_corpus)\n",
    "answer_corpus_tok[:20]\n",
    "\n",
    "#probably not the most efficient way but it seems to have worked at least for tokenizing whole corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'.': 264755, ',': 218149, 'the': 171927, 'to': 133262, 'and': 105988, 'I': 93236, 'a': 89283, 'of': 88552, 'in': 77170, 'is': 75659, ...})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_dict = nltk.FreqDist(answer_corpus_tok)\n",
    "answer_dict\n",
    "\n",
    "#success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create frequency dictionary for bigrams of entire corpus ###\n",
    "\n",
    "Attempting to create frequency dictionary for all bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'met'), ('met', 'my'), ('my', 'friend'), ('friend', 'Nife'), ('Nife', 'while'), ('while', 'I'), ('I', 'was'), ('was', 'studying'), ('studying', 'in'), ('in', 'a')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's try to do this from the answer_corpus_tok\n",
    "\n",
    "answer_corpus_bigrams = list(nltk.bigrams(answer_corpus_tok))\n",
    "answer_corpus_bigrams[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('.', 'I'): 24177, (',', 'I'): 21399, ('in', 'the'): 18669, ('.', 'The'): 17403, (',', 'and'): 16701, ('of', 'the'): 15011, ('.', 'In'): 13393, (',', 'the'): 12288, ('.', 'It'): 9348, ('to', 'the'): 8553, ...})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ok, now time for the dictionary\n",
    "answer_bigram_dict = nltk.FreqDist(answer_corpus_bigrams)\n",
    "answer_bigram_dict\n",
    "\n",
    "#success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Progress-report 2\n",
    "\n",
    "The following is everything that has been completed since Progress Report 2.  See progress_report.MD for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next goals:\n",
    "Create another DF called bigrams_df with bigrams, MI scores, occurences per million score, and perhaps more to bge added later. To do so:  \n",
    "1) Create function for calculating MI \n",
    "2) Create function for calculating occurences per million for unigrams and bigrams  \n",
    "3) Apply the MI formula for pairs of words in the bigram list and create a column in the new DF  \n",
    "4) Apply the occurences per million for bigrams and create a column in the new DF  \n",
    "5) Create a column showing percentage of time the bigrams are used by the three proficiency levels  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Mutual Information (MI)\n",
    "\n",
    "(from https://corpus.byu.edu/mutualInformation.asp)  \n",
    "\n",
    "Mutual Information is calculated as follows:  \n",
    "MI = log ( (AB * sizeCorpus) / (A * B * span) ) / log (2)  \n",
    "\n",
    "Suppose we are calculating the MI for the collocate color near purple in BYU-BNC.  \n",
    "\n",
    "A = frequency of node word (e.g. purple): 1262  \n",
    "B = frequency of collocate (e.g. color): 115  \n",
    "AB = frequency of collocate near the node word (e.g. color near purple): 24  \n",
    "sizeCorpus= size of corpus (# words; in this case the BNC): 96,263,399  \n",
    "span = span of words (e.g. 3 to left and 3 to right of node word): 6  \n",
    "log (2) is literally the log10 of the number 2: .30103  \n",
    "\n",
    "MI = 11.37 = log ( (24 * 96,263,399) / (1262 * 115 * 6) ) / .30103  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Found something called 'Pointwise Mutual Information' - I believe it is what I am looking for.\n",
    "\n",
    "import math\n",
    "from math import log\n",
    "\n",
    "def MI(word1, word2):\n",
    "  prob_word1 = answer_dict[word1] / float(sum(answer_dict.values()))\n",
    "  prob_word2 = answer_dict[word2] / float(sum(answer_dict.values()))\n",
    "  prob_word1_word2 = answer_bigram_dict[word1, word2] / float(sum(answer_bigram_dict.values()))\n",
    "  return math.log(prob_word1_word2/float(prob_word1*prob_word2),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1605"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24516"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#something I imagine has an average MI\n",
    "answer_bigram_dict['young', 'people']\n",
    "answer_dict['young']\n",
    "answer_dict['people']\n",
    "\n",
    "#Yes - 'young' collocates strongly with 'people' (about 25% of time) but 'people' doesn't collocate strongly with 'young'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.840354713355728"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MI('young','people')\n",
    "\n",
    "#That is the standard range for a M1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "171927"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1547"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.1986947748534735"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Time to try one that shouldn't have as high MI, e.g. 'man' with 'the'\n",
    "\n",
    "answer_bigram_dict['the', 'man']\n",
    "answer_dict['the']\n",
    "answer_dict['man']\n",
    "\n",
    "MI('the', 'man')\n",
    "\n",
    "#With a smoothing of MI3, this would not show up on collocation lists (a good thing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating combined dataframe for easier analysis and viewing\n",
    "- joins answer_df, user_df, and course_df\n",
    "- removes unnecessary columns\n",
    "- narrows results down to only answers from writing classes and first versions of their work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#join answer_df and user_df along 'user_file_id' column\n",
    "combo_df = answer_df.join(user_df, on='user_file_id', lsuffix='user_file_id')\n",
    "\n",
    "#now join this new df with course_df along 'course_id' column\n",
    "combo_df = combo_df.join(course_df, on='course_id', lsuffix='user_file_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping unnecessary columns (there a lot)\n",
    "combo_df = combo_df.drop(['directoryuser_file_id', 'is_doublespaced', 'is_plagiarized', 'is_deleteduser_file_id',\n",
    "                            'modifiedby', 'modifieddate', 'allow_submit_after_duedate', 'anon_id', 'file_type_id',\n",
    "                            'file_info_id', 'user_file_parent_id', 'createdby', 'session_id',\n",
    "                           'document_id','filename', 'content_text', 'createddate', 'allow_multiple_accesses',\n",
    "                           'directoryuser_file_id', 'is_doublespaced', 'is_plagiarized', 'is_deleteduser_file_id',\n",
    "                           'modifiedby', 'modifieddate', 'allow_submit_after_duedate','activity', 'order_num', \n",
    "                            'due_date', 'post_date', 'assignment_name', 'directory', 'activity', 'semester',\n",
    "                            'order_num', 'due_date', 'post_date', 'assignment_name', 'allow_double_spacing',\n",
    "                           'duration', 'pull_off_date', 'direction', 'grammar_qp_id', 'is_deleted',\n",
    "                            'section', 'course_description'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping only 1st versions of students' work\n",
    "combo_df = combo_df.loc[combo_df['version'] == 1]\n",
    "\n",
    "#'version' column now unnecessary\n",
    "combo_df = combo_df.drop(['version'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keeping only answers from writing classes (class_id = 2)\n",
    "combo_df = combo_df.loc[combo_df['class_id'] == 2]\n",
    "\n",
    "#'class_id' column now unnecessary\n",
    "combo_df = combo_df.drop(['class_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>bigrams</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>7507</td>\n",
       "      <td>dk5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>[In, my, country, we, usually, do, n't, use, t...</td>\n",
       "      <td>[(In, my), (my, country), (country, we), (we, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>7507</td>\n",
       "      <td>dk5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "      <td>[I, organized, the, instructions, by, time, .]</td>\n",
       "      <td>[(I, organized), (organized, the), (the, instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>7508</td>\n",
       "      <td>ad1</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\r\\r...</td>\n",
       "      <td>[First, ,, prepare, a, port, ,, loose, tea, ,,...</td>\n",
       "      <td>[(First, ,), (,, prepare), (prepare, a), (a, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>7508</td>\n",
       "      <td>ad1</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>By time</td>\n",
       "      <td>[By, time]</td>\n",
       "      <td>[(By, time)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>7509</td>\n",
       "      <td>eg5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>First, prepare your cup, loose tea or bag tea,...</td>\n",
       "      <td>[First, ,, prepare, your, cup, ,, loose, tea, ...</td>\n",
       "      <td>[(First, ,), (,, prepare), (prepare, your), (y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id  user_file_id anon_id  level_id  course_id  \\\n",
       "answer_id                                                           \n",
       "3                   12          7507     dk5         4        115   \n",
       "4                   13          7507     dk5         4        115   \n",
       "5                   12          7508     ad1         4        115   \n",
       "6                   13          7508     ad1         4        115   \n",
       "7                   12          7509     eg5         4        115   \n",
       "\n",
       "                                                        text  \\\n",
       "answer_id                                                      \n",
       "3          In my country we usually don't use tea bags. F...   \n",
       "4                      I organized the instructions by time.   \n",
       "5          First, prepare a port, loose tea, and cup.\\r\\r...   \n",
       "6                                                    By time   \n",
       "7          First, prepare your cup, loose tea or bag tea,...   \n",
       "\n",
       "                                                        toks  \\\n",
       "answer_id                                                      \n",
       "3          [In, my, country, we, usually, do, n't, use, t...   \n",
       "4             [I, organized, the, instructions, by, time, .]   \n",
       "5          [First, ,, prepare, a, port, ,, loose, tea, ,,...   \n",
       "6                                                 [By, time]   \n",
       "7          [First, ,, prepare, your, cup, ,, loose, tea, ...   \n",
       "\n",
       "                                                     bigrams  \n",
       "answer_id                                                     \n",
       "3          [(In, my), (my, country), (country, we), (we, ...  \n",
       "4          [(I, organized), (organized, the), (the, instr...  \n",
       "5          [(First, ,), (,, prepare), (prepare, a), (a, p...  \n",
       "6                                               [(By, time)]  \n",
       "7          [(First, ,), (,, prepare), (prepare, your), (y...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just change the order of columns to something more logical and rename some columns\n",
    "combo_df = combo_df[['question_id','user_file_id', 'anon_iduser_file_id', 'level_id', 'course_id', 'text', 'toks', 'bigrams']]\n",
    "combo_df.rename(columns={'anon_iduser_file_id':'anon_id'}, inplace=True)\n",
    "\n",
    "#finished result =  much cleaner\n",
    "combo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function for calculating occurrences per million for unigrams and bigrams  \n",
    "\n",
    "Formula:\n",
    "\n",
    "FN = FO(1,000,000) / C\n",
    "\n",
    "FN = normalized frequency\n",
    "FO = observed frequency\n",
    "C = corpus size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2553650"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2553649"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total number of unigrams\n",
    "total_unigrams = len(combo_corpus_tok)\n",
    "\n",
    "#total number of bigrams\n",
    "total_bigrams = len(combo_corpus_bigrams)\n",
    "\n",
    "total_unigrams\n",
    "total_bigrams\n",
    "\n",
    "#different by one a bigrams will be naturally be unigrams - 1 (for the first one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new freq dicts for combo_df (unigrams and bigrams) using same \n",
    "#code as earlier versions with answer_df\n",
    "\n",
    "combo_corpus = ' '.join(combo_df['text'])\n",
    "combo_corpus_tok = nltk.word_tokenize(combo_corpus)\n",
    "combo_unigram_dict = nltk.FreqDist(combo_corpus_tok)\n",
    "\n",
    "combo_corpus_bigrams = list(nltk.bigrams(combo_corpus_tok))\n",
    "combo_bigram_dict = nltk.FreqDist(combo_corpus_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function where you enter the unigram and it tells \n",
    "#you the frequency in the corpus per million tokens\n",
    "\n",
    "def unigram_per_M(unigram):\n",
    "   return (combo_unigram_dict[unigram]*1000000) / total_unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97163"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "38048.675425371526"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "38048.675425371526"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test manually and with defined function\n",
    "combo_unigram_dict['the']\n",
    "\n",
    "(97163*1000000)/2553650\n",
    "unigram_per_M('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function where you enter the bigram and it tells \n",
    "#you the frequency in the corpus per million tokens\n",
    "\n",
    "def bigram_per_M(word1, word2):\n",
    "   return (combo_bigram_dict[word1, word2]*1000000) / total_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "29.369737187843747"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "29.369737187843747"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test manually and with defined function\n",
    "combo_bigram_dict['the', 'man']\n",
    "\n",
    "(75*1000000)/2553649\n",
    "bigram_per_M('the', 'man')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a bigram_df showing relevant info based on above formulas\n",
    "- columns for this dataframe:\n",
    "    - default index\n",
    "    - bigrams\n",
    "    - MI scores\n",
    "    - occurrences per million\n",
    "    - normalized percentage used at each proficiency level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(In, my)</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(my, country)</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(country, we)</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(we, usually)</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(usually, do)</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bigram  tokens\n",
       "0       (In, my)     808\n",
       "1  (my, country)     825\n",
       "2  (country, we)      17\n",
       "3  (we, usually)      49\n",
       "4  (usually, do)      55"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_df = pd.DataFrame.from_dict(combo_bigram_dict,orient='index')\n",
    "bigram_df = bigram_df.reset_index()\n",
    "bigram_df = bigram_df.rename(columns = {0:'tokens', 'index': 'bigram'})\n",
    "bigram_df.head()\n",
    "\n",
    "#first two bullet points complete - now to add more columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing bigram tuples to lists for easier manipulation\n",
    "bigram_df['bigram'] = [list(x) for x in bigram_df['bigram']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating MI column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#New MI calculator based on new dictionary\n",
    "\n",
    "def MI(word1, word2):\n",
    "  prob_word1 = combo_unigram_dict[word1] / float(sum(combo_unigram_dict.values()))\n",
    "  prob_word2 = combo_unigram_dict[word2] / float(sum(combo_unigram_dict.values()))\n",
    "  prob_word1_word2 = combo_bigram_dict[word1, word2] / float(sum(combo_bigram_dict.values()))\n",
    "  return math.log(prob_word1_word2/float(prob_word1*prob_word2),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.052017460488083"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = bigram_df.iloc[0][0]\n",
    "MI(test[0], test[1])\n",
    "\n",
    "#it works on one cell, so theoretically should work on all..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bigram_df['MI'] = [MI(x[0], x[1]) for x in bigram_df['bigram']]\n",
    "\n",
    "#it took a few hours to run it, but it worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>tokens</th>\n",
       "      <th>MI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[In, my]</td>\n",
       "      <td>808</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[my, country]</td>\n",
       "      <td>825</td>\n",
       "      <td>5.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[country, we]</td>\n",
       "      <td>17</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[we, usually]</td>\n",
       "      <td>49</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[usually, do]</td>\n",
       "      <td>55</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bigram  tokens    MI\n",
       "0       [In, my]     808  4.05\n",
       "1  [my, country]     825  5.59\n",
       "2  [country, we]      17  0.66\n",
       "3  [we, usually]      49  3.17\n",
       "4  [usually, do]      55  3.38"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_df[['MI']] = bigram_df[['MI']].apply(lambda x: pd.Series.round(x, 2))\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating per_million column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316.4099686370366"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing one one cell first\n",
    "bigram_per_M(test[0], test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_df['per_million'] = [bigram_per_M(x[0], x[1]) for x in bigram_df['bigram']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>tokens</th>\n",
       "      <th>MI</th>\n",
       "      <th>per_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[In, my]</td>\n",
       "      <td>808</td>\n",
       "      <td>4.05</td>\n",
       "      <td>316.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[my, country]</td>\n",
       "      <td>825</td>\n",
       "      <td>5.59</td>\n",
       "      <td>323.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[country, we]</td>\n",
       "      <td>17</td>\n",
       "      <td>0.66</td>\n",
       "      <td>6.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[we, usually]</td>\n",
       "      <td>49</td>\n",
       "      <td>3.17</td>\n",
       "      <td>19.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[usually, do]</td>\n",
       "      <td>55</td>\n",
       "      <td>3.38</td>\n",
       "      <td>21.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bigram  tokens    MI  per_million\n",
       "0       [In, my]     808  4.05       316.41\n",
       "1  [my, country]     825  5.59       323.07\n",
       "2  [country, we]      17  0.66         6.66\n",
       "3  [we, usually]      49  3.17        19.19\n",
       "4  [usually, do]      55  3.38        21.54"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_df[['per_million']] = bigram_df[['per_million']].apply(lambda x: pd.Series.round(x, 2))\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating %\\_per_level column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create level dataframes\n",
    "level_3 = combo_df.loc[combo_df['level_id'] == 3, :] \n",
    "level_4 = combo_df.loc[combo_df['level_id'] == 4, :] \n",
    "level_5 = combo_df.loc[combo_df['level_id'] == 5, :] \n",
    "\n",
    "#create frequency dictionaries for each level\n",
    "level_3_corpus = ' '.join(level_3['text'])\n",
    "level_3_tok = nltk.word_tokenize(level_3_corpus)\n",
    "level_3_bigrams = list(nltk.bigrams(level_3_tok))\n",
    "level_3_bigram_dict = nltk.FreqDist(level_3_bigrams)\n",
    "\n",
    "level_4_corpus = ' '.join(level_4['text'])\n",
    "level_4_tok = nltk.word_tokenize(level_4_corpus)\n",
    "level_4_bigrams = list(nltk.bigrams(level_4_tok))\n",
    "level_4_bigram_dict = nltk.FreqDist(level_4_bigrams)\n",
    "\n",
    "level_5_corpus = ' '.join(level_5['text'])\n",
    "level_5_tok = nltk.word_tokenize(level_5_corpus)\n",
    "level_5_bigrams = list(nltk.bigrams(level_5_tok))\n",
    "level_5_bigram_dict = nltk.FreqDist(level_5_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('.', 'I'): 1708, (',', 'I'): 1467, ('.', 'The'): 1254, ('in', 'the'): 1209, (',', 'and'): 1119, ('of', 'the'): 894, ('.', 'In'): 890, (',', 'the'): 785, ('is', 'a'): 729, (',', 'you'): 709, ...})"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({('in', 'the'): 10087, (',', 'and'): 9824, ('.', 'The'): 9741, ('of', 'the'): 9030, ('.', 'In'): 8533, (',', 'I'): 8147, (',', 'the'): 8050, ('.', 'I'): 7541, ('.', 'It'): 5106, ('.', 'For'): 4660, ...})"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.11985724199464658"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'11.99%'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'11.99%'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'40.71%'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'47.15%'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test to see what I want in each cell in the level_3 column\n",
    "level_3_bigram_dict #I need the values from this dictionary divided by the value from\n",
    "combo_bigram_dict #this dictionary\n",
    "\n",
    "#for example\n",
    "level_3_bigram_dict['in', 'the'] / combo_bigram_dict['in', 'the'] \n",
    "\n",
    "#or better yet as a percentage\n",
    "\"{0:.2f}%\".format(level_3_bigram_dict['in', 'the'] / combo_bigram_dict['in', 'the'] * 100)\n",
    "\n",
    "#totals for all 3 levels should add up to 100%\n",
    "\"{0:.2f}%\".format(level_3_bigram_dict['in', 'the'] / combo_bigram_dict['in', 'the'] * 100)\n",
    "\"{0:.2f}%\".format(level_4_bigram_dict['in', 'the'] / combo_bigram_dict['in', 'the'] * 100)\n",
    "\"{0:.2f}%\".format(level_5_bigram_dict['in', 'the'] / combo_bigram_dict['in', 'the'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2671149144254279"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3767573349633252"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3266350855745721"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#also necessary to normalize as different number of responses at each level\n",
    "\n",
    "#weighting for each level\n",
    "level_3_percent = len(level_3.index) / len(combo_df.index)\n",
    "level_4_percent = len(level_4.index) / len(combo_df.index)\n",
    "level_5_percent = len(level_5.index) / len(combo_df.index)\n",
    "\n",
    "level_3_percent\n",
    "level_4_percent\n",
    "level_5_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "968.825794621027"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.09604697081600347"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'9.60%'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of normalizing with ['in', 'the'] bigram\n",
    "\n",
    "#normalized number\n",
    "level_3_bigram_dict['in', 'the'] * (level_3_percent/(1/3)) \n",
    "\n",
    "#applied \n",
    "level_3_bigram_dict['in', 'the'] * (level_3_percent/(1/3)) / combo_bigram_dict['in', 'the']\n",
    "\n",
    "#as a percent\n",
    "\"{0:.2f}%\".format(level_3_bigram_dict['in', 'the'] * (level_3_percent/(1/3)) / combo_bigram_dict['in', 'the']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9.60%'"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'46.01%'"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'46.20%'"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a function for the above\n",
    "def norm_percent_level3(word1, word2):\n",
    "    return \"{0:.2f}%\".format(level_3_bigram_dict[word1, word2] * (level_3_percent/(1/3)) / combo_bigram_dict[word1, word2]*100)\n",
    "\n",
    "def norm_percent_level4(word1, word2):\n",
    "    return \"{0:.2f}%\".format(level_4_bigram_dict[word1, word2] * (level_4_percent/(1/3)) / combo_bigram_dict[word1, word2]*100)\n",
    "\n",
    "def norm_percent_level5(word1, word2):\n",
    "    return \"{0:.2f}%\".format(level_5_bigram_dict[word1, word2] * (level_5_percent/(1/3)) / combo_bigram_dict[word1, word2]*100)\n",
    "\n",
    "norm_percent_level3('in', 'the')\n",
    "norm_percent_level4('in', 'the')\n",
    "norm_percent_level5('in', 'the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>tokens</th>\n",
       "      <th>MI</th>\n",
       "      <th>per_million</th>\n",
       "      <th>level_3</th>\n",
       "      <th>level_4</th>\n",
       "      <th>level_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[In, my]</td>\n",
       "      <td>808</td>\n",
       "      <td>4.05</td>\n",
       "      <td>316.41</td>\n",
       "      <td>9.32%</td>\n",
       "      <td>64.77%</td>\n",
       "      <td>30.32%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[my, country]</td>\n",
       "      <td>825</td>\n",
       "      <td>5.59</td>\n",
       "      <td>323.07</td>\n",
       "      <td>14.18%</td>\n",
       "      <td>51.65%</td>\n",
       "      <td>35.40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[country, we]</td>\n",
       "      <td>17</td>\n",
       "      <td>0.66</td>\n",
       "      <td>6.66</td>\n",
       "      <td>4.71%</td>\n",
       "      <td>79.78%</td>\n",
       "      <td>23.06%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[we, usually]</td>\n",
       "      <td>49</td>\n",
       "      <td>3.17</td>\n",
       "      <td>19.19</td>\n",
       "      <td>9.81%</td>\n",
       "      <td>78.43%</td>\n",
       "      <td>18.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[usually, do]</td>\n",
       "      <td>55</td>\n",
       "      <td>3.38</td>\n",
       "      <td>21.54</td>\n",
       "      <td>2.91%</td>\n",
       "      <td>63.71%</td>\n",
       "      <td>35.63%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bigram  tokens    MI  per_million level_3 level_4 level_5\n",
       "0       [In, my]     808  4.05       316.41   9.32%  64.77%  30.32%\n",
       "1  [my, country]     825  5.59       323.07  14.18%  51.65%  35.40%\n",
       "2  [country, we]      17  0.66         6.66   4.71%  79.78%  23.06%\n",
       "3  [we, usually]      49  3.17        19.19   9.81%  78.43%  18.00%\n",
       "4  [usually, do]      55  3.38        21.54   2.91%  63.71%  35.63%"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's see what it looks like if applied to the whole dataframe\n",
    "\n",
    "bigram_df['level_3'] = [norm_percent_level3(x[0], x[1]) for x in bigram_df['bigram']]\n",
    "bigram_df['level_4'] = [norm_percent_level4(x[0], x[1]) for x in bigram_df['bigram']]\n",
    "bigram_df['level_5'] = [norm_percent_level5(x[0], x[1]) for x in bigram_df['bigram']]\n",
    "\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A lot of work for a very small final dataframe, but at least it should be usable for machine analysis and future research."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next goals (for final submission of code):  \n",
    "<br>\n",
    "_Final analysis touch ups_:\n",
    "-\tDeal with capitalization issues skewing data\n",
    "-\tRemove levels from combo_df other than 3,4,5 (easy to do but need time to re-run whole script afterwards)\n",
    "\n",
    "\n",
    "_Machine learning_:\n",
    "- Predict level based on bigram frequency (types and tokens)\n",
    "- Predict level based on MI of bigrams used \n",
    "\n",
    "\n",
    "_Visualizations_:\n",
    "- Create visualizations (heat maps for predictions and bar graphs for observed stats)\n",
    "- Sort bigram_df in different orders to produce tables of common bigrams\n",
    "- Tidy up notebook / add descriptive detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
