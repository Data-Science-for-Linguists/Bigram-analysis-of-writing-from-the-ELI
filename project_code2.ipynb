{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project_Code 2: Continued clean up and analysis of ELI Data #\n",
    "## Ben Naismith ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes since 'Project_Code1' ###\n",
    "\n",
    "This new document has been created as a number of significant changes have been made to the original code. Based on discussions with other members of the ELI Data Mining Group, the following points were determined:\n",
    "\n",
    "- For the sake of efficiency, it is better not to merge the different data frames into one big one\n",
    "- A 'sanitization' step of the data was completed which duplicated some of the steps of my initial code. These duplications include removing unwanted apostrophes, changing all 'null' and 'ull' to NaN, and removing empty or unreal students (who were most likely teachers). As such, the dataset is now ready for more in-depth cleaning and analysis, i.e. the purpose of this notebook. The code for the sanitization step is in a private repository of the ELI Data Mining Groups 'convert_0_to_1.ipynb'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sharing Plan ###\n",
    "\n",
    "The full ELI data set (see project_plan.md) is private at this time. Below is a workbook with the current code for organizing and cleaning that data. In order to see how the code works, snippets of data have been displayed throughout.\n",
    "\n",
    "This notebook will continue to be updated until the project is ready, at which point a sample of raw data, e.g. a CSV of 1000 answers, will be included in the repository to allow for testing and reproducibility by others of the code. The exact method for sampling will be determined once the initial code is complete, as it is necessary to first have cleaner data before it can be sampled; at present, sampling results in errors due to false students, entries, etc. which can not be linked to the appropriate CSV files.\n",
    "\n",
    "Ultimately, it is the intention of the dataset's authors for the entire dataset to be made public, with a CC license. Please see the LICENSE.md for details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setup ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "#Import necesary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%pprint #turn off pretty printing\n",
    "\n",
    "#return every shell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#Create short-hand for directory root\n",
    "cor_dir = \"/Users/Benjamin's/Documents/ELI_Data_Mining/Data-Archive/1_sanitized/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student information (S_info_csv and S_info_df) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>native_language</th>\n",
       "      <th>language_used_at_home</th>\n",
       "      <th>language_used_at_home_now</th>\n",
       "      <th>non_native_language_1</th>\n",
       "      <th>yrs_of_study_lang1</th>\n",
       "      <th>study_in_classroom_lang1</th>\n",
       "      <th>ways_of_study_lang1</th>\n",
       "      <th>non_native_language_2</th>\n",
       "      <th>yrs_of_study_lang2</th>\n",
       "      <th>study_in_classroom_lang2</th>\n",
       "      <th>ways_of_study_lang2</th>\n",
       "      <th>non_native_language_3</th>\n",
       "      <th>yrs_of_study_lang3</th>\n",
       "      <th>study_in_classroom_lang3</th>\n",
       "      <th>ways_of_study_lang3</th>\n",
       "      <th>createddate</th>\n",
       "      <th>modifieddate</th>\n",
       "      <th>course_history</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anon_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ez9</th>\n",
       "      <td>Male</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Studied...</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Studied by myself</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2006-01-30 15:07:18</td>\n",
       "      <td>2006-03-14 15:13:37</td>\n",
       "      <td>6;12;18;24;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gm3</th>\n",
       "      <td>Male</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Had a native-speaker teacher;S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2006-01-30 15:07:28</td>\n",
       "      <td>2006-03-14 15:12:49</td>\n",
       "      <td>6;12;24;30;38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fg5</th>\n",
       "      <td>Male</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>Nepali</td>\n",
       "      <td>Nepali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Had a n...</td>\n",
       "      <td>French</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Had a n...</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Studied by myself</td>\n",
       "      <td>2006-01-30 15:07:45</td>\n",
       "      <td>2006-03-14 15:11:36</td>\n",
       "      <td>18;24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ce5</th>\n",
       "      <td>Female</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Had a n...</td>\n",
       "      <td>German</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Listened to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2006-01-30 15:07:49</td>\n",
       "      <td>2006-03-14 15:12:24</td>\n",
       "      <td>6;12;24;30;38;56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fi7</th>\n",
       "      <td>Female</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean;Japanese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Had a native-speaker teacher;S...</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Listened to...</td>\n",
       "      <td>French</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Listened to...</td>\n",
       "      <td>2006-01-30 15:07:52</td>\n",
       "      <td>2006-03-14 15:12:17</td>\n",
       "      <td>6;12;24;30;38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gender  birth_year native_language language_used_at_home  \\\n",
       "anon_id                                                             \n",
       "ez9        Male      1978.0          Arabic                Arabic   \n",
       "gm3        Male      1980.0          Arabic                Arabic   \n",
       "fg5        Male      1938.0          Nepali                Nepali   \n",
       "ce5      Female      1984.0          Korean                Korean   \n",
       "fi7      Female      1982.0          Korean       Korean;Japanese   \n",
       "\n",
       "        language_used_at_home_now non_native_language_1 yrs_of_study_lang1  \\\n",
       "anon_id                                                                      \n",
       "ez9                           NaN               English  more than 5 years   \n",
       "gm3                           NaN               English  more than 5 years   \n",
       "fg5                           NaN               English  more than 5 years   \n",
       "ce5                           NaN               English  more than 5 years   \n",
       "fi7                           NaN               English  more than 5 years   \n",
       "\n",
       "         study_in_classroom_lang1  \\\n",
       "anon_id                             \n",
       "ez9                           1.0   \n",
       "gm3                           1.0   \n",
       "fg5                           1.0   \n",
       "ce5                           1.0   \n",
       "fi7                           1.0   \n",
       "\n",
       "                                       ways_of_study_lang1  \\\n",
       "anon_id                                                      \n",
       "ez9      Studied grammar;Worked in pairs/groups;Studied...   \n",
       "gm3      Studied grammar;Had a native-speaker teacher;S...   \n",
       "fg5      Studied grammar;Worked in pairs/groups;Had a n...   \n",
       "ce5      Studied grammar;Worked in pairs/groups;Had a n...   \n",
       "fi7      Studied grammar;Had a native-speaker teacher;S...   \n",
       "\n",
       "        non_native_language_2 yrs_of_study_lang2  study_in_classroom_lang2  \\\n",
       "anon_id                                                                      \n",
       "ez9                   Turkish   less than 1 year                       0.0   \n",
       "gm3                       NaN                NaN                       0.0   \n",
       "fg5                    French   less than 1 year                       1.0   \n",
       "ce5                    German          1-2 years                       1.0   \n",
       "fi7                  Japanese   less than 1 year                       1.0   \n",
       "\n",
       "                                       ways_of_study_lang2  \\\n",
       "anon_id                                                      \n",
       "ez9                                      Studied by myself   \n",
       "gm3                                                  other   \n",
       "fg5      Studied grammar;Worked in pairs/groups;Had a n...   \n",
       "ce5      Studied grammar;Studied vocabulary;Listened to...   \n",
       "fi7      Studied grammar;Studied vocabulary;Listened to...   \n",
       "\n",
       "        non_native_language_3 yrs_of_study_lang3  study_in_classroom_lang3  \\\n",
       "anon_id                                                                      \n",
       "ez9                       NaN                NaN                       0.0   \n",
       "gm3                       NaN                NaN                       0.0   \n",
       "fg5                     Hindi  more than 5 years                       0.0   \n",
       "ce5                       NaN                NaN                       0.0   \n",
       "fi7                    French          1-2 years                       1.0   \n",
       "\n",
       "                                       ways_of_study_lang3  \\\n",
       "anon_id                                                      \n",
       "ez9                                                  other   \n",
       "gm3                                                  other   \n",
       "fg5                                      Studied by myself   \n",
       "ce5                                                  other   \n",
       "fi7      Studied grammar;Studied vocabulary;Listened to...   \n",
       "\n",
       "                 createddate         modifieddate    course_history  \n",
       "anon_id                                                              \n",
       "ez9      2006-01-30 15:07:18  2006-03-14 15:13:37     6;12;18;24;30  \n",
       "gm3      2006-01-30 15:07:28  2006-03-14 15:12:49     6;12;24;30;38  \n",
       "fg5      2006-01-30 15:07:45  2006-03-14 15:11:36             18;24  \n",
       "ce5      2006-01-30 15:07:49  2006-03-14 15:12:24  6;12;24;30;38;56  \n",
       "fi7      2006-01-30 15:07:52  2006-03-14 15:12:17     6;12;24;30;38  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>native_language</th>\n",
       "      <th>language_used_at_home</th>\n",
       "      <th>language_used_at_home_now</th>\n",
       "      <th>non_native_language_1</th>\n",
       "      <th>yrs_of_study_lang1</th>\n",
       "      <th>study_in_classroom_lang1</th>\n",
       "      <th>ways_of_study_lang1</th>\n",
       "      <th>non_native_language_2</th>\n",
       "      <th>yrs_of_study_lang2</th>\n",
       "      <th>study_in_classroom_lang2</th>\n",
       "      <th>ways_of_study_lang2</th>\n",
       "      <th>non_native_language_3</th>\n",
       "      <th>yrs_of_study_lang3</th>\n",
       "      <th>study_in_classroom_lang3</th>\n",
       "      <th>ways_of_study_lang3</th>\n",
       "      <th>createddate</th>\n",
       "      <th>modifieddate</th>\n",
       "      <th>course_history</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anon_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hb0</th>\n",
       "      <td>Female</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>English</td>\n",
       "      <td>3-5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Had a native-speaker teacher;T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:09:38</td>\n",
       "      <td>2011-06-20 14:13:01</td>\n",
       "      <td>851;869;870;871;872;923;942;944;945;946;1008;1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dp8</th>\n",
       "      <td>Male</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>English</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Had a n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:10:15</td>\n",
       "      <td>2011-06-20 14:13:57</td>\n",
       "      <td>868;869;870;871;872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bn6</th>\n",
       "      <td>Male</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Teacher spo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:11:17</td>\n",
       "      <td>2011-06-20 14:15:51</td>\n",
       "      <td>860;861;862;871;872;930;947;948;949;951;998;99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aq6</th>\n",
       "      <td>Female</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-09-14 14:05:38</td>\n",
       "      <td>2012-09-14 14:09:19</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fm3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-09-17 17:12:46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1034;1035;1036;1037;1038;1099;1100;1101;1102;1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ey5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-04-11 13:28:41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-06-20 13:12:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-07-12 16:25:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1074;1075;1076;1077;1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gf3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-11-21 13:42:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gl8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-10-23 14:14:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gender  birth_year native_language language_used_at_home  \\\n",
       "anon_id                                                             \n",
       "hb0      Female      1980.0          Arabic                Arabic   \n",
       "dp8        Male      1991.0          Arabic        Arabic;English   \n",
       "bn6        Male      1986.0          Arabic        Arabic;English   \n",
       "aq6      Female      1964.0         English               English   \n",
       "fm3         NaN         NaN             NaN                   NaN   \n",
       "ey5         NaN         NaN             NaN                   NaN   \n",
       "gb5         NaN         NaN             NaN                   NaN   \n",
       "aa7         NaN         NaN             NaN                   NaN   \n",
       "gf3         NaN         NaN             NaN                   NaN   \n",
       "gl8         NaN         NaN             NaN                   NaN   \n",
       "\n",
       "        language_used_at_home_now non_native_language_1 yrs_of_study_lang1  \\\n",
       "anon_id                                                                      \n",
       "hb0                        Arabic               English          3-5 years   \n",
       "dp8                Arabic;English               English          1-2 years   \n",
       "bn6                Arabic;English               English  more than 5 years   \n",
       "aq6                       English                   NaN                NaN   \n",
       "fm3                           NaN                   NaN                NaN   \n",
       "ey5                           NaN                   NaN                NaN   \n",
       "gb5                           NaN                   NaN                NaN   \n",
       "aa7                           NaN                   NaN                NaN   \n",
       "gf3                           NaN                   NaN                NaN   \n",
       "gl8                           NaN                   NaN                NaN   \n",
       "\n",
       "         study_in_classroom_lang1  \\\n",
       "anon_id                             \n",
       "hb0                           1.0   \n",
       "dp8                           1.0   \n",
       "bn6                           1.0   \n",
       "aq6                           NaN   \n",
       "fm3                           NaN   \n",
       "ey5                           NaN   \n",
       "gb5                           NaN   \n",
       "aa7                           NaN   \n",
       "gf3                           NaN   \n",
       "gl8                           NaN   \n",
       "\n",
       "                                       ways_of_study_lang1  \\\n",
       "anon_id                                                      \n",
       "hb0      Studied grammar;Had a native-speaker teacher;T...   \n",
       "dp8      Studied grammar;Worked in pairs/groups;Had a n...   \n",
       "bn6      Studied grammar;Studied vocabulary;Teacher spo...   \n",
       "aq6                                                    NaN   \n",
       "fm3                                                    NaN   \n",
       "ey5                                                    NaN   \n",
       "gb5                                                    NaN   \n",
       "aa7                                                    NaN   \n",
       "gf3                                                    NaN   \n",
       "gl8                                                    NaN   \n",
       "\n",
       "        non_native_language_2 yrs_of_study_lang2  study_in_classroom_lang2  \\\n",
       "anon_id                                                                      \n",
       "hb0                       NaN                NaN                       0.0   \n",
       "dp8                       NaN                NaN                       0.0   \n",
       "bn6                       NaN                NaN                       0.0   \n",
       "aq6                       NaN                NaN                       NaN   \n",
       "fm3                       NaN                NaN                       NaN   \n",
       "ey5                       NaN                NaN                       NaN   \n",
       "gb5                       NaN                NaN                       NaN   \n",
       "aa7                       NaN                NaN                       NaN   \n",
       "gf3                       NaN                NaN                       NaN   \n",
       "gl8                       NaN                NaN                       NaN   \n",
       "\n",
       "        ways_of_study_lang2 non_native_language_3 yrs_of_study_lang3  \\\n",
       "anon_id                                                                \n",
       "hb0                   other                   NaN                NaN   \n",
       "dp8                   other                   NaN                NaN   \n",
       "bn6                   other                   NaN                NaN   \n",
       "aq6                     NaN                   NaN                NaN   \n",
       "fm3                     NaN                   NaN                NaN   \n",
       "ey5                     NaN                   NaN                NaN   \n",
       "gb5                     NaN                   NaN                NaN   \n",
       "aa7                     NaN                   NaN                NaN   \n",
       "gf3                     NaN                   NaN                NaN   \n",
       "gl8                     NaN                   NaN                NaN   \n",
       "\n",
       "         study_in_classroom_lang3 ways_of_study_lang3          createddate  \\\n",
       "anon_id                                                                      \n",
       "hb0                           0.0               other  2011-06-20 14:09:38   \n",
       "dp8                           0.0               other  2011-06-20 14:10:15   \n",
       "bn6                           0.0               other  2011-06-20 14:11:17   \n",
       "aq6                           NaN                 NaN  2012-09-14 14:05:38   \n",
       "fm3                           NaN                 NaN  2012-09-17 17:12:46   \n",
       "ey5                           NaN                 NaN  2013-04-11 13:28:41   \n",
       "gb5                           NaN                 NaN  2013-06-20 13:12:55   \n",
       "aa7                           NaN                 NaN  2013-07-12 16:25:34   \n",
       "gf3                           NaN                 NaN  2013-11-21 13:42:32   \n",
       "gl8                           NaN                 NaN  2014-10-23 14:14:57   \n",
       "\n",
       "                modifieddate  \\\n",
       "anon_id                        \n",
       "hb0      2011-06-20 14:13:01   \n",
       "dp8      2011-06-20 14:13:57   \n",
       "bn6      2011-06-20 14:15:51   \n",
       "aq6      2012-09-14 14:09:19   \n",
       "fm3                      NaN   \n",
       "ey5                      NaN   \n",
       "gb5                      NaN   \n",
       "aa7                      NaN   \n",
       "gf3                      NaN   \n",
       "gl8                      NaN   \n",
       "\n",
       "                                            course_history  \n",
       "anon_id                                                     \n",
       "hb0      851;869;870;871;872;923;942;944;945;946;1008;1...  \n",
       "dp8                                    868;869;870;871;872  \n",
       "bn6      860;861;862;871;872;930;947;948;949;951;998;99...  \n",
       "aq6                                                   1114  \n",
       "fm3      1034;1035;1036;1037;1038;1099;1100;1101;1102;1103  \n",
       "ey5                                                   1089  \n",
       "gb5                                                   1092  \n",
       "aa7                               1074;1075;1076;1077;1078  \n",
       "gf3                                                   1112  \n",
       "gl8                                                   1077  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Process the student_information.csv file\n",
    "S_info_csv = cor_dir + \"student_information.csv\"\n",
    "S_info_df = pd.read_csv(S_info_csv, index_col = 'anon_id')\n",
    "\n",
    "S_info_df.head() #Issues still apparent with integers turned into floats\n",
    "S_info_df.tail(10) #6 anon_id with no personal info - perhaps not students and to be 'pruned', as well as teachers with 'English' as the native language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>native_language</th>\n",
       "      <th>language_used_at_home</th>\n",
       "      <th>language_used_at_home_now</th>\n",
       "      <th>non_native_language_1</th>\n",
       "      <th>yrs_of_study_lang1</th>\n",
       "      <th>study_in_classroom_lang1</th>\n",
       "      <th>ways_of_study_lang1</th>\n",
       "      <th>non_native_language_2</th>\n",
       "      <th>yrs_of_study_lang2</th>\n",
       "      <th>study_in_classroom_lang2</th>\n",
       "      <th>ways_of_study_lang2</th>\n",
       "      <th>non_native_language_3</th>\n",
       "      <th>yrs_of_study_lang3</th>\n",
       "      <th>study_in_classroom_lang3</th>\n",
       "      <th>ways_of_study_lang3</th>\n",
       "      <th>createddate</th>\n",
       "      <th>modifieddate</th>\n",
       "      <th>course_history</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anon_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ez7</th>\n",
       "      <td>Male</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I lived in a country where they spoke Arabic</td>\n",
       "      <td>English</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Studied pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2007-02-20 10:05:39</td>\n",
       "      <td>2007-03-20 10:09:23</td>\n",
       "      <td>156;167;180;191;200;212;223;234;245;256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ay4</th>\n",
       "      <td>Female</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Had a native-speaker teacher;S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2009-06-09 12:04:22</td>\n",
       "      <td>2009-11-13 12:43:36</td>\n",
       "      <td>509;515;516;517;560;571;574;601;622;642;645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aq6</th>\n",
       "      <td>Female</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-09-14 14:05:38</td>\n",
       "      <td>2012-09-14 14:09:19</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gender  birth_year native_language language_used_at_home  \\\n",
       "anon_id                                                             \n",
       "ez7        Male      1987.0         English                Arabic   \n",
       "ay4      Female      1974.0         English                Korean   \n",
       "aq6      Female      1964.0         English               English   \n",
       "\n",
       "        language_used_at_home_now non_native_language_1 yrs_of_study_lang1  \\\n",
       "anon_id                                                                      \n",
       "ez7                Arabic;English                Arabic  more than 5 years   \n",
       "ay4                        Korean                Korean  more than 5 years   \n",
       "aq6                       English                   NaN                NaN   \n",
       "\n",
       "         study_in_classroom_lang1  \\\n",
       "anon_id                             \n",
       "ez7                           0.0   \n",
       "ay4                           1.0   \n",
       "aq6                           NaN   \n",
       "\n",
       "                                       ways_of_study_lang1  \\\n",
       "anon_id                                                      \n",
       "ez7           I lived in a country where they spoke Arabic   \n",
       "ay4      Studied grammar;Had a native-speaker teacher;S...   \n",
       "aq6                                                    NaN   \n",
       "\n",
       "        non_native_language_2 yrs_of_study_lang2  study_in_classroom_lang2  \\\n",
       "anon_id                                                                      \n",
       "ez7                   English   less than 1 year                       1.0   \n",
       "ay4                       NaN                NaN                       0.0   \n",
       "aq6                       NaN                NaN                       NaN   \n",
       "\n",
       "                                       ways_of_study_lang2  \\\n",
       "anon_id                                                      \n",
       "ez7      Studied grammar;Studied vocabulary;Studied pro...   \n",
       "ay4                                                  other   \n",
       "aq6                                                    NaN   \n",
       "\n",
       "        non_native_language_3 yrs_of_study_lang3  study_in_classroom_lang3  \\\n",
       "anon_id                                                                      \n",
       "ez7                       NaN                NaN                       0.0   \n",
       "ay4                       NaN                NaN                       0.0   \n",
       "aq6                       NaN                NaN                       NaN   \n",
       "\n",
       "        ways_of_study_lang3          createddate         modifieddate  \\\n",
       "anon_id                                                                 \n",
       "ez7                   other  2007-02-20 10:05:39  2007-03-20 10:09:23   \n",
       "ay4                   other  2009-06-09 12:04:22  2009-11-13 12:43:36   \n",
       "aq6                     NaN  2012-09-14 14:05:38  2012-09-14 14:09:19   \n",
       "\n",
       "                                      course_history  \n",
       "anon_id                                               \n",
       "ez7          156;167;180;191;200;212;223;234;245;256  \n",
       "ay4      509;515;516;517;560;571;574;601;622;642;645  \n",
       "aq6                                             1114  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove anyone with 'English' or 'NaN' as their native_language, i.e. not students\n",
    "\n",
    "#First try to create filters\n",
    "\n",
    "Englishfilter = S_info_df['native_language'] == 'English' #first filter works\n",
    "NaNfilter = S_info_df['native_language'] == np.nan #second filter doesn't\n",
    "\n",
    "fake_Ss = S_info_df.loc[Englishfilter] #works, but...\n",
    "fake_Ss\n",
    "\n",
    "#fake_Ss = S_info_df.loc[(Englishfilter) or (NaNfilter)] #doesn't work\n",
    "#fake_Ss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student responses (answer_csv and answer_df) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>directory</th>\n",
       "      <th>is_doublespaced</th>\n",
       "      <th>is_plagiarized</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>eq0</td>\n",
       "      <td>7505</td>\n",
       "      <td>I met my friend Nife while I was studying in a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>am8</td>\n",
       "      <td>7506</td>\n",
       "      <td>Ten years ago, I met a women on the train betw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>dk5</td>\n",
       "      <td>7507</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>dk5</td>\n",
       "      <td>7507</td>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>ad1</td>\n",
       "      <td>7508</td>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\r\\r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id anon_id  user_file_id  \\\n",
       "answer_id                                      \n",
       "1                    5     eq0          7505   \n",
       "2                    5     am8          7506   \n",
       "3                   12     dk5          7507   \n",
       "4                   13     dk5          7507   \n",
       "5                   12     ad1          7508   \n",
       "\n",
       "                                                        text directory  \\\n",
       "answer_id                                                                \n",
       "1          I met my friend Nife while I was studying in a...       NaN   \n",
       "2          Ten years ago, I met a women on the train betw...       NaN   \n",
       "3          In my country we usually don't use tea bags. F...       NaN   \n",
       "4                      I organized the instructions by time.       NaN   \n",
       "5          First, prepare a port, loose tea, and cup.\\r\\r...       NaN   \n",
       "\n",
       "           is_doublespaced  is_plagiarized  is_deleted  \n",
       "answer_id                                               \n",
       "1                        0               0           0  \n",
       "2                        0               0           0  \n",
       "3                        0               0           0  \n",
       "4                        0               0           0  \n",
       "5                        0               0           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>directory</th>\n",
       "      <th>is_doublespaced</th>\n",
       "      <th>is_plagiarized</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48411</th>\n",
       "      <td>6138</td>\n",
       "      <td>dv8</td>\n",
       "      <td>100847</td>\n",
       "      <td>Early Second Language Education\\r\\r\\r\\nSaudi A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48412</th>\n",
       "      <td>6138</td>\n",
       "      <td>ce1</td>\n",
       "      <td>100848</td>\n",
       "      <td>Publicly funded health care system\\r\\r\\r\\n\\r\\r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48413</th>\n",
       "      <td>6139</td>\n",
       "      <td>fo7</td>\n",
       "      <td>100911</td>\n",
       "      <td>Happiness is the most effective feeling in peo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48414</th>\n",
       "      <td>6139</td>\n",
       "      <td>fs9</td>\n",
       "      <td>100912</td>\n",
       "      <td>everyone want to play some games. some people ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48415</th>\n",
       "      <td>6139</td>\n",
       "      <td>cl7</td>\n",
       "      <td>100913</td>\n",
       "      <td>Playing a game is fun only when you win?\\r\\r\\r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48416</th>\n",
       "      <td>6139</td>\n",
       "      <td>dr8</td>\n",
       "      <td>100914</td>\n",
       "      <td>Many people enjoy a game in their free time. B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48417</th>\n",
       "      <td>6137</td>\n",
       "      <td>fv1</td>\n",
       "      <td>100915</td>\n",
       "      <td>\\r\\r\\r\\n                           ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48418</th>\n",
       "      <td>6137</td>\n",
       "      <td>fo1</td>\n",
       "      <td>100916</td>\n",
       "      <td>Some  patients are suffering from the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48419</th>\n",
       "      <td>6119</td>\n",
       "      <td>ge8</td>\n",
       "      <td>100917</td>\n",
       "      <td>My house looks amazing and modern. I decorated...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48420</th>\n",
       "      <td>6027</td>\n",
       "      <td>ge8</td>\n",
       "      <td>100918</td>\n",
       "      <td>History and Geography a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id anon_id  user_file_id  \\\n",
       "answer_id                                      \n",
       "48411             6138     dv8        100847   \n",
       "48412             6138     ce1        100848   \n",
       "48413             6139     fo7        100911   \n",
       "48414             6139     fs9        100912   \n",
       "48415             6139     cl7        100913   \n",
       "48416             6139     dr8        100914   \n",
       "48417             6137     fv1        100915   \n",
       "48418             6137     fo1        100916   \n",
       "48419             6119     ge8        100917   \n",
       "48420             6027     ge8        100918   \n",
       "\n",
       "                                                        text directory  \\\n",
       "answer_id                                                                \n",
       "48411      Early Second Language Education\\r\\r\\r\\nSaudi A...       NaN   \n",
       "48412      Publicly funded health care system\\r\\r\\r\\n\\r\\r...       NaN   \n",
       "48413      Happiness is the most effective feeling in peo...       NaN   \n",
       "48414      everyone want to play some games. some people ...       NaN   \n",
       "48415      Playing a game is fun only when you win?\\r\\r\\r...       NaN   \n",
       "48416      Many people enjoy a game in their free time. B...       NaN   \n",
       "48417                 \\r\\r\\r\\n                           ...       NaN   \n",
       "48418               Some  patients are suffering from the...       NaN   \n",
       "48419      My house looks amazing and modern. I decorated...       NaN   \n",
       "48420                             History and Geography a...       NaN   \n",
       "\n",
       "           is_doublespaced  is_plagiarized  is_deleted  \n",
       "answer_id                                               \n",
       "48411                    1               0           0  \n",
       "48412                    0               0           0  \n",
       "48413                    1               0           0  \n",
       "48414                    1               0           0  \n",
       "48415                    1               0           0  \n",
       "48416                    1               0           0  \n",
       "48417                    0               0           0  \n",
       "48418                    0               0           0  \n",
       "48419                    0               0           0  \n",
       "48420                    0               0           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Process answer.csv file\n",
    "answer_csv = cor_dir + \"answer.csv\"\n",
    "answer_df = pd.read_csv(answer_csv, index_col = 'answer_id')\n",
    "\n",
    "answer_df.head()\n",
    "answer_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course IDs ###\n",
    "(should help with finding specific texts and linking other data frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>semester</th>\n",
       "      <th>section</th>\n",
       "      <th>course_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>course_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2064</td>\n",
       "      <td>A</td>\n",
       "      <td>Reading Pre_Intermediate 2064 A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2064</td>\n",
       "      <td>B</td>\n",
       "      <td>Reading Low_Intermediate 2064 B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>M</td>\n",
       "      <td>Reading Intermediate 2064 M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>P</td>\n",
       "      <td>Reading Intermediate 2064 P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>Q</td>\n",
       "      <td>Reading Intermediate 2064 Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           class_id  level_id  semester section  \\\n",
       "course_id                                         \n",
       "1                 1         2      2064       A   \n",
       "2                 1         3      2064       B   \n",
       "3                 1         4      2064       M   \n",
       "4                 1         4      2064       P   \n",
       "5                 1         4      2064       Q   \n",
       "\n",
       "                        course_description  \n",
       "course_id                                   \n",
       "1          Reading Pre_Intermediate 2064 A  \n",
       "2          Reading Low_Intermediate 2064 B  \n",
       "3              Reading Intermediate 2064 M  \n",
       "4              Reading Intermediate 2064 P  \n",
       "5              Reading Intermediate 2064 Q  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Process course.csv file\n",
    "course_csv = cor_dir + \"course.csv\"\n",
    "course_df = pd.read_csv(course_csv, index_col = 'course_id')\n",
    "\n",
    "course_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  user_file_wav_txt ###\n",
    "- big csv file with a lot of information\n",
    "- should help with finding specific texts and linking other data frames\n",
    "- includes file_type_id, course_id, and paths of text and wav files (i.e. all the spoken responses I need)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>file_type_id</th>\n",
       "      <th>file_info_id</th>\n",
       "      <th>user_file_parent_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>activity</th>\n",
       "      <th>order_num</th>\n",
       "      <th>due_date</th>\n",
       "      <th>...</th>\n",
       "      <th>modifiedby</th>\n",
       "      <th>modifieddate</th>\n",
       "      <th>allow_submit_after_duedate</th>\n",
       "      <th>allow_multiple_accesses</th>\n",
       "      <th>allow_double_spacing</th>\n",
       "      <th>duration</th>\n",
       "      <th>pull_off_date</th>\n",
       "      <th>direction</th>\n",
       "      <th>grammar_qp_id</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_file_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2006-08-07 14:19:48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-08 12:17:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2006-08-07 14:19:48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-08 12:19:15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2006-08-07 14:19:48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-08 12:21:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2006-08-07 14:19:48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-08 12:24:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2006-08-07 14:19:48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-08 12:14:57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             anon_id  file_type_id  file_info_id  user_file_parent_id  \\\n",
       "user_file_id                                                            \n",
       "239              NaN             5          13.0                  NaN   \n",
       "240              NaN             5          13.0                  NaN   \n",
       "241              NaN             5          13.0                  NaN   \n",
       "242              NaN             5          13.0                  NaN   \n",
       "243              NaN             5          13.0                  NaN   \n",
       "\n",
       "              course_id  session_id  document_id  activity  order_num  \\\n",
       "user_file_id                                                            \n",
       "239                  90         NaN          NaN         1        1.0   \n",
       "240                  90         NaN          NaN         1        2.0   \n",
       "241                  90         NaN          NaN         1        3.0   \n",
       "242                  90         NaN          NaN         1        4.0   \n",
       "243                  90         NaN          NaN         1        5.0   \n",
       "\n",
       "                         due_date    ...     modifiedby         modifieddate  \\\n",
       "user_file_id                         ...                                       \n",
       "239           2006-08-07 14:19:48    ...            NaN  2006-08-08 12:17:18   \n",
       "240           2006-08-07 14:19:48    ...            NaN  2006-08-08 12:19:15   \n",
       "241           2006-08-07 14:19:48    ...            NaN  2006-08-08 12:21:18   \n",
       "242           2006-08-07 14:19:48    ...            NaN  2006-08-08 12:24:00   \n",
       "243           2006-08-07 14:19:48    ...            NaN  2006-08-08 12:14:57   \n",
       "\n",
       "              allow_submit_after_duedate allow_multiple_accesses  \\\n",
       "user_file_id                                                       \n",
       "239                                    0                       0   \n",
       "240                                    0                       0   \n",
       "241                                    0                       0   \n",
       "242                                    0                       0   \n",
       "243                                    0                       0   \n",
       "\n",
       "             allow_double_spacing  duration  pull_off_date direction  \\\n",
       "user_file_id                                                           \n",
       "239                             0       NaN            NaN       NaN   \n",
       "240                             0       NaN            NaN       NaN   \n",
       "241                             0       NaN            NaN       NaN   \n",
       "242                             0       NaN            NaN       NaN   \n",
       "243                             0       NaN            NaN       NaN   \n",
       "\n",
       "              grammar_qp_id is_deleted  \n",
       "user_file_id                            \n",
       "239                     NaN          0  \n",
       "240                     NaN          0  \n",
       "241                     NaN          0  \n",
       "242                     NaN          0  \n",
       "243                     NaN          0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Process user_file_wavtxt.csv file\n",
    "user_csv = cor_dir + \"user_file_wavtxt.csv\"\n",
    "user_df = pd.read_csv(user_csv, index_col = 'user_file_id')\n",
    "\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic info about dataframes ###\n",
    "\n",
    "The following information is an overview of the four dataframes/csv files currently being looked at:\n",
    "\n",
    "#### S_info_df ####\n",
    "Size:\n",
    "- there are 941 entries, i.e. students, although at least 9 need to be removed once filters can be made to work\n",
    "- 21 columns including info about languages spoken, personal data like age, and learning preferences\n",
    "- Some columns will likely be removed if deemed unhelpful/unnecessary (e.g. 4th language spoken)\n",
    "- Some data is normalized, e.g. years of study, but others was open, resulting in very varied responses\n",
    "\n",
    "Connection to other dataframes:\n",
    "- link to answer_df is anon_id\n",
    "\n",
    "Most useful columns for this project:\n",
    "- anon_id (for linking to other df)\n",
    "- L1, gender, time studying, age (for data analysis)  \n",
    "\n",
    "\n",
    "#### answer_df ####\n",
    "Size:\n",
    "- there are 47175 'text' entries, i.e. student responses, although 48384 total rows. The remaining (including many null texts need to be removed as without texts they serve no purpose\n",
    "- 9 columns including info about the question, the answer, and characteristics of the text (like if it was plagiarized)\n",
    "\n",
    "Connection to other dataframes:\n",
    "- link to S_info_df and course_df is anon_id column\n",
    "\n",
    "Most useful columns for this project:\n",
    "- answer_id (shorthand for the individual texts to be analyzed)\n",
    "- text (the most important column so far) -> to be converted into tokens, bigrams, etc.  \n",
    "- anon_id (for linking to other df)\n",
    "\n",
    "\n",
    "#### course_df ####\n",
    "Size:\n",
    "- there are 1071 entries, i.e. one row for each course\n",
    "- 6 columns including info about the course and class, both in terms of their assigned number and a description\n",
    "\n",
    "Connection to other dataframes:\n",
    "- link to user_df is course_id \n",
    "\n",
    "Most useful columns for this project:\n",
    "- only really useful as a transition for linking to other df  \n",
    "\n",
    "\n",
    "#### user_df ####\n",
    "Size:\n",
    "- there are 76371 rows, each with a file_id number. However, it is unclear how to use this informatin effectively.\n",
    "- There are 29 columns, although many are not useful for this project\n",
    "- A lot of the cells have no input\n",
    "- Some columns will likely be removed if deemed unhelpful/unnecessary\n",
    "\n",
    "Connection to other dataframes:\n",
    "- link to course_df is course_id column\n",
    "\n",
    "Most useful columns for this project:\n",
    "- course_id (to link to other DF)\n",
    "- file_type_id (for indicating the type of activity used in class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 941 entries, ez9 to gl8\n",
      "Data columns (total 20 columns):\n",
      "gender                       920 non-null object\n",
      "birth_year                   920 non-null float64\n",
      "native_language              920 non-null object\n",
      "language_used_at_home        919 non-null object\n",
      "language_used_at_home_now    860 non-null object\n",
      "non_native_language_1        866 non-null object\n",
      "yrs_of_study_lang1           871 non-null object\n",
      "study_in_classroom_lang1     871 non-null float64\n",
      "ways_of_study_lang1          871 non-null object\n",
      "non_native_language_2        312 non-null object\n",
      "yrs_of_study_lang2           315 non-null object\n",
      "study_in_classroom_lang2     871 non-null float64\n",
      "ways_of_study_lang2          871 non-null object\n",
      "non_native_language_3        56 non-null object\n",
      "yrs_of_study_lang3           60 non-null object\n",
      "study_in_classroom_lang3     871 non-null float64\n",
      "ways_of_study_lang3          871 non-null object\n",
      "createddate                  941 non-null object\n",
      "modifieddate                 918 non-null object\n",
      "course_history               940 non-null object\n",
      "dtypes: float64(4), object(16)\n",
      "memory usage: 154.4+ KB\n"
     ]
    }
   ],
   "source": [
    "S_info_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 48384 entries, 1 to 48420\n",
      "Data columns (total 8 columns):\n",
      "question_id        48384 non-null int64\n",
      "anon_id            48353 non-null object\n",
      "user_file_id       48384 non-null int64\n",
      "text               47175 non-null object\n",
      "directory          14 non-null object\n",
      "is_doublespaced    48384 non-null int64\n",
      "is_plagiarized     48384 non-null int64\n",
      "is_deleted         48384 non-null int64\n",
      "dtypes: int64(5), object(3)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "answer_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1071 entries, 1 to 1123\n",
      "Data columns (total 5 columns):\n",
      "class_id              1071 non-null int64\n",
      "level_id              1071 non-null int64\n",
      "semester              1071 non-null int64\n",
      "section               1071 non-null object\n",
      "course_description    1058 non-null object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 50.2+ KB\n"
     ]
    }
   ],
   "source": [
    "course_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 76371 entries, 239 to 103667\n",
      "Data columns (total 28 columns):\n",
      "anon_id                       76142 non-null object\n",
      "file_type_id                  76371 non-null int64\n",
      "file_info_id                  13241 non-null float64\n",
      "user_file_parent_id           33348 non-null float64\n",
      "course_id                     76371 non-null int64\n",
      "session_id                    0 non-null float64\n",
      "document_id                   0 non-null float64\n",
      "activity                      76371 non-null int64\n",
      "order_num                     40323 non-null float64\n",
      "due_date                      5346 non-null object\n",
      "post_date                     5346 non-null object\n",
      "assignment_name               0 non-null float64\n",
      "version                       76371 non-null int64\n",
      "directory                     76371 non-null object\n",
      "filename                      76371 non-null object\n",
      "content_text                  0 non-null float64\n",
      "createdby                     0 non-null float64\n",
      "createddate                   76371 non-null object\n",
      "modifiedby                    1076 non-null float64\n",
      "modifieddate                  7959 non-null object\n",
      "allow_submit_after_duedate    76371 non-null int64\n",
      "allow_multiple_accesses       76371 non-null int64\n",
      "allow_double_spacing          76371 non-null int64\n",
      "duration                      0 non-null float64\n",
      "pull_off_date                 0 non-null float64\n",
      "direction                     0 non-null float64\n",
      "grammar_qp_id                 2711 non-null float64\n",
      "is_deleted                    76371 non-null int64\n",
      "dtypes: float64(13), int64(8), object(7)\n",
      "memory usage: 16.9+ MB\n"
     ]
    }
   ],
   "source": [
    "user_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Speaking Answers dataframe ###\n",
    "\n",
    "1) Start with 'course.csv' which has class_id (we want #3 for speaking classes)  \n",
    "2) In 'course.csv', class_id is linked to course_id  \n",
    "3) In 'user_file_wavtxt.csv' course_id is linked to file_type_id (we want #6 for RSA)  \n",
    "4) MISSING STEP OR STEPS - nothing links to answer.csv other than anon_id and this isn't specific enough - is this information in the original text file?  \n",
    "(Final goal) answer_id -> text in 'answer.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ALL ATTEMPTS FAIL MISERABLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating find_stuff function ###\n",
    "\n",
    "Goal: create a function that allows for easy retrieval within, from the various different, dataframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>semester</th>\n",
       "      <th>section</th>\n",
       "      <th>course_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>course_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2064</td>\n",
       "      <td>A</td>\n",
       "      <td>Speaking Pre_Intermediate 2064 A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2064</td>\n",
       "      <td>B</td>\n",
       "      <td>Speaking Low_Intermediate 2064 B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>M</td>\n",
       "      <td>Speaking Intermediate 2064 M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>P</td>\n",
       "      <td>Speaking Intermediate 2064 P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>Q</td>\n",
       "      <td>Speaking Intermediate 2064 Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           class_id  level_id  semester section  \\\n",
       "course_id                                         \n",
       "13                3         2      2064       A   \n",
       "14                3         3      2064       B   \n",
       "15                3         4      2064       M   \n",
       "16                3         4      2064       P   \n",
       "17                3         4      2064       Q   \n",
       "\n",
       "                         course_description  \n",
       "course_id                                    \n",
       "13         Speaking Pre_Intermediate 2064 A  \n",
       "14         Speaking Low_Intermediate 2064 B  \n",
       "15             Speaking Intermediate 2064 M  \n",
       "16             Speaking Intermediate 2064 P  \n",
       "17             Speaking Intermediate 2064 Q  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adapted from initial work of Brianna - thank you!\n",
    "\n",
    "#this works to find all the course_id entries for a particular class type, in this case '3' which == speaking\n",
    "\n",
    "def find_stuff(df, class_type):\n",
    "    class_id = df.loc[df['class_id'] == class_type]\n",
    "    return class_id\n",
    "\n",
    "test = find_stuff(course_df, 3)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>semester</th>\n",
       "      <th>section</th>\n",
       "      <th>course_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>course_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2064</td>\n",
       "      <td>A</td>\n",
       "      <td>Grammar Pre_Intermediate 2064 A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2064</td>\n",
       "      <td>B</td>\n",
       "      <td>Grammar Low_Intermediate 2064 B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>M</td>\n",
       "      <td>Grammar Intermediate 2064 M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>P</td>\n",
       "      <td>Grammar Intermediate 2064 P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>Q</td>\n",
       "      <td>Grammar Intermediate 2064 Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           class_id  level_id  semester section  \\\n",
       "course_id                                         \n",
       "25                5         2      2064       A   \n",
       "26                5         3      2064       B   \n",
       "27                5         4      2064       M   \n",
       "28                5         4      2064       P   \n",
       "29                5         4      2064       Q   \n",
       "\n",
       "                        course_description  \n",
       "course_id                                   \n",
       "25         Grammar Pre_Intermediate 2064 A  \n",
       "26         Grammar Low_Intermediate 2064 B  \n",
       "27             Grammar Intermediate 2064 M  \n",
       "28             Grammar Intermediate 2064 P  \n",
       "29             Grammar Intermediate 2064 Q  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test #2\n",
    "\n",
    "test2 = find_stuff(course_df, 5)\n",
    "test2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next step is to either expand on this function or create other similar ones to allow look up of other types of info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization of answers ###\n",
    "\n",
    "Goal: tokenize the text in answer.csv to allow for further analysis (bigrams, lexical diversity, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I met my friend Nife while I was studying in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ten years ago, I met a women on the train betw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\r\\r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text\n",
       "answer_id                                                   \n",
       "1          I met my friend Nife while I was studying in a...\n",
       "2          Ten years ago, I met a women on the train betw...\n",
       "3          In my country we usually don't use tea bags. F...\n",
       "4                      I organized the instructions by time.\n",
       "5          First, prepare a port, loose tea, and cup.\\r\\r..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find column to tokenize\n",
    "\n",
    "answer_df[['text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply tokenizing function to 'text' column, using .map()\n",
    "    #answer_df['toks'] = answer_df['text'].map(nltk.word_tokenize)\n",
    "#Perhaps not working because of NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>directory</th>\n",
       "      <th>is_doublespaced</th>\n",
       "      <th>is_plagiarized</th>\n",
       "      <th>is_deleted</th>\n",
       "      <th>toks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>eq0</td>\n",
       "      <td>7505</td>\n",
       "      <td>I met my friend Nife while I was studying in a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, met, my, friend, Nife, while, I, was, stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>am8</td>\n",
       "      <td>7506</td>\n",
       "      <td>Ten years ago, I met a women on the train betw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Ten, years, ago, ,, I, met, a, women, on, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>dk5</td>\n",
       "      <td>7507</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[In, my, country, we, usually, do, n't, use, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>dk5</td>\n",
       "      <td>7507</td>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, organized, the, instructions, by, time, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>ad1</td>\n",
       "      <td>7508</td>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\r\\r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[First, ,, prepare, a, port, ,, loose, tea, ,,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id anon_id  user_file_id  \\\n",
       "answer_id                                      \n",
       "1                    5     eq0          7505   \n",
       "2                    5     am8          7506   \n",
       "3                   12     dk5          7507   \n",
       "4                   13     dk5          7507   \n",
       "5                   12     ad1          7508   \n",
       "\n",
       "                                                        text directory  \\\n",
       "answer_id                                                                \n",
       "1          I met my friend Nife while I was studying in a...       NaN   \n",
       "2          Ten years ago, I met a women on the train betw...       NaN   \n",
       "3          In my country we usually don't use tea bags. F...       NaN   \n",
       "4                      I organized the instructions by time.       NaN   \n",
       "5          First, prepare a port, loose tea, and cup.\\r\\r...       NaN   \n",
       "\n",
       "           is_doublespaced  is_plagiarized  is_deleted  \\\n",
       "answer_id                                                \n",
       "1                        0               0           0   \n",
       "2                        0               0           0   \n",
       "3                        0               0           0   \n",
       "4                        0               0           0   \n",
       "5                        0               0           0   \n",
       "\n",
       "                                                        toks  \n",
       "answer_id                                                     \n",
       "1          [I, met, my, friend, Nife, while, I, was, stud...  \n",
       "2          [Ten, years, ago, ,, I, met, a, women, on, the...  \n",
       "3          [In, my, country, we, usually, do, n't, use, t...  \n",
       "4             [I, organized, the, instructions, by, time, .]  \n",
       "5          [First, ,, prepare, a, port, ,, loose, tea, ,,...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#With the magic of stackoverflow, this seems to work, converting NaN to empty strings\n",
    "answer_df = answer_df[answer_df['text'].notnull()]\n",
    "answer_df['toks'] = answer_df.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\n",
    "\n",
    "answer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams###\n",
    "\n",
    "Goal: create a bigram columns from the tok column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'met', 'my', 'friend', 'Nife', 'while', 'I', 'was', 'studying', 'in', 'a', 'middle', 'school', '.', 'I', 'was', 'happy', 'when', 'I', 'met', 'him', 'because', 'he', 'was', 'a', 'good', 'student', 'in', 'our', 'school', '.', 'We', 'continued', 'the', 'middle', 'and', 'high', 'school', 'to', 'gather', 'in', 'the', 'same', 'school', '.', 'We', 'were', 'studying', 'in', 'the', 'different', 'classes', 'in', 'the', 'middle', 'school', ';', 'however', ',', 'in', 'the', 'high', 'school', 'we', 'were', 'studying', 'in', 'the', 'same', 'class', '.', 'We', 'went', 'to', 'many', 'places', 'in', 'the', 'free', 'time', 'while', 'we', 'were', 'studying', 'in', 'the', 'high', 'school', '.', 'When', 'we', 'finished', 'from', 'the', 'high', 'school', ',', 'I', 'went', 'to', 'K.S', 'University', 'and', 'he', 'went', 'to', 'I.M', 'University', '.', 'While', 'we', 'were', 'enjoying', 'in', 'academic', 'life', ',', 'we', 'made', 'many', 'achievement', 'in', 'these', 'universities', '.', 'I', 'graduated', 'when', 'Nife', 'was', 'studying', 'in', 'the', 'last', 'semester', 'in', 'the', 'university', '.', 'After', 'that', ',', 'I', 'got', 'a', 'job', '.', 'Fortunately', ',', 'it', 'was', 'nearby', 'my', 'home', '.', 'I', 'worked', 'two', 'years', 'then', 'I', 'got', 'scholarship', 'from', 'ministry', 'of', 'high', 'education', 'in', 'my', 'country', '.', 'When', 'I', 'came', 'here', 'to', 'U.S', ',', 'my', 'friend', 'Nife', 'arrange', 'some', 'documents', 'to', 'study', 'at', 'grad', 'school', 'in', 'Malaysia', '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('I', 'met'), ('met', 'my'), ('my', 'friend'), ('friend', 'Nife'), ('Nife', 'while'), ('while', 'I'), ('I', 'was'), ('was', 'studying'), ('studying', 'in'), ('in', 'a'), ('a', 'middle'), ('middle', 'school'), ('school', '.'), ('.', 'I'), ('I', 'was'), ('was', 'happy'), ('happy', 'when'), ('when', 'I'), ('I', 'met'), ('met', 'him'), ('him', 'because'), ('because', 'he'), ('he', 'was'), ('was', 'a'), ('a', 'good'), ('good', 'student'), ('student', 'in'), ('in', 'our'), ('our', 'school'), ('school', '.'), ('.', 'We'), ('We', 'continued'), ('continued', 'the'), ('the', 'middle'), ('middle', 'and'), ('and', 'high'), ('high', 'school'), ('school', 'to'), ('to', 'gather'), ('gather', 'in'), ('in', 'the'), ('the', 'same'), ('same', 'school'), ('school', '.'), ('.', 'We'), ('We', 'were'), ('were', 'studying'), ('studying', 'in'), ('in', 'the'), ('the', 'different'), ('different', 'classes'), ('classes', 'in'), ('in', 'the'), ('the', 'middle'), ('middle', 'school'), ('school', ';'), (';', 'however'), ('however', ','), (',', 'in'), ('in', 'the'), ('the', 'high'), ('high', 'school'), ('school', 'we'), ('we', 'were'), ('were', 'studying'), ('studying', 'in'), ('in', 'the'), ('the', 'same'), ('same', 'class'), ('class', '.'), ('.', 'We'), ('We', 'went'), ('went', 'to'), ('to', 'many'), ('many', 'places'), ('places', 'in'), ('in', 'the'), ('the', 'free'), ('free', 'time'), ('time', 'while'), ('while', 'we'), ('we', 'were'), ('were', 'studying'), ('studying', 'in'), ('in', 'the'), ('the', 'high'), ('high', 'school'), ('school', '.'), ('.', 'When'), ('When', 'we'), ('we', 'finished'), ('finished', 'from'), ('from', 'the'), ('the', 'high'), ('high', 'school'), ('school', ','), (',', 'I'), ('I', 'went'), ('went', 'to'), ('to', 'K.S'), ('K.S', 'University'), ('University', 'and'), ('and', 'he'), ('he', 'went'), ('went', 'to'), ('to', 'I.M'), ('I.M', 'University'), ('University', '.'), ('.', 'While'), ('While', 'we'), ('we', 'were'), ('were', 'enjoying'), ('enjoying', 'in'), ('in', 'academic'), ('academic', 'life'), ('life', ','), (',', 'we'), ('we', 'made'), ('made', 'many'), ('many', 'achievement'), ('achievement', 'in'), ('in', 'these'), ('these', 'universities'), ('universities', '.'), ('.', 'I'), ('I', 'graduated'), ('graduated', 'when'), ('when', 'Nife'), ('Nife', 'was'), ('was', 'studying'), ('studying', 'in'), ('in', 'the'), ('the', 'last'), ('last', 'semester'), ('semester', 'in'), ('in', 'the'), ('the', 'university'), ('university', '.'), ('.', 'After'), ('After', 'that'), ('that', ','), (',', 'I'), ('I', 'got'), ('got', 'a'), ('a', 'job'), ('job', '.'), ('.', 'Fortunately'), ('Fortunately', ','), (',', 'it'), ('it', 'was'), ('was', 'nearby'), ('nearby', 'my'), ('my', 'home'), ('home', '.'), ('.', 'I'), ('I', 'worked'), ('worked', 'two'), ('two', 'years'), ('years', 'then'), ('then', 'I'), ('I', 'got'), ('got', 'scholarship'), ('scholarship', 'from'), ('from', 'ministry'), ('ministry', 'of'), ('of', 'high'), ('high', 'education'), ('education', 'in'), ('in', 'my'), ('my', 'country'), ('country', '.'), ('.', 'When'), ('When', 'I'), ('I', 'came'), ('came', 'here'), ('here', 'to'), ('to', 'U.S'), ('U.S', ','), (',', 'my'), ('my', 'friend'), ('friend', 'Nife'), ('Nife', 'arrange'), ('arrange', 'some'), ('some', 'documents'), ('documents', 'to'), ('to', 'study'), ('study', 'at'), ('at', 'grad'), ('grad', 'school'), ('school', 'in'), ('in', 'Malaysia'), ('Malaysia', '.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>directory</th>\n",
       "      <th>is_doublespaced</th>\n",
       "      <th>is_plagiarized</th>\n",
       "      <th>is_deleted</th>\n",
       "      <th>toks</th>\n",
       "      <th>bigrams</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>eq0</td>\n",
       "      <td>7505</td>\n",
       "      <td>I met my friend Nife while I was studying in a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, met, my, friend, Nife, while, I, was, stud...</td>\n",
       "      <td>[(I, met), (met, my), (my, friend), (friend, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>am8</td>\n",
       "      <td>7506</td>\n",
       "      <td>Ten years ago, I met a women on the train betw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Ten, years, ago, ,, I, met, a, women, on, the...</td>\n",
       "      <td>[(Ten, years), (years, ago), (ago, ,), (,, I),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>dk5</td>\n",
       "      <td>7507</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[In, my, country, we, usually, do, n't, use, t...</td>\n",
       "      <td>[(In, my), (my, country), (country, we), (we, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>dk5</td>\n",
       "      <td>7507</td>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, organized, the, instructions, by, time, .]</td>\n",
       "      <td>[(I, organized), (organized, the), (the, instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>ad1</td>\n",
       "      <td>7508</td>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\r\\r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[First, ,, prepare, a, port, ,, loose, tea, ,,...</td>\n",
       "      <td>[(First, ,), (,, prepare), (prepare, a), (a, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id anon_id  user_file_id  \\\n",
       "answer_id                                      \n",
       "1                    5     eq0          7505   \n",
       "2                    5     am8          7506   \n",
       "3                   12     dk5          7507   \n",
       "4                   13     dk5          7507   \n",
       "5                   12     ad1          7508   \n",
       "\n",
       "                                                        text directory  \\\n",
       "answer_id                                                                \n",
       "1          I met my friend Nife while I was studying in a...       NaN   \n",
       "2          Ten years ago, I met a women on the train betw...       NaN   \n",
       "3          In my country we usually don't use tea bags. F...       NaN   \n",
       "4                      I organized the instructions by time.       NaN   \n",
       "5          First, prepare a port, loose tea, and cup.\\r\\r...       NaN   \n",
       "\n",
       "           is_doublespaced  is_plagiarized  is_deleted  \\\n",
       "answer_id                                                \n",
       "1                        0               0           0   \n",
       "2                        0               0           0   \n",
       "3                        0               0           0   \n",
       "4                        0               0           0   \n",
       "5                        0               0           0   \n",
       "\n",
       "                                                        toks  \\\n",
       "answer_id                                                      \n",
       "1          [I, met, my, friend, Nife, while, I, was, stud...   \n",
       "2          [Ten, years, ago, ,, I, met, a, women, on, the...   \n",
       "3          [In, my, country, we, usually, do, n't, use, t...   \n",
       "4             [I, organized, the, instructions, by, time, .]   \n",
       "5          [First, ,, prepare, a, port, ,, loose, tea, ,,...   \n",
       "\n",
       "                                                     bigrams  \n",
       "answer_id                                                     \n",
       "1          [(I, met), (met, my), (my, friend), (friend, N...  \n",
       "2          [(Ten, years), (years, ago), (ago, ,), (,, I),...  \n",
       "3          [(In, my), (my, country), (country, we), (we, ...  \n",
       "4          [(I, organized), (organized, the), (the, instr...  \n",
       "5          [(First, ,), (,, prepare), (prepare, a), (a, p...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mini-test to make sure I am creating bigrams correctly\n",
    "\n",
    "bigram_test = answer_df.toks[1]\n",
    "bigram_test\n",
    "list(nltk.bigrams(bigram_test))\n",
    "\n",
    "#test works, let's try on dataframe\n",
    "\n",
    "answer_df['bigrams'] = answer_df.toks.apply(lambda x: list(nltk.bigrams(x)))\n",
    "answer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create frequency dictionary for entire corpus ###\n",
    "\n",
    "Attempting to create frequency dictionary for all toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'in': 15, '.': 12, 'the': 11, 'I': 10, 'school': 9, 'to': 6, ',': 6, 'was': 5, 'studying': 5, 'high': 5, ...})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdict = nltk.FreqDist(answer_df.toks[1])\n",
    "testdict\n",
    "#looks ok, now to apply to the whole column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answer_id\n",
       "1    {'I': 10, 'met': 2, 'my': 4, 'friend': 2, 'Nif...\n",
       "2    {'Ten': 1, 'years': 1, 'ago': 1, ',': 8, 'I': ...\n",
       "3    {'In': 1, 'my': 1, 'country': 1, 'we': 5, 'usu...\n",
       "4    {'I': 1, 'organized': 1, 'the': 1, 'instructio...\n",
       "5    {'First': 1, ',': 9, 'prepare': 1, 'a': 2, 'po...\n",
       "Name: toks, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdict = answer_df.toks.apply(lambda x: nltk.FreqDist(x))\n",
    "fdict.head()\n",
    "#haha they are mini-dicts for each text rather than for the dataframe as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I met my friend Nife while I was studying in a middle school. I was happy when I met him because he '"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['I', 'met', 'my', 'friend', 'Nife', 'while', 'I', 'was', 'studying', 'in', 'a', 'middle', 'school', '.', 'I', 'was', 'happy', 'when', 'I', 'met']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_corpus = ' '.join(answer_df['text'])\n",
    "answer_corpus[:100]\n",
    "answer_corpus_tok = nltk.word_tokenize(answer_corpus)\n",
    "answer_corpus_tok[:20]\n",
    "\n",
    "#probably not the most efficient way but it seems to have worked at least for tokenizing whole corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'.': 264755, ',': 218149, 'the': 171927, 'to': 133262, 'and': 105988, 'I': 93236, 'a': 89283, 'of': 88552, 'in': 77170, 'is': 75659, ...})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_dict = nltk.FreqDist(answer_corpus_tok)\n",
    "answer_dict\n",
    "\n",
    "#success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create frequency dictionary for bigrams of entire corpus ###\n",
    "\n",
    "Attempting to create frequency dictionary for all bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'met'), ('met', 'my'), ('my', 'friend'), ('friend', 'Nife'), ('Nife', 'while'), ('while', 'I'), ('I', 'was'), ('was', 'studying'), ('studying', 'in'), ('in', 'a')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's try to do this from the answer_corpus_tok\n",
    "\n",
    "answer_corpus_bigrams = list(nltk.bigrams(answer_corpus_tok))\n",
    "answer_corpus_bigrams[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('.', 'I'): 24177, (',', 'I'): 21399, ('in', 'the'): 18669, ('.', 'The'): 17403, (',', 'and'): 16701, ('of', 'the'): 15011, ('.', 'In'): 13393, (',', 'the'): 12288, ('.', 'It'): 9348, ('to', 'the'): 8553, ...})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ok, now time for the dictionary\n",
    "answer_bigram_dict = nltk.FreqDist(answer_corpus_bigrams)\n",
    "answer_bigram_dict\n",
    "\n",
    "#success! (although unless I use MI or do something about stop words/punctuation, then it's not very useful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count vectors ###\n",
    "\n",
    "Attempting to create count vector of toks and bigram columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "textvec = CountVectorizer(min_df=1, tokenizer=nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sents turned into sparse vector of word frequency counts\n",
    "toks_counts = textvec.fit_transform(answer_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47175, 63041)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks_counts.shape\n",
    "toks_counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#not sure if this has any use! (Perhaps TF-IDF?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Mutual Information (MI) ####\n",
    "\n",
    "(from https://corpus.byu.edu/mutualInformation.asp)  \n",
    "\n",
    "Mutual Information is calculated as follows:  \n",
    "MI = log ( (AB * sizeCorpus) / (A * B * span) ) / log (2)  \n",
    "\n",
    "Suppose we are calculating the MI for the collocate color near purple in BYU-BNC.  \n",
    "\n",
    "A = frequency of node word (e.g. purple): 1262  \n",
    "B = frequency of collocate (e.g. color): 115  \n",
    "AB = frequency of collocate near the node word (e.g. color near purple): 24  \n",
    "sizeCorpus= size of corpus (# words; in this case the BNC): 96,263,399  \n",
    "span = span of words (e.g. 3 to left and 3 to right of node word): 6  \n",
    "log (2) is literally the log10 of the number 2: .30103  \n",
    "\n",
    "MI = 11.37 = log ( (24 * 96,263,399) / (1262 * 115 * 6) ) / .30103  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
