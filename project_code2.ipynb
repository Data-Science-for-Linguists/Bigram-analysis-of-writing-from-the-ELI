{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project_Code 2: Clean up and analysis of ELI Data #\n",
    "## Ben Naismith ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes since 'Project_Code1' ###\n",
    "\n",
    "This new document has been created as a number of significant changes have been made to the original code. Based on discussions with other members of the ELI Data Mining Group, the following points were determined:\n",
    "\n",
    "- For the sake of efficiency, it is better not to merge the different data frames into one big one\n",
    "- A 'sanitization' step of the data was completed which duplicated some of the steps of my initial code. These duplications include removing unwanted apostrophes, changing all 'null' and 'ull' to NaN, and removing empty or unreal students (who were most likely teachers). As such, the dataset is now ready for more in-depth cleaning and analysis, i.e. the purpose of this notebook. The code for the sanitization step is in a private repository of the ELI Data Mining Groups 'convert_0_to_1.ipynb'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sharing Plan ###\n",
    "\n",
    "The full ELI data set (see project_plan.md) is private at this time. Below is a workbook with the current code for organizing and cleaning that data. In order to see how the code works, snippets of data have been displayed throughout.\n",
    "\n",
    "A sample of the 'sanitized' data is included in the 'data' folder in this same repository. It contains samples of the four CSV files referred to in this code, consisting of 1000 answers, in order to allow for testing and reproducibility by others of the code. These 1000 answers are the first 1000 from the answer_csv file and correspond to user_file_id 7505 to 10108.\n",
    "\n",
    "Ultimately, it is the intention of the dataset's authors for the entire dataset to be made public, with a CC license. Please see the LICENSE_notes.md for details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setup ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import necesary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "#return every shell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#Create short-hand for directory root\n",
    "cor_dir = \"/Users/Benjamin's/Documents/ELI_Data_Mining/Data-Archive/1_sanitized/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 48384 entries, 1 to 48420\n",
      "Data columns (total 8 columns):\n",
      "question_id        48384 non-null int64\n",
      "anon_id            48353 non-null object\n",
      "user_file_id       48384 non-null int64\n",
      "text               47175 non-null object\n",
      "directory          14 non-null object\n",
      "is_doublespaced    48384 non-null int64\n",
      "is_plagiarized     48384 non-null int64\n",
      "is_deleted         48384 non-null int64\n",
      "dtypes: int64(5), object(3)\n",
      "memory usage: 3.3+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 913 entries, ez9 to bn6\n",
      "Data columns (total 20 columns):\n",
      "gender                       913 non-null object\n",
      "birth_year                   913 non-null int64\n",
      "native_language              913 non-null object\n",
      "language_used_at_home        912 non-null object\n",
      "language_used_at_home_now    855 non-null object\n",
      "non_native_language_1        859 non-null object\n",
      "yrs_of_study_lang1           863 non-null object\n",
      "study_in_classroom_lang1     863 non-null float64\n",
      "ways_of_study_lang1          863 non-null object\n",
      "non_native_language_2        309 non-null object\n",
      "yrs_of_study_lang2           312 non-null object\n",
      "study_in_classroom_lang2     863 non-null float64\n",
      "ways_of_study_lang2          863 non-null object\n",
      "non_native_language_3        55 non-null object\n",
      "yrs_of_study_lang3           59 non-null object\n",
      "study_in_classroom_lang3     863 non-null float64\n",
      "ways_of_study_lang3          863 non-null object\n",
      "createddate                  913 non-null object\n",
      "modifieddate                 909 non-null object\n",
      "course_history               913 non-null object\n",
      "dtypes: float64(3), int64(1), object(16)\n",
      "memory usage: 149.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#Add starter code created by Na-Rae Han for the ELI research group\n",
    "from elitools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student information (S_info_csv and S_info_df) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process the student_information.csv file\n",
    "S_info_csv = cor_dir + \"student_information.csv\"\n",
    "S_info_df = pd.read_csv(S_info_csv, index_col = 'anon_id')\n",
    "\n",
    "S_info_df.head() #Issues still apparent with integers turned into floats\n",
    "S_info_df.tail(10) #6 anon_id with no personal info - perhaps not students and to be 'pruned', as well as teachers with 'English' as the native language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove anyone with 'English' or 'NaN' as their native_language, i.e. not students\n",
    "\n",
    "#First try to create filters\n",
    "\n",
    "Englishfilter = S_info_df['native_language'] == 'English' #first filter works\n",
    "NaNfilter = S_info_df['native_language'] == np.nan #second filter doesn't\n",
    "\n",
    "fake_Ss = S_info_df.loc[Englishfilter] #works, but...\n",
    "fake_Ss\n",
    "\n",
    "#fake_Ss = S_info_df.loc[(Englishfilter) or (NaNfilter)] #doesn't work\n",
    "#fake_Ss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student responses (answer_csv and answer_df) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process answer.csv file\n",
    "answer_csv = cor_dir + \"answer.csv\"\n",
    "answer_df = pd.read_csv(answer_csv, index_col = 'answer_id')\n",
    "\n",
    "answer_df.head()\n",
    "answer_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course IDs ###\n",
    "(should help with finding specific texts and linking other data frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process course.csv file\n",
    "course_csv = cor_dir + \"course.csv\"\n",
    "course_df = pd.read_csv(course_csv, index_col = 'course_id')\n",
    "\n",
    "course_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  user_file_internal ###\n",
    "- big csv file with a lot of information\n",
    "- should help with finding specific texts and linking other data frames\n",
    "- includes file_type_id, course_id, and paths of text and wav files (i.e. all the spoken responses I need)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process user_file_wavtxt.csv file\n",
    "user_csv = cor_dir + \"user_file_internal.csv\"\n",
    "user_df = pd.read_csv(user_csv, index_col = 'user_file_id')\n",
    "\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic info about dataframes ###\n",
    "\n",
    "The following information is an overview of the four dataframes/csv files currently being looked at:\n",
    "\n",
    "#### S_info_df ####\n",
    "Size:\n",
    "- there are 941 entries, i.e. students, although at least 9 need to be removed once filters can be made to work\n",
    "- 21 columns including info about languages spoken, personal data like age, and learning preferences\n",
    "- Some columns will likely be removed if deemed unhelpful/unnecessary (e.g. 4th language spoken)\n",
    "- Some data is normalized, e.g. years of study, but others was open, resulting in very varied responses\n",
    "\n",
    "Connection to other dataframes:\n",
    "- link to answer_df is anon_id\n",
    "\n",
    "Most useful columns for this project:\n",
    "- anon_id (for linking to other df)\n",
    "- L1, gender, time studying, age (for data analysis)  \n",
    "\n",
    "\n",
    "#### answer_df ####\n",
    "Size:\n",
    "- there are 47175 'text' entries, i.e. student responses, although 48384 total rows. The remaining (including many null texts need to be removed as without texts they serve no purpose\n",
    "- 9 columns including info about the question, the answer, and characteristics of the text (like if it was plagiarized)\n",
    "\n",
    "Connection to other dataframes:\n",
    "- link to S_info_df and course_df is anon_id column\n",
    "\n",
    "Most useful columns for this project:\n",
    "- answer_id (shorthand for the individual texts to be analyzed)\n",
    "- text (the most important column so far) -> to be converted into tokens, bigrams, etc.  \n",
    "- anon_id (for linking to other df)\n",
    "\n",
    "\n",
    "#### course_df ####\n",
    "Size:\n",
    "- there are 1071 entries, i.e. one row for each course\n",
    "- 6 columns including info about the course and class, both in terms of their assigned number and a description\n",
    "\n",
    "Connection to other dataframes:\n",
    "- link to user_df is course_id \n",
    "\n",
    "Most useful columns for this project:\n",
    "- only really useful as a transition for linking to other df  \n",
    "\n",
    "\n",
    "#### user_df ####\n",
    "Size:\n",
    "- there are 76371 rows, each with a file_id number. However, it is unclear how to use this informatin effectively.\n",
    "- There are 29 columns, although many are not useful for this project\n",
    "- A lot of the cells have no input\n",
    "- Some columns will likely be removed if deemed unhelpful/unnecessary\n",
    "\n",
    "Connection to other dataframes:\n",
    "- link to course_df is course_id column\n",
    "\n",
    "Most useful columns for this project:\n",
    "- course_id (to link to other DF)\n",
    "- file_type_id (for indicating the type of activity used in class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_info_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating find_stuff function ###\n",
    "\n",
    "Goal: create a function that allows for easy retrieval within, from the various different, dataframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from initial work of Brianna - thank you!\n",
    "\n",
    "#this works to find all the course_id entries for a particular class type, in this case '3' which == speaking\n",
    "\n",
    "def find_stuff(df, class_type):\n",
    "    class_id = df.loc[df['class_id'] == class_type]\n",
    "    return class_id\n",
    "\n",
    "test = find_stuff(course_df, 3)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test #2\n",
    "\n",
    "test2 = find_stuff(course_df, 5)\n",
    "test2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next step is to either expand on this function or create other similar ones to allow look up of other types of info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization of answers ###\n",
    "\n",
    "Goal: tokenize the text in answer.csv to allow for further analysis (bigrams, lexical diversity, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find column to tokenize\n",
    "answer_df[['text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With the magic of stackoverflow, this seems to work, converting NaN to empty strings\n",
    "answer_df = answer_df[answer_df['text'].notnull()]\n",
    "answer_df['toks'] = answer_df.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\n",
    "\n",
    "answer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams###\n",
    "\n",
    "Goal: create a bigram columns from the tok column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mini-test to make sure I am creating bigrams correctly\n",
    "\n",
    "bigram_test = answer_df.toks[1]\n",
    "bigram_test\n",
    "list(nltk.bigrams(bigram_test))\n",
    "\n",
    "#test works, let's try on dataframe\n",
    "\n",
    "answer_df['bigrams'] = answer_df.toks.apply(lambda x: list(nltk.bigrams(x)))\n",
    "answer_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create frequency dictionary for entire corpus ###\n",
    "\n",
    "Frequency dictionary for all toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdict = nltk.FreqDist(answer_df.toks[1])\n",
    "random.sample(list(testdict.items()),5) #random 5-item sample\n",
    "#looks ok, now to apply to the whole column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_corpus = ' '.join(answer_df['text'])\n",
    "answer_corpus[:100]\n",
    "answer_corpus_tok = nltk.word_tokenize(answer_corpus)\n",
    "answer_corpus_tok[:20]\n",
    "\n",
    "#probably not the most efficient way but it seems to have worked at least for tokenizing whole corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_dict = nltk.FreqDist(answer_corpus_tok)\n",
    "random.sample(list(answer_dict.items()),5) #random 5-item sample\n",
    "\n",
    "#success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create frequency dictionary for bigrams of entire corpus ###\n",
    "\n",
    "Attempting to create frequency dictionary for all bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try to do this from the answer_corpus_tok\n",
    "\n",
    "answer_corpus_bigrams = list(nltk.bigrams(answer_corpus_tok))\n",
    "answer_corpus_bigrams[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now time for the dictionary\n",
    "answer_bigram_dict = nltk.FreqDist(answer_corpus_bigrams)\n",
    "random.sample(list(answer_bigram_dict.items()),5) #random 5-item sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Progress-report 2\n",
    "\n",
    "The following is everything that has been completed since Progress Report 2.  See progress_report.MD for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next goals:\n",
    "Create another DF called bigrams_df with bigrams, MI scores, occurences per million score, and perhaps more to bge added later. To do so:  \n",
    "1) Create function for calculating MI \n",
    "2) Create function for calculating occurences per million for unigrams and bigrams  \n",
    "3) Apply the MI formula for pairs of words in the bigram list and create a column in the new DF  \n",
    "4) Apply the occurences per million for bigrams and create a column in the new DF  \n",
    "5) Create a column showing percentage of time the bigrams are used by the three proficiency levels  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Mutual Information (MI)\n",
    "\n",
    "(from https://corpus.byu.edu/mutualInformation.asp)  \n",
    "\n",
    "Mutual Information is calculated as follows:  \n",
    "MI = log ( (AB * sizeCorpus) / (A * B * span) ) / log (2)  \n",
    "\n",
    "Suppose we are calculating the MI for the collocate color near purple in BYU-BNC.  \n",
    "\n",
    "A = frequency of node word (e.g. purple): 1262  \n",
    "B = frequency of collocate (e.g. color): 115  \n",
    "AB = frequency of collocate near the node word (e.g. color near purple): 24  \n",
    "sizeCorpus= size of corpus (# words; in this case the BNC): 96,263,399  \n",
    "span = span of words (e.g. 3 to left and 3 to right of node word): 6  \n",
    "log (2) is literally the log10 of the number 2: .30103  \n",
    "\n",
    "MI = 11.37 = log ( (24 * 96,263,399) / (1262 * 115 * 6) ) / .30103  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Found something called 'Pointwise Mutual Information' - I believe it is what I am looking for.\n",
    "\n",
    "import math\n",
    "from math import log\n",
    "\n",
    "def MI(word1, word2):\n",
    "  prob_word1 = answer_dict[word1] / float(sum(answer_dict.values()))\n",
    "  prob_word2 = answer_dict[word2] / float(sum(answer_dict.values()))\n",
    "  prob_word1_word2 = answer_bigram_dict[word1, word2] / float(sum(answer_bigram_dict.values()))\n",
    "  return math.log(prob_word1_word2/float(prob_word1*prob_word2),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#something I imagine has an average MI\n",
    "answer_bigram_dict['young', 'people']\n",
    "answer_dict['young']\n",
    "answer_dict['people']\n",
    "\n",
    "#Yes - 'young' collocates strongly with 'people' (about 25% of time) but 'people' doesn't collocate strongly with 'young'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MI('young','people')\n",
    "\n",
    "#That is the standard range for a M1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time to try one that shouldn't have as high MI, e.g. 'man' with 'the'\n",
    "\n",
    "answer_bigram_dict['the', 'man']\n",
    "answer_dict['the']\n",
    "answer_dict['man']\n",
    "\n",
    "MI('the', 'man')\n",
    "\n",
    "#With a smoothing of MI3, this would not show up on collocation lists (a good thing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating combined dataframe for easier analysis and viewing\n",
    "- joins answer_df, user_df, and course_df\n",
    "- removes unnecessary columns\n",
    "- narrows results down to only answers from writing classes and first versions of their work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#join answer_df and user_df along 'user_file_id' column\n",
    "combo_df = answer_df.join(user_df, on='user_file_id', lsuffix='user_file_id')\n",
    "\n",
    "#now join this new df with course_df along 'course_id' column\n",
    "combo_df = combo_df.join(course_df, on='course_id', lsuffix='user_file_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dropping unnecessary columns (there a lot)\n",
    "combo_df = combo_df.drop(['directoryuser_file_id', 'is_doublespaced', 'is_plagiarized', 'is_deleteduser_file_id',\n",
    "                            'modifiedby', 'modifieddate', 'allow_submit_after_duedate', 'anon_id', 'file_type_id',\n",
    "                            'file_info_id', 'user_file_parent_id', 'createdby', 'session_id',\n",
    "                           'document_id','filename', 'content_text', 'createddate', 'allow_multiple_accesses',\n",
    "                           'directoryuser_file_id', 'is_doublespaced', 'is_plagiarized', 'is_deleteduser_file_id',\n",
    "                           'modifiedby', 'modifieddate', 'allow_submit_after_duedate','activity', 'order_num', \n",
    "                            'due_date', 'post_date', 'assignment_name', 'directory', 'activity', 'semester',\n",
    "                            'order_num', 'due_date', 'post_date', 'assignment_name', 'allow_double_spacing',\n",
    "                           'duration', 'pull_off_date', 'direction', 'grammar_qp_id', 'is_deleted',\n",
    "                            'section', 'course_description'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keeping only 1st versions of students' work\n",
    "combo_df = combo_df.loc[combo_df['version'] == 1]\n",
    "\n",
    "#'version' column now unnecessary\n",
    "combo_df = combo_df.drop(['version'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keeping only answers from writing classes (class_id = 2)\n",
    "combo_df = combo_df.loc[combo_df['class_id'] == 2]\n",
    "\n",
    "#'class_id' column now unnecessary\n",
    "combo_df = combo_df.drop(['class_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#just change the order of columns to something more logical and rename some columns\n",
    "combo_df = combo_df[['question_id','user_file_id', 'anon_iduser_file_id', 'level_id', 'course_id', 'text', 'toks', 'bigrams']]\n",
    "combo_df.rename(columns={'anon_iduser_file_id':'anon_id'}, inplace=True)\n",
    "\n",
    "#finished result =  much cleaner\n",
    "combo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove level 2 (too few to be usefully analyzed)\n",
    "\n",
    "combo_df.level_id.unique()\n",
    "\n",
    "combo_df = combo_df.loc[combo_df['level_id'] != 2]\n",
    "\n",
    "combo_df.level_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function for calculating occurrences per million for unigrams and bigrams  \n",
    "\n",
    "Formula:\n",
    "\n",
    "FN = FO(1,000,000) / C\n",
    "\n",
    "FN = normalized frequency\n",
    "FO = observed frequency\n",
    "C = corpus size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create new freq dicts for combo_df (unigrams and bigrams) using same \n",
    "#code as earlier versions with answer_df\n",
    "\n",
    "combo_corpus = ' '.join(combo_df['text'])\n",
    "combo_corpus_tok = nltk.word_tokenize(combo_corpus)\n",
    "combo_corpus_tok = list(map(lambda x:x.lower(),combo_corpus_tok)) #making everything lowercase\n",
    "combo_unigram_dict = nltk.FreqDist(combo_corpus_tok)\n",
    "\n",
    "combo_corpus_bigrams = list(nltk.bigrams(combo_corpus_tok))\n",
    "combo_bigram_dict = nltk.FreqDist(combo_corpus_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total number of unigrams\n",
    "total_unigrams = len(combo_corpus_tok)\n",
    "\n",
    "#total number of bigrams\n",
    "total_bigrams = len(combo_corpus_bigrams)\n",
    "\n",
    "total_unigrams\n",
    "total_bigrams\n",
    "\n",
    "#different by one a bigrams will be naturally be unigrams - 1 (for the first one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create function where you enter the unigram and it tells \n",
    "#you the frequency in the corpus per million tokens\n",
    "\n",
    "def unigram_per_M(unigram):\n",
    "   return (combo_unigram_dict[unigram]*1000000) / total_unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test manually and with defined function\n",
    "combo_unigram_dict['the']\n",
    "\n",
    "(108346*1000000)/2549012\n",
    "unigram_per_M('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create function where you enter the bigram and it tells you the frequency in the corpus per million tokens\n",
    "\n",
    "def bigram_per_M(word1, word2):\n",
    "   return (combo_bigram_dict[word1, word2]*1000000) / total_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test manually and with defined function\n",
    "combo_bigram_dict['the', 'man']\n",
    "\n",
    "(92*1000000)/2549011\n",
    "bigram_per_M('the', 'man')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a bigram_df showing relevant info based on above formulas\n",
    "- columns for this dataframe:\n",
    "    - default index\n",
    "    - bigrams\n",
    "    - MI scores\n",
    "    - occurrences per million\n",
    "    - normalized percentage used at each proficiency level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_df = pd.DataFrame.from_dict(combo_bigram_dict,orient='index')\n",
    "bigram_df = bigram_df.reset_index()\n",
    "bigram_df = bigram_df.rename(columns = {0:'tokens', 'index': 'bigram'})\n",
    "bigram_df.head()\n",
    "\n",
    "#first two bullet points complete - now to add more columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Changing bigram tuples to lists for easier manipulation\n",
    "bigram_df['bigram'] = [list(x) for x in bigram_df['bigram']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating MI column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#New MI calculator based on new dictionary\n",
    "\n",
    "def MI(word1, word2):\n",
    "  prob_word1 = combo_unigram_dict[word1] / float(sum(combo_unigram_dict.values()))\n",
    "  prob_word2 = combo_unigram_dict[word2] / float(sum(combo_unigram_dict.values()))\n",
    "  prob_word1_word2 = combo_bigram_dict[word1, word2] / float(sum(combo_bigram_dict.values()))\n",
    "  return math.log(prob_word1_word2/float(prob_word1*prob_word2),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = bigram_df.iloc[0][0]\n",
    "MI(test[0], test[1])\n",
    "\n",
    "#it works on one cell, so theoretically should work on all..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bigram_df['MI'] = [MI(x[0], x[1]) for x in bigram_df['bigram']]\n",
    "\n",
    "#it took a few hours to run it, but it worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_df[['MI']] = bigram_df[['MI']].apply(lambda x: pd.Series.round(x, 2))\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating per_million column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing one one cell first\n",
    "bigram_per_M(test[0], test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_df['per_million'] = [bigram_per_M(x[0], x[1]) for x in bigram_df['bigram']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_df[['per_million']] = bigram_df[['per_million']].apply(lambda x: pd.Series.round(x, 2))\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_df['per_million'] = [bigram_per_M(x[0], x[1]) for x in bigram_df['bigram']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating 'normalized toks per level' and 'relative percentage per level' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create level dataframes\n",
    "level_3 = combo_df.loc[combo_df['level_id'] == 3, :] \n",
    "level_4 = combo_df.loc[combo_df['level_id'] == 4, :] \n",
    "level_5 = combo_df.loc[combo_df['level_id'] == 5, :] \n",
    "\n",
    "#create frequency dictionaries for each level\n",
    "level_3_corpus = ' '.join(level_3['text'])\n",
    "level_3_tok = nltk.word_tokenize(level_3_corpus)\n",
    "level_3_tok = list(map(lambda x:x.lower(),level_3_tok))\n",
    "level_3_bigrams = list(nltk.bigrams(level_3_tok))\n",
    "level_3_bigram_dict = nltk.FreqDist(level_3_bigrams)\n",
    "\n",
    "level_4_corpus = ' '.join(level_4['text'])\n",
    "level_4_tok = nltk.word_tokenize(level_4_corpus)\n",
    "level_4_tok = list(map(lambda x:x.lower(),level_4_tok))\n",
    "level_4_bigrams = list(nltk.bigrams(level_4_tok))\n",
    "level_4_bigram_dict = nltk.FreqDist(level_4_bigrams)\n",
    "\n",
    "level_5_corpus = ' '.join(level_5['text'])\n",
    "level_5_tok = nltk.word_tokenize(level_5_corpus)\n",
    "level_5_tok = list(map(lambda x:x.lower(),level_5_tok))\n",
    "level_5_bigrams = list(nltk.bigrams(level_5_tok))\n",
    "level_5_bigram_dict = nltk.FreqDist(level_5_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test to see what I want in each cell in the level_3 column\n",
    "#I need the values from level_3_bigram_dict divided by the value from combo_bigram_dict\n",
    "\n",
    "#for example\n",
    "level_3_bigram_dict['in', 'the'] / combo_bigram_dict['in', 'the'] \n",
    "\n",
    "#or better yet as a percentage\n",
    "\"{0:.2f}%\".format(level_3_bigram_dict['in', 'the'] / combo_bigram_dict['in', 'the'] * 100)\n",
    "\n",
    "#totals for all 3 levels should add up to 100%\n",
    "\"{0:.2f}%\".format(level_3_bigram_dict['in', 'the'] / combo_bigram_dict['in', 'the'] * 100)\n",
    "\"{0:.2f}%\".format(level_4_bigram_dict['in', 'the'] / combo_bigram_dict['in', 'the'] * 100)\n",
    "\"{0:.2f}%\".format(level_5_bigram_dict['in', 'the'] / combo_bigram_dict['in', 'the'] * 100)\n",
    "\n",
    "12.17 + 40.75 + 47.07 #close enough!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_3_bigram_dict['in', 'the']\n",
    "level_4_bigram_dict['in', 'the']\n",
    "level_5_bigram_dict['in', 'the']\n",
    "\n",
    "1360+4553+5259\n",
    "\n",
    "combo_bigram_dict['in', 'the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#also necessary to normalize as different number of responses at each level\n",
    "\n",
    "#weighting for each level\n",
    "level_3_weighting = len(level_3.index) / len(combo_df.index)\n",
    "level_4_weighting = len(level_4.index) / len(combo_df.index)\n",
    "level_5_weighting = len(level_5.index) / len(combo_df.index)\n",
    "\n",
    "level_3_weighting\n",
    "level_4_weighting\n",
    "level_5_weighting\n",
    "\n",
    "level_3_weighting+level_4_weighting+level_5_weighting #should equal 100\n",
    "\n",
    "#difference between observed and expected, i.e. expected weighting (.33) -  actual weighting (level_N_percent)\n",
    "level_3_change = (1/3) - level_3_weighting\n",
    "level_4_change = (1/3) - level_4_weighting\n",
    "level_5_change = (1/3) - level_5_weighting\n",
    "\n",
    "level_3_change\n",
    "level_4_change\n",
    "level_5_change\n",
    "\n",
    "round(level_3_change + level_4_change + level_5_change, 2) # should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of normalizing with ['in', 'the'] bigram\n",
    "\n",
    "#un-normalized number\n",
    "level_3_bigram_dict['in', 'the']\n",
    "level_4_bigram_dict['in', 'the']\n",
    "level_5_bigram_dict['in', 'the']\n",
    "combo_bigram_dict['in', 'the']\n",
    "\n",
    "#normalized number\n",
    "n3 = level_3_bigram_dict['in', 'the'] + (combo_bigram_dict['in', 'the'] * level_3_change)\n",
    "n4 = level_4_bigram_dict['in', 'the'] + (combo_bigram_dict['in', 'the'] * level_4_change)\n",
    "n5 = level_5_bigram_dict['in', 'the'] + (combo_bigram_dict['in', 'the'] * level_5_change)\n",
    "\n",
    "n3\n",
    "n4\n",
    "n5\n",
    "\n",
    "n3 + n4 + n5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function for the above\n",
    "\n",
    "def norm_toks_level3(word1, word2):\n",
    "    return int((level_3_bigram_dict[word1,word2] + (combo_bigram_dict[word1,word2] * level_3_change)))\n",
    "\n",
    "def norm_toks_level4(word1, word2):\n",
    "    return int((level_4_bigram_dict[word1,word2] + (combo_bigram_dict[word1,word2] * level_4_change)))\n",
    "            \n",
    "def norm_toks_level5(word1, word2):\n",
    "    return int((level_5_bigram_dict[word1,word2] + (combo_bigram_dict[word1,word2] * level_5_change)))\n",
    "\n",
    "#Example time:\n",
    "norm_toks_level3('in', 'the')\n",
    "norm_toks_level4('in', 'the')\n",
    "norm_toks_level5('in', 'the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And as a comparative percentage\n",
    "def norm_percent_level3(word1, word2):\n",
    "    return \"{0:.2f}%\".format(((level_3_bigram_dict[word1,word2] + (combo_bigram_dict[word1,word2] * level_3_change)) / combo_bigram_dict[word1, word2])*100)\n",
    "\n",
    "def norm_percent_level4(word1, word2):\n",
    "    return \"{0:.2f}%\".format(((level_4_bigram_dict[word1,word2] + (combo_bigram_dict[word1,word2] * level_4_change)) / combo_bigram_dict[word1, word2])*100)\n",
    "\n",
    "def norm_percent_level5(word1, word2):\n",
    "    return \"{0:.2f}%\".format(((level_5_bigram_dict[word1,word2] + (combo_bigram_dict[word1,word2] * level_5_change)) / combo_bigram_dict[word1, word2])*100)\n",
    "\n",
    "#Example time:\n",
    "norm_percent_level3('in', 'the')\n",
    "norm_percent_level4('in', 'the')\n",
    "norm_percent_level5('in', 'the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized tokens pplied to the whole dataframe\n",
    "\n",
    "bigram_df['lv3_norm_toks'] = [norm_toks_level3(x[0], x[1]) for x in bigram_df['bigram']]\n",
    "bigram_df['lv4_norm_toks'] = [norm_toks_level4(x[0], x[1]) for x in bigram_df['bigram']]\n",
    "bigram_df['lv5_norm_toks'] = [norm_toks_level5(x[0], x[1]) for x in bigram_df['bigram']]\n",
    "\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And now the comparative percentages\n",
    "\n",
    "bigram_df['level_3'] = [norm_percent_level3(x[0], x[1]) for x in bigram_df['bigram']]\n",
    "bigram_df['level_4'] = [norm_percent_level4(x[0], x[1]) for x in bigram_df['bigram']]\n",
    "bigram_df['level_5'] = [norm_percent_level5(x[0], x[1]) for x in bigram_df['bigram']]\n",
    "\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating level per_million columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create per_million columns for each level\n",
    "\n",
    "bigram_df['lv3_per_M'] = round(bigram_df['lv3_norm_toks']*1000000/total_bigrams, 2)\n",
    "bigram_df['lv4_per_M'] = round(bigram_df['lv4_norm_toks']*1000000/total_bigrams, 2)\n",
    "bigram_df['lv5_per_M'] = round(bigram_df['lv5_norm_toks']*1000000/total_bigrams, 2)\n",
    "\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A lot of work for a very small final dataframe, but at least it should be usable for machine analysis and future research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see a few 'Top 20' lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_df.index += 1 #lists look better starting at 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bigram_MI = bigram_df.sort_values('MI', ascending = False).reset_index(drop=True)\n",
    "top_bigram_MI.index += 1\n",
    "top_bigram_MI[top_bigram_MI['tokens'] >= 50].head(20) #set min number to get rid of random names and rarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bigram_toks = bigram_df.sort_values('tokens', ascending = False).reset_index(drop=True)\n",
    "top_bigram_toks.index += 1 #lists look better starting at 1\n",
    "top_bigram_toks.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bigram_level3 = bigram_df.sort_values('level_3', ascending = False).reset_index(drop=True)\n",
    "top_bigram_level3.index += 1\n",
    "top_bigram_level3.head(20)\n",
    "\n",
    "top_bigram_level4 = bigram_df.sort_values('level_4', ascending = False).reset_index(drop=True)\n",
    "top_bigram_level4.index += 1\n",
    "top_bigram_level4.head(20)\n",
    "\n",
    "top_bigram_level5 = bigram_df.sort_values('level_5', ascending = False).reset_index(drop=True)\n",
    "top_bigram_level5.index += 1\n",
    "top_bigram_level5.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next goals (for final submission of code):  \n",
    "<br>\n",
    "_Final analysis touch ups_:\n",
    "-\tDeal with capitalization issues skewing data **COMPLETED AT EARLIER combo_corpus_tok STAGE**\n",
    "-\tRemove levels from combo_df other than 3,4,5 (easy to do but need time to re-run whole script afterwards) **COMPLETED AT EARLIER combo_df STAGE**\n",
    "\n",
    "\n",
    "_Machine learning_:\n",
    "- Predict level based on bigram frequency (types and tokens)\n",
    "- Predict level based on MI of bigrams used \n",
    "\n",
    "\n",
    "_Visualizations_:\n",
    "- Create visualizations (heat maps for predictions and bar graphs for observed stats)\n",
    "- Sort bigram_df in different orders to produce tables of common bigrams\n",
    "- Tidy up notebook / add descriptive detail"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
