{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# project_code_final: Analysis of the ELI Data #\n",
    "## Ben Naismith ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook ###\n",
    "\n",
    "This notebook contains the most up-to-date and streamlined code for the project. For early cleaning and analysis efforts, please refer to the following documents:\n",
    "- Cleaning: https://github.com/Data-Science-for-Linguists/Bigram-analysis-of-writing-from-the-ELI/tree/master/early_experiments/project_code1_cleaning.ipynb\n",
    "- Analysis: https://github.com/Data-Science-for-Linguists/Bigram-analysis-of-writing-from-the-ELI/tree/master/early_experiments/project_code2_analysis.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents ###\n",
    "\n",
    "1.  [Data sharing plan](#1.-Data-sharing-plan): description of sample data contents and licensing agreement\n",
    "2.  [Initial setup](#2.-Initial-setup): importing necessary modules\n",
    "3.  [Student information](#3.-Student-information): S_info_csv and S_info_df\n",
    "4.  [Student responses](#4.-Student-responses): answer_csv and answer_df\n",
    "5.  [Course IDs](#5.-Course-IDs): course_csv and course_df\n",
    "6.  [User file internal](#6.-user_file_internal): user_csv and user_df\n",
    "7.  [Basic info about dataframes](#7.-Basic-info-about-dataframes): description of dataframes in sections 3-6\n",
    "8.  [Tokenization of answers](#8.-Tokenization-of-answers): tokenization from answers_df\n",
    "9.  [Bigrams](#9.-Bigrams): creating bigram column from tokens\n",
    "10. [Corpus frequency dictionary](#10.-Corpus-frequency-dictionary): creating unigram frequency dictionary\n",
    "11. [Bigram frequency dictionary](#11.-Bigram-frequency-dictionary): creating bigram frequency dictionary\n",
    "12. [Mutual Information](#12.-Mutual-Information): creating a function for calculating MI\n",
    "13. [Combo dataframe](#13.-Combo-dataframe): combines earlier dataframes for easier analysis\n",
    "14. [Occurrences per million](#14.-Occurrences-per-million): create function to calculate occurrences per million\n",
    "15. [bigram_df](#15.-bigram_df): create new dataframe using new functions from earlier sections\n",
    "16. [levels_df](#16.-levels_df): create a small dataframe with useful overall statistics\n",
    "17. [Pickling](#17.-Pickling): saving pickles of dataframes and MI dict\n",
    "18. [Visualizations](#18.-Visualizations): create function to calculate occurrences per million"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data sharing plan ###\n",
    "\n",
    "The full ELI data set (see project_plan.md) is private at this time. Below is a workbook with the current code for analyzing that data. In order to see how the code works, snippets of data have been displayed throughout.\n",
    "\n",
    "A sample of the 'sanitized' data is included in the 'data' folder in this same repository. It contains samples of the four CSV files referred to in this code, consisting of 1000 answers, in order to allow for testing and reproducibility by others of the code. These 1000 answers are the first 1000 from the answer_csv file and correspond to user_file_id 7505 to 10108.\n",
    "\n",
    "Ultimately, it is the intention of the dataset's authors for the entire dataset to be made public, with a CC license. Please see the LICENSE_notes.md for details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initial setup ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import necesary modules\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "#return every shell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#Create short-hand for directory root\n",
    "cor_dir = \"/Users/Benjamin's/Documents/ELI_Data_Mining/Data-Archive/1_sanitized/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 48384 entries, 1 to 48420\n",
      "Data columns (total 8 columns):\n",
      "question_id        48384 non-null int64\n",
      "anon_id            48353 non-null object\n",
      "user_file_id       48384 non-null int64\n",
      "text               47175 non-null object\n",
      "directory          14 non-null object\n",
      "is_doublespaced    48384 non-null int64\n",
      "is_plagiarized     48384 non-null int64\n",
      "is_deleted         48384 non-null int64\n",
      "dtypes: int64(5), object(3)\n",
      "memory usage: 3.3+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 913 entries, ez9 to bn6\n",
      "Data columns (total 20 columns):\n",
      "gender                       913 non-null object\n",
      "birth_year                   913 non-null int64\n",
      "native_language              913 non-null object\n",
      "language_used_at_home        912 non-null object\n",
      "language_used_at_home_now    855 non-null object\n",
      "non_native_language_1        859 non-null object\n",
      "yrs_of_study_lang1           863 non-null object\n",
      "study_in_classroom_lang1     863 non-null float64\n",
      "ways_of_study_lang1          863 non-null object\n",
      "non_native_language_2        309 non-null object\n",
      "yrs_of_study_lang2           312 non-null object\n",
      "study_in_classroom_lang2     863 non-null float64\n",
      "ways_of_study_lang2          863 non-null object\n",
      "non_native_language_3        55 non-null object\n",
      "yrs_of_study_lang3           59 non-null object\n",
      "study_in_classroom_lang3     863 non-null float64\n",
      "ways_of_study_lang3          863 non-null object\n",
      "createddate                  913 non-null object\n",
      "modifieddate                 909 non-null object\n",
      "course_history               913 non-null object\n",
      "dtypes: float64(3), int64(1), object(16)\n",
      "memory usage: 149.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#Add starter code created by Na-Rae Han for the ELI research group\n",
    "from elitools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Student information \n",
    "- S_info_csv\n",
    "- S_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>native_language</th>\n",
       "      <th>language_used_at_home</th>\n",
       "      <th>language_used_at_home_now</th>\n",
       "      <th>non_native_language_1</th>\n",
       "      <th>yrs_of_study_lang1</th>\n",
       "      <th>study_in_classroom_lang1</th>\n",
       "      <th>ways_of_study_lang1</th>\n",
       "      <th>non_native_language_2</th>\n",
       "      <th>yrs_of_study_lang2</th>\n",
       "      <th>study_in_classroom_lang2</th>\n",
       "      <th>ways_of_study_lang2</th>\n",
       "      <th>non_native_language_3</th>\n",
       "      <th>yrs_of_study_lang3</th>\n",
       "      <th>study_in_classroom_lang3</th>\n",
       "      <th>ways_of_study_lang3</th>\n",
       "      <th>createddate</th>\n",
       "      <th>modifieddate</th>\n",
       "      <th>course_history</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anon_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ez9</th>\n",
       "      <td>Male</td>\n",
       "      <td>1978</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Studied...</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Studied by myself</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2006-01-30 15:07:18</td>\n",
       "      <td>2006-03-14 15:13:37</td>\n",
       "      <td>6;12;18;24;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gm3</th>\n",
       "      <td>Male</td>\n",
       "      <td>1980</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Had a native-speaker teacher;S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2006-01-30 15:07:28</td>\n",
       "      <td>2006-03-14 15:12:49</td>\n",
       "      <td>6;12;24;30;38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fg5</th>\n",
       "      <td>Male</td>\n",
       "      <td>1938</td>\n",
       "      <td>Nepali</td>\n",
       "      <td>Nepali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Had a n...</td>\n",
       "      <td>French</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Had a n...</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Studied by myself</td>\n",
       "      <td>2006-01-30 15:07:45</td>\n",
       "      <td>2006-03-14 15:11:36</td>\n",
       "      <td>18;24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ce5</th>\n",
       "      <td>Female</td>\n",
       "      <td>1984</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Had a n...</td>\n",
       "      <td>German</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Listened to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2006-01-30 15:07:49</td>\n",
       "      <td>2006-03-14 15:12:24</td>\n",
       "      <td>6;12;24;30;38;56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fi7</th>\n",
       "      <td>Female</td>\n",
       "      <td>1982</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean;Japanese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Had a native-speaker teacher;S...</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Listened to...</td>\n",
       "      <td>French</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Listened to...</td>\n",
       "      <td>2006-01-30 15:07:52</td>\n",
       "      <td>2006-03-14 15:12:17</td>\n",
       "      <td>6;12;24;30;38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gender  birth_year native_language language_used_at_home  \\\n",
       "anon_id                                                             \n",
       "ez9        Male        1978          Arabic                Arabic   \n",
       "gm3        Male        1980          Arabic                Arabic   \n",
       "fg5        Male        1938          Nepali                Nepali   \n",
       "ce5      Female        1984          Korean                Korean   \n",
       "fi7      Female        1982          Korean       Korean;Japanese   \n",
       "\n",
       "        language_used_at_home_now non_native_language_1 yrs_of_study_lang1  \\\n",
       "anon_id                                                                      \n",
       "ez9                           NaN               English  more than 5 years   \n",
       "gm3                           NaN               English  more than 5 years   \n",
       "fg5                           NaN               English  more than 5 years   \n",
       "ce5                           NaN               English  more than 5 years   \n",
       "fi7                           NaN               English  more than 5 years   \n",
       "\n",
       "         study_in_classroom_lang1  \\\n",
       "anon_id                             \n",
       "ez9                           1.0   \n",
       "gm3                           1.0   \n",
       "fg5                           1.0   \n",
       "ce5                           1.0   \n",
       "fi7                           1.0   \n",
       "\n",
       "                                       ways_of_study_lang1  \\\n",
       "anon_id                                                      \n",
       "ez9      Studied grammar;Worked in pairs/groups;Studied...   \n",
       "gm3      Studied grammar;Had a native-speaker teacher;S...   \n",
       "fg5      Studied grammar;Worked in pairs/groups;Had a n...   \n",
       "ce5      Studied grammar;Worked in pairs/groups;Had a n...   \n",
       "fi7      Studied grammar;Had a native-speaker teacher;S...   \n",
       "\n",
       "        non_native_language_2 yrs_of_study_lang2  study_in_classroom_lang2  \\\n",
       "anon_id                                                                      \n",
       "ez9                   Turkish   less than 1 year                       0.0   \n",
       "gm3                       NaN                NaN                       0.0   \n",
       "fg5                    French   less than 1 year                       1.0   \n",
       "ce5                    German          1-2 years                       1.0   \n",
       "fi7                  Japanese   less than 1 year                       1.0   \n",
       "\n",
       "                                       ways_of_study_lang2  \\\n",
       "anon_id                                                      \n",
       "ez9                                      Studied by myself   \n",
       "gm3                                                  other   \n",
       "fg5      Studied grammar;Worked in pairs/groups;Had a n...   \n",
       "ce5      Studied grammar;Studied vocabulary;Listened to...   \n",
       "fi7      Studied grammar;Studied vocabulary;Listened to...   \n",
       "\n",
       "        non_native_language_3 yrs_of_study_lang3  study_in_classroom_lang3  \\\n",
       "anon_id                                                                      \n",
       "ez9                       NaN                NaN                       0.0   \n",
       "gm3                       NaN                NaN                       0.0   \n",
       "fg5                     Hindi  more than 5 years                       0.0   \n",
       "ce5                       NaN                NaN                       0.0   \n",
       "fi7                    French          1-2 years                       1.0   \n",
       "\n",
       "                                       ways_of_study_lang3  \\\n",
       "anon_id                                                      \n",
       "ez9                                                  other   \n",
       "gm3                                                  other   \n",
       "fg5                                      Studied by myself   \n",
       "ce5                                                  other   \n",
       "fi7      Studied grammar;Studied vocabulary;Listened to...   \n",
       "\n",
       "                 createddate         modifieddate    course_history  \n",
       "anon_id                                                              \n",
       "ez9      2006-01-30 15:07:18  2006-03-14 15:13:37     6;12;18;24;30  \n",
       "gm3      2006-01-30 15:07:28  2006-03-14 15:12:49     6;12;24;30;38  \n",
       "fg5      2006-01-30 15:07:45  2006-03-14 15:11:36             18;24  \n",
       "ce5      2006-01-30 15:07:49  2006-03-14 15:12:24  6;12;24;30;38;56  \n",
       "fi7      2006-01-30 15:07:52  2006-03-14 15:12:17     6;12;24;30;38  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>native_language</th>\n",
       "      <th>language_used_at_home</th>\n",
       "      <th>language_used_at_home_now</th>\n",
       "      <th>non_native_language_1</th>\n",
       "      <th>yrs_of_study_lang1</th>\n",
       "      <th>study_in_classroom_lang1</th>\n",
       "      <th>ways_of_study_lang1</th>\n",
       "      <th>non_native_language_2</th>\n",
       "      <th>yrs_of_study_lang2</th>\n",
       "      <th>study_in_classroom_lang2</th>\n",
       "      <th>ways_of_study_lang2</th>\n",
       "      <th>non_native_language_3</th>\n",
       "      <th>yrs_of_study_lang3</th>\n",
       "      <th>study_in_classroom_lang3</th>\n",
       "      <th>ways_of_study_lang3</th>\n",
       "      <th>createddate</th>\n",
       "      <th>modifieddate</th>\n",
       "      <th>course_history</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anon_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ec5</th>\n",
       "      <td>Female</td>\n",
       "      <td>1963</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-16 14:08:05</td>\n",
       "      <td>2011-06-16 14:13:03</td>\n",
       "      <td>719;720;721;722;723;772;774;785;813;819;858;85...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cy2</th>\n",
       "      <td>Male</td>\n",
       "      <td>1988</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>English</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Had a n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:09:05</td>\n",
       "      <td>2011-06-20 14:11:31</td>\n",
       "      <td>845;846;847;871;872;927;928;931;949;950;1008;1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>br9</th>\n",
       "      <td>Female</td>\n",
       "      <td>1981</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Studied...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:09:15</td>\n",
       "      <td>2011-06-20 14:12:02</td>\n",
       "      <td>868;869;870;871;872;947;951;953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cl5</th>\n",
       "      <td>Male</td>\n",
       "      <td>1987</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>English</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Practiced s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:09:23</td>\n",
       "      <td>2011-06-20 14:13:16</td>\n",
       "      <td>770;771;778;779;781;856;857;859;861;871;952;95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de1</th>\n",
       "      <td>Male</td>\n",
       "      <td>1983</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Teacher spo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:09:27</td>\n",
       "      <td>2011-06-20 14:12:02</td>\n",
       "      <td>850;851;852;871;872;926;932;933;944;945;1008;1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ap0</th>\n",
       "      <td>Male</td>\n",
       "      <td>1978</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Listened to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:09:33</td>\n",
       "      <td>2011-06-20 14:12:52</td>\n",
       "      <td>845;846;847;871;872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gu4</th>\n",
       "      <td>Male</td>\n",
       "      <td>1983</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Studied by myself;I lived in a country where t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:09:34</td>\n",
       "      <td>2011-06-20 14:13:04</td>\n",
       "      <td>772;773;774;775;776;868;869;870;871;872;922;92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hb0</th>\n",
       "      <td>Female</td>\n",
       "      <td>1980</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>English</td>\n",
       "      <td>3-5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Had a native-speaker teacher;T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:09:38</td>\n",
       "      <td>2011-06-20 14:13:01</td>\n",
       "      <td>851;869;870;871;872;923;942;944;945;946;1008;1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dp8</th>\n",
       "      <td>Male</td>\n",
       "      <td>1991</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>English</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Worked in pairs/groups;Had a n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:10:15</td>\n",
       "      <td>2011-06-20 14:13:57</td>\n",
       "      <td>868;869;870;871;872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bn6</th>\n",
       "      <td>Male</td>\n",
       "      <td>1986</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>English</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Teacher spo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2011-06-20 14:11:17</td>\n",
       "      <td>2011-06-20 14:15:51</td>\n",
       "      <td>860;861;862;871;872;930;947;948;949;951;998;99...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gender  birth_year native_language language_used_at_home  \\\n",
       "anon_id                                                             \n",
       "ec5      Female        1963         Chinese               Chinese   \n",
       "cy2        Male        1988          Arabic                Arabic   \n",
       "br9      Female        1981         Chinese               Chinese   \n",
       "cl5        Male        1987          Arabic                Arabic   \n",
       "de1        Male        1983          Arabic                Arabic   \n",
       "ap0        Male        1978        Japanese              Japanese   \n",
       "gu4        Male        1983          Arabic                Arabic   \n",
       "hb0      Female        1980          Arabic                Arabic   \n",
       "dp8        Male        1991          Arabic        Arabic;English   \n",
       "bn6        Male        1986          Arabic        Arabic;English   \n",
       "\n",
       "        language_used_at_home_now non_native_language_1 yrs_of_study_lang1  \\\n",
       "anon_id                                                                      \n",
       "ec5                       Chinese                   NaN                NaN   \n",
       "cy2                        Arabic               English   less than 1 year   \n",
       "br9                       Chinese               English  more than 5 years   \n",
       "cl5                Arabic;English               English   less than 1 year   \n",
       "de1                        Arabic               English  more than 5 years   \n",
       "ap0                      Japanese               English  more than 5 years   \n",
       "gu4                Arabic;English                Arabic  more than 5 years   \n",
       "hb0                        Arabic               English          3-5 years   \n",
       "dp8                Arabic;English               English          1-2 years   \n",
       "bn6                Arabic;English               English  more than 5 years   \n",
       "\n",
       "         study_in_classroom_lang1  \\\n",
       "anon_id                             \n",
       "ec5                           NaN   \n",
       "cy2                           1.0   \n",
       "br9                           1.0   \n",
       "cl5                           1.0   \n",
       "de1                           1.0   \n",
       "ap0                           1.0   \n",
       "gu4                           0.0   \n",
       "hb0                           1.0   \n",
       "dp8                           1.0   \n",
       "bn6                           1.0   \n",
       "\n",
       "                                       ways_of_study_lang1  \\\n",
       "anon_id                                                      \n",
       "ec5                                                    NaN   \n",
       "cy2      Studied grammar;Worked in pairs/groups;Had a n...   \n",
       "br9      Studied grammar;Worked in pairs/groups;Studied...   \n",
       "cl5      Studied grammar;Studied vocabulary;Practiced s...   \n",
       "de1      Studied grammar;Studied vocabulary;Teacher spo...   \n",
       "ap0      Studied grammar;Studied vocabulary;Listened to...   \n",
       "gu4      Studied by myself;I lived in a country where t...   \n",
       "hb0      Studied grammar;Had a native-speaker teacher;T...   \n",
       "dp8      Studied grammar;Worked in pairs/groups;Had a n...   \n",
       "bn6      Studied grammar;Studied vocabulary;Teacher spo...   \n",
       "\n",
       "        non_native_language_2 yrs_of_study_lang2  study_in_classroom_lang2  \\\n",
       "anon_id                                                                      \n",
       "ec5                       NaN                NaN                       NaN   \n",
       "cy2                       NaN                NaN                       0.0   \n",
       "br9                       NaN                NaN                       0.0   \n",
       "cl5                       NaN                NaN                       0.0   \n",
       "de1                       NaN                NaN                       0.0   \n",
       "ap0                       NaN                NaN                       0.0   \n",
       "gu4                       NaN                NaN                       0.0   \n",
       "hb0                       NaN                NaN                       0.0   \n",
       "dp8                       NaN                NaN                       0.0   \n",
       "bn6                       NaN                NaN                       0.0   \n",
       "\n",
       "        ways_of_study_lang2 non_native_language_3 yrs_of_study_lang3  \\\n",
       "anon_id                                                                \n",
       "ec5                     NaN                   NaN                NaN   \n",
       "cy2                   other                   NaN                NaN   \n",
       "br9                   other                   NaN                NaN   \n",
       "cl5                   other                   NaN                NaN   \n",
       "de1                   other                   NaN                NaN   \n",
       "ap0                   other                   NaN                NaN   \n",
       "gu4                   other                   NaN                NaN   \n",
       "hb0                   other                   NaN                NaN   \n",
       "dp8                   other                   NaN                NaN   \n",
       "bn6                   other                   NaN                NaN   \n",
       "\n",
       "         study_in_classroom_lang3 ways_of_study_lang3          createddate  \\\n",
       "anon_id                                                                      \n",
       "ec5                           NaN                 NaN  2011-06-16 14:08:05   \n",
       "cy2                           0.0               other  2011-06-20 14:09:05   \n",
       "br9                           0.0               other  2011-06-20 14:09:15   \n",
       "cl5                           0.0               other  2011-06-20 14:09:23   \n",
       "de1                           0.0               other  2011-06-20 14:09:27   \n",
       "ap0                           0.0               other  2011-06-20 14:09:33   \n",
       "gu4                           0.0               other  2011-06-20 14:09:34   \n",
       "hb0                           0.0               other  2011-06-20 14:09:38   \n",
       "dp8                           0.0               other  2011-06-20 14:10:15   \n",
       "bn6                           0.0               other  2011-06-20 14:11:17   \n",
       "\n",
       "                modifieddate  \\\n",
       "anon_id                        \n",
       "ec5      2011-06-16 14:13:03   \n",
       "cy2      2011-06-20 14:11:31   \n",
       "br9      2011-06-20 14:12:02   \n",
       "cl5      2011-06-20 14:13:16   \n",
       "de1      2011-06-20 14:12:02   \n",
       "ap0      2011-06-20 14:12:52   \n",
       "gu4      2011-06-20 14:13:04   \n",
       "hb0      2011-06-20 14:13:01   \n",
       "dp8      2011-06-20 14:13:57   \n",
       "bn6      2011-06-20 14:15:51   \n",
       "\n",
       "                                            course_history  \n",
       "anon_id                                                     \n",
       "ec5      719;720;721;722;723;772;774;785;813;819;858;85...  \n",
       "cy2      845;846;847;871;872;927;928;931;949;950;1008;1...  \n",
       "br9                        868;869;870;871;872;947;951;953  \n",
       "cl5      770;771;778;779;781;856;857;859;861;871;952;95...  \n",
       "de1      850;851;852;871;872;926;932;933;944;945;1008;1...  \n",
       "ap0                                    845;846;847;871;872  \n",
       "gu4      772;773;774;775;776;868;869;870;871;872;922;92...  \n",
       "hb0      851;869;870;871;872;923;942;944;945;946;1008;1...  \n",
       "dp8                                    868;869;870;871;872  \n",
       "bn6      860;861;862;871;872;930;947;948;949;951;998;99...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Process the student_information.csv file\n",
    "S_info_csv = cor_dir + \"student_information.csv\"\n",
    "S_info_df = pd.read_csv(S_info_csv, index_col = 'anon_id')\n",
    "\n",
    "S_info_df.head() #Issues still apparent with integers turned into floats\n",
    "S_info_df.tail(10) #6 anon_id with no personal info - perhaps not students and to be 'pruned', as well as teachers with 'English' as the native language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>native_language</th>\n",
       "      <th>language_used_at_home</th>\n",
       "      <th>language_used_at_home_now</th>\n",
       "      <th>non_native_language_1</th>\n",
       "      <th>yrs_of_study_lang1</th>\n",
       "      <th>study_in_classroom_lang1</th>\n",
       "      <th>ways_of_study_lang1</th>\n",
       "      <th>non_native_language_2</th>\n",
       "      <th>yrs_of_study_lang2</th>\n",
       "      <th>study_in_classroom_lang2</th>\n",
       "      <th>ways_of_study_lang2</th>\n",
       "      <th>non_native_language_3</th>\n",
       "      <th>yrs_of_study_lang3</th>\n",
       "      <th>study_in_classroom_lang3</th>\n",
       "      <th>ways_of_study_lang3</th>\n",
       "      <th>createddate</th>\n",
       "      <th>modifieddate</th>\n",
       "      <th>course_history</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anon_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ez7</th>\n",
       "      <td>Male</td>\n",
       "      <td>1987</td>\n",
       "      <td>English</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic;English</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I lived in a country where they spoke Arabic</td>\n",
       "      <td>English</td>\n",
       "      <td>less than 1 year</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Studied vocabulary;Studied pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2007-02-20 10:05:39</td>\n",
       "      <td>2007-03-20 10:09:23</td>\n",
       "      <td>156;167;180;191;200;212;223;234;245;256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ay4</th>\n",
       "      <td>Female</td>\n",
       "      <td>1974</td>\n",
       "      <td>English</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>more than 5 years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Studied grammar;Had a native-speaker teacher;S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>2009-06-09 12:04:22</td>\n",
       "      <td>2009-11-13 12:43:36</td>\n",
       "      <td>509;515;516;517;560;571;574;601;622;642;645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gender  birth_year native_language language_used_at_home  \\\n",
       "anon_id                                                             \n",
       "ez7        Male        1987         English                Arabic   \n",
       "ay4      Female        1974         English                Korean   \n",
       "\n",
       "        language_used_at_home_now non_native_language_1 yrs_of_study_lang1  \\\n",
       "anon_id                                                                      \n",
       "ez7                Arabic;English                Arabic  more than 5 years   \n",
       "ay4                        Korean                Korean  more than 5 years   \n",
       "\n",
       "         study_in_classroom_lang1  \\\n",
       "anon_id                             \n",
       "ez7                           0.0   \n",
       "ay4                           1.0   \n",
       "\n",
       "                                       ways_of_study_lang1  \\\n",
       "anon_id                                                      \n",
       "ez7           I lived in a country where they spoke Arabic   \n",
       "ay4      Studied grammar;Had a native-speaker teacher;S...   \n",
       "\n",
       "        non_native_language_2 yrs_of_study_lang2  study_in_classroom_lang2  \\\n",
       "anon_id                                                                      \n",
       "ez7                   English   less than 1 year                       1.0   \n",
       "ay4                       NaN                NaN                       0.0   \n",
       "\n",
       "                                       ways_of_study_lang2  \\\n",
       "anon_id                                                      \n",
       "ez7      Studied grammar;Studied vocabulary;Studied pro...   \n",
       "ay4                                                  other   \n",
       "\n",
       "        non_native_language_3 yrs_of_study_lang3  study_in_classroom_lang3  \\\n",
       "anon_id                                                                      \n",
       "ez7                       NaN                NaN                       0.0   \n",
       "ay4                       NaN                NaN                       0.0   \n",
       "\n",
       "        ways_of_study_lang3          createddate         modifieddate  \\\n",
       "anon_id                                                                 \n",
       "ez7                   other  2007-02-20 10:05:39  2007-03-20 10:09:23   \n",
       "ay4                   other  2009-06-09 12:04:22  2009-11-13 12:43:36   \n",
       "\n",
       "                                      course_history  \n",
       "anon_id                                               \n",
       "ez7          156;167;180;191;200;212;223;234;245;256  \n",
       "ay4      509;515;516;517;560;571;574;601;622;642;645  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove anyone with 'English' or 'NaN' as their native_language, i.e. not students\n",
    "\n",
    "#First try to create filters\n",
    "\n",
    "Englishfilter = S_info_df['native_language'] == 'English' #first filter works\n",
    "NaNfilter = S_info_df['native_language'] == np.nan #second filter doesn't\n",
    "\n",
    "fake_Ss = S_info_df.loc[Englishfilter] #works, but...\n",
    "fake_Ss\n",
    "\n",
    "#fake_Ss = S_info_df.loc[(Englishfilter) or (NaNfilter)] #doesn't work\n",
    "#fake_Ss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Student responses###\n",
    "- answer_csv\n",
    "- answer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>directory</th>\n",
       "      <th>is_doublespaced</th>\n",
       "      <th>is_plagiarized</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>eq0</td>\n",
       "      <td>7505</td>\n",
       "      <td>I met my friend Nife while I was studying in a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>am8</td>\n",
       "      <td>7506</td>\n",
       "      <td>Ten years ago, I met a women on the train betw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>dk5</td>\n",
       "      <td>7507</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>dk5</td>\n",
       "      <td>7507</td>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>ad1</td>\n",
       "      <td>7508</td>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\r\\r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id anon_id  user_file_id  \\\n",
       "answer_id                                      \n",
       "1                    5     eq0          7505   \n",
       "2                    5     am8          7506   \n",
       "3                   12     dk5          7507   \n",
       "4                   13     dk5          7507   \n",
       "5                   12     ad1          7508   \n",
       "\n",
       "                                                        text directory  \\\n",
       "answer_id                                                                \n",
       "1          I met my friend Nife while I was studying in a...       NaN   \n",
       "2          Ten years ago, I met a women on the train betw...       NaN   \n",
       "3          In my country we usually don't use tea bags. F...       NaN   \n",
       "4                      I organized the instructions by time.       NaN   \n",
       "5          First, prepare a port, loose tea, and cup.\\r\\r...       NaN   \n",
       "\n",
       "           is_doublespaced  is_plagiarized  is_deleted  \n",
       "answer_id                                               \n",
       "1                        0               0           0  \n",
       "2                        0               0           0  \n",
       "3                        0               0           0  \n",
       "4                        0               0           0  \n",
       "5                        0               0           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>directory</th>\n",
       "      <th>is_doublespaced</th>\n",
       "      <th>is_plagiarized</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48411</th>\n",
       "      <td>6138</td>\n",
       "      <td>dv8</td>\n",
       "      <td>100847</td>\n",
       "      <td>Early Second Language Education\\r\\r\\r\\nSaudi A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48412</th>\n",
       "      <td>6138</td>\n",
       "      <td>ce1</td>\n",
       "      <td>100848</td>\n",
       "      <td>Publicly funded health care system\\r\\r\\r\\n\\r\\r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48413</th>\n",
       "      <td>6139</td>\n",
       "      <td>fo7</td>\n",
       "      <td>100911</td>\n",
       "      <td>Happiness is the most effective feeling in peo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48414</th>\n",
       "      <td>6139</td>\n",
       "      <td>fs9</td>\n",
       "      <td>100912</td>\n",
       "      <td>everyone want to play some games. some people ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48415</th>\n",
       "      <td>6139</td>\n",
       "      <td>cl7</td>\n",
       "      <td>100913</td>\n",
       "      <td>Playing a game is fun only when you win?\\r\\r\\r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48416</th>\n",
       "      <td>6139</td>\n",
       "      <td>dr8</td>\n",
       "      <td>100914</td>\n",
       "      <td>Many people enjoy a game in their free time. B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48417</th>\n",
       "      <td>6137</td>\n",
       "      <td>fv1</td>\n",
       "      <td>100915</td>\n",
       "      <td>\\r\\r\\r\\n                           ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48418</th>\n",
       "      <td>6137</td>\n",
       "      <td>fo1</td>\n",
       "      <td>100916</td>\n",
       "      <td>Some  patients are suffering from the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48419</th>\n",
       "      <td>6119</td>\n",
       "      <td>ge8</td>\n",
       "      <td>100917</td>\n",
       "      <td>My house looks amazing and modern. I decorated...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48420</th>\n",
       "      <td>6027</td>\n",
       "      <td>ge8</td>\n",
       "      <td>100918</td>\n",
       "      <td>History and Geography a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id anon_id  user_file_id  \\\n",
       "answer_id                                      \n",
       "48411             6138     dv8        100847   \n",
       "48412             6138     ce1        100848   \n",
       "48413             6139     fo7        100911   \n",
       "48414             6139     fs9        100912   \n",
       "48415             6139     cl7        100913   \n",
       "48416             6139     dr8        100914   \n",
       "48417             6137     fv1        100915   \n",
       "48418             6137     fo1        100916   \n",
       "48419             6119     ge8        100917   \n",
       "48420             6027     ge8        100918   \n",
       "\n",
       "                                                        text directory  \\\n",
       "answer_id                                                                \n",
       "48411      Early Second Language Education\\r\\r\\r\\nSaudi A...       NaN   \n",
       "48412      Publicly funded health care system\\r\\r\\r\\n\\r\\r...       NaN   \n",
       "48413      Happiness is the most effective feeling in peo...       NaN   \n",
       "48414      everyone want to play some games. some people ...       NaN   \n",
       "48415      Playing a game is fun only when you win?\\r\\r\\r...       NaN   \n",
       "48416      Many people enjoy a game in their free time. B...       NaN   \n",
       "48417                 \\r\\r\\r\\n                           ...       NaN   \n",
       "48418               Some  patients are suffering from the...       NaN   \n",
       "48419      My house looks amazing and modern. I decorated...       NaN   \n",
       "48420                             History and Geography a...       NaN   \n",
       "\n",
       "           is_doublespaced  is_plagiarized  is_deleted  \n",
       "answer_id                                               \n",
       "48411                    1               0           0  \n",
       "48412                    0               0           0  \n",
       "48413                    1               0           0  \n",
       "48414                    1               0           0  \n",
       "48415                    1               0           0  \n",
       "48416                    1               0           0  \n",
       "48417                    0               0           0  \n",
       "48418                    0               0           0  \n",
       "48419                    0               0           0  \n",
       "48420                    0               0           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Process answer.csv file\n",
    "answer_csv = cor_dir + \"answer.csv\"\n",
    "answer_df = pd.read_csv(answer_csv, index_col = 'answer_id')\n",
    "\n",
    "answer_df.head()\n",
    "answer_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Course IDs ###\n",
    "(to help with finding specific texts and linking other data frames)\n",
    "- course_csv\n",
    "- course_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>semester</th>\n",
       "      <th>section</th>\n",
       "      <th>course_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>course_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2064</td>\n",
       "      <td>A</td>\n",
       "      <td>Reading Pre_Intermediate 2064 A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2064</td>\n",
       "      <td>B</td>\n",
       "      <td>Reading Low_Intermediate 2064 B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>M</td>\n",
       "      <td>Reading Intermediate 2064 M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>P</td>\n",
       "      <td>Reading Intermediate 2064 P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2064</td>\n",
       "      <td>Q</td>\n",
       "      <td>Reading Intermediate 2064 Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           class_id  level_id  semester section  \\\n",
       "course_id                                         \n",
       "1                 1         2      2064       A   \n",
       "2                 1         3      2064       B   \n",
       "3                 1         4      2064       M   \n",
       "4                 1         4      2064       P   \n",
       "5                 1         4      2064       Q   \n",
       "\n",
       "                        course_description  \n",
       "course_id                                   \n",
       "1          Reading Pre_Intermediate 2064 A  \n",
       "2          Reading Low_Intermediate 2064 B  \n",
       "3              Reading Intermediate 2064 M  \n",
       "4              Reading Intermediate 2064 P  \n",
       "5              Reading Intermediate 2064 Q  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Process course.csv file\n",
    "course_csv = cor_dir + \"course.csv\"\n",
    "course_df = pd.read_csv(course_csv, index_col = 'course_id')\n",
    "\n",
    "course_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. user_file_internal ###\n",
    "- big csv file with a lot of information\n",
    "- helps with finding specific texts and linking other data frames\n",
    "- includes file_type_id, course_id, and many other fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>file_type_id</th>\n",
       "      <th>file_info_id</th>\n",
       "      <th>user_file_parent_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>activity</th>\n",
       "      <th>order_num</th>\n",
       "      <th>due_date</th>\n",
       "      <th>...</th>\n",
       "      <th>modifiedby</th>\n",
       "      <th>modifieddate</th>\n",
       "      <th>allow_submit_after_duedate</th>\n",
       "      <th>allow_multiple_accesses</th>\n",
       "      <th>allow_double_spacing</th>\n",
       "      <th>duration</th>\n",
       "      <th>pull_off_date</th>\n",
       "      <th>direction</th>\n",
       "      <th>grammar_qp_id</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_file_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aj8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-07 14:19:48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fg8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-07 14:19:48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>be0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-07 14:19:48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fc4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-07 14:19:48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fc4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-08-07 14:19:48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             anon_id  file_type_id  file_info_id  user_file_parent_id  \\\n",
       "user_file_id                                                            \n",
       "1                aj8             1           NaN                  NaN   \n",
       "2                fg8             1           NaN                  NaN   \n",
       "3                be0             1           NaN                  NaN   \n",
       "4                fc4             1           NaN                  NaN   \n",
       "5                fc4             1           NaN                  1.0   \n",
       "\n",
       "              course_id  session_id  document_id  activity  order_num  \\\n",
       "user_file_id                                                            \n",
       "1                    10         NaN          NaN        12        NaN   \n",
       "2                    10         NaN          NaN        12        NaN   \n",
       "3                    10         NaN          NaN        12        NaN   \n",
       "4                    10         NaN          NaN        12        NaN   \n",
       "5                    10         NaN          NaN        12        NaN   \n",
       "\n",
       "                         due_date    ...     modifiedby modifieddate  \\\n",
       "user_file_id                         ...                               \n",
       "1             2006-08-07 14:19:48    ...            NaN          NaN   \n",
       "2             2006-08-07 14:19:48    ...            NaN          NaN   \n",
       "3             2006-08-07 14:19:48    ...            NaN          NaN   \n",
       "4             2006-08-07 14:19:48    ...            NaN          NaN   \n",
       "5             2006-08-07 14:19:48    ...            NaN          NaN   \n",
       "\n",
       "              allow_submit_after_duedate  allow_multiple_accesses  \\\n",
       "user_file_id                                                        \n",
       "1                                      0                        0   \n",
       "2                                      0                        0   \n",
       "3                                      0                        0   \n",
       "4                                      0                        0   \n",
       "5                                      0                        0   \n",
       "\n",
       "              allow_double_spacing duration pull_off_date direction  \\\n",
       "user_file_id                                                          \n",
       "1                                0      NaN           NaN       NaN   \n",
       "2                                0      NaN           NaN       NaN   \n",
       "3                                0      NaN           NaN       NaN   \n",
       "4                                0      NaN           NaN       NaN   \n",
       "5                                0      NaN           NaN       NaN   \n",
       "\n",
       "              grammar_qp_id is_deleted  \n",
       "user_file_id                            \n",
       "1                       NaN          0  \n",
       "2                       NaN          0  \n",
       "3                       NaN          0  \n",
       "4                       NaN          0  \n",
       "5                       NaN          0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Process user_file_wavtxt.csv file\n",
    "user_csv = cor_dir + \"user_file_internal.csv\"\n",
    "user_df = pd.read_csv(user_csv, index_col = 'user_file_id')\n",
    "\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Basic info about dataframes ###\n",
    "\n",
    "The following information is an overview of the four dataframes/csv files currently being looked at:\n",
    "\n",
    "#### S_info_df ####\n",
    "Size:\n",
    "- there are 941 entries, i.e. students, although at least 9 need to be removed once filters can be made to work\n",
    "- 21 columns including info about languages spoken, personal data like age, and learning preferences\n",
    "- Some columns will likely be removed if deemed unhelpful/unnecessary (e.g. 4th language spoken)\n",
    "- Some data is normalized, e.g. years of study, but others was open, resulting in very varied responses\n",
    "\n",
    "Connection to other dataframes:\n",
    "- link to answer_df is anon_id\n",
    "\n",
    "Most useful columns for this project:\n",
    "- anon_id (for linking to other df)\n",
    "- L1, gender, time studying, age (for data analysis)  \n",
    "\n",
    "\n",
    "#### answer_df ####\n",
    "Size:\n",
    "- there are 47175 'text' entries, i.e. student responses, although 48384 total rows. The remaining (including many null texts need to be removed as without texts they serve no purpose\n",
    "- 9 columns including info about the question, the answer, and characteristics of the text (like if it was plagiarized)\n",
    "\n",
    "Connection to other dataframes:\n",
    "- link to S_info_df and course_df is anon_id column\n",
    "\n",
    "Most useful columns for this project:\n",
    "- answer_id (shorthand for the individual texts to be analyzed)\n",
    "- text (the most important column so far) -> to be converted into tokens, bigrams, etc.  \n",
    "- anon_id (for linking to other df)\n",
    "\n",
    "\n",
    "#### course_df ####\n",
    "Size:\n",
    "- there are 1071 entries, i.e. one row for each course\n",
    "- 6 columns including info about the course and class, both in terms of their assigned number and a description\n",
    "\n",
    "Connection to other dataframes:\n",
    "- link to user_df is course_id \n",
    "\n",
    "Most useful columns for this project:\n",
    "- only really useful as a transition for linking to other df  \n",
    "\n",
    "\n",
    "#### user_df ####\n",
    "Size:\n",
    "- there are 76371 rows, each with a file_id number. However, it is unclear how to use this informatin effectively.\n",
    "- There are 29 columns, although many are not useful for this project\n",
    "- A lot of the cells have no input\n",
    "- Some columns will likely be removed if deemed unhelpful/unnecessary\n",
    "\n",
    "Connection to other dataframes:\n",
    "- link to course_df is course_id column\n",
    "\n",
    "Most useful columns for this project:\n",
    "- course_id (to link to other DF)\n",
    "- file_type_id (for indicating the type of activity used in class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 913 entries, ez9 to bn6\n",
      "Data columns (total 20 columns):\n",
      "gender                       913 non-null object\n",
      "birth_year                   913 non-null int64\n",
      "native_language              913 non-null object\n",
      "language_used_at_home        912 non-null object\n",
      "language_used_at_home_now    855 non-null object\n",
      "non_native_language_1        859 non-null object\n",
      "yrs_of_study_lang1           863 non-null object\n",
      "study_in_classroom_lang1     863 non-null float64\n",
      "ways_of_study_lang1          863 non-null object\n",
      "non_native_language_2        309 non-null object\n",
      "yrs_of_study_lang2           312 non-null object\n",
      "study_in_classroom_lang2     863 non-null float64\n",
      "ways_of_study_lang2          863 non-null object\n",
      "non_native_language_3        55 non-null object\n",
      "yrs_of_study_lang3           59 non-null object\n",
      "study_in_classroom_lang3     863 non-null float64\n",
      "ways_of_study_lang3          863 non-null object\n",
      "createddate                  913 non-null object\n",
      "modifieddate                 909 non-null object\n",
      "course_history               913 non-null object\n",
      "dtypes: float64(3), int64(1), object(16)\n",
      "memory usage: 149.8+ KB\n"
     ]
    }
   ],
   "source": [
    "S_info_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 48384 entries, 1 to 48420\n",
      "Data columns (total 8 columns):\n",
      "question_id        48384 non-null int64\n",
      "anon_id            48353 non-null object\n",
      "user_file_id       48384 non-null int64\n",
      "text               47175 non-null object\n",
      "directory          14 non-null object\n",
      "is_doublespaced    48384 non-null int64\n",
      "is_plagiarized     48384 non-null int64\n",
      "is_deleted         48384 non-null int64\n",
      "dtypes: int64(5), object(3)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "answer_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1071 entries, 1 to 1123\n",
      "Data columns (total 5 columns):\n",
      "class_id              1071 non-null int64\n",
      "level_id              1071 non-null int64\n",
      "semester              1071 non-null int64\n",
      "section               1071 non-null object\n",
      "course_description    1058 non-null object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 50.2+ KB\n"
     ]
    }
   ],
   "source": [
    "course_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27134 entries, 1 to 100918\n",
      "Data columns (total 28 columns):\n",
      "anon_id                       26922 non-null object\n",
      "file_type_id                  27134 non-null int64\n",
      "file_info_id                  2151 non-null float64\n",
      "user_file_parent_id           25884 non-null float64\n",
      "course_id                     27134 non-null int64\n",
      "session_id                    26142 non-null float64\n",
      "document_id                   1599 non-null float64\n",
      "activity                      27134 non-null int64\n",
      "order_num                     2722 non-null float64\n",
      "due_date                      3286 non-null object\n",
      "post_date                     3714 non-null object\n",
      "assignment_name               2700 non-null object\n",
      "version                       27134 non-null int64\n",
      "directory                     0 non-null float64\n",
      "filename                      0 non-null float64\n",
      "content_text                  964 non-null object\n",
      "createdby                     24955 non-null object\n",
      "createddate                   27134 non-null object\n",
      "modifiedby                    462 non-null float64\n",
      "modifieddate                  462 non-null object\n",
      "allow_submit_after_duedate    27134 non-null int64\n",
      "allow_multiple_accesses       27134 non-null int64\n",
      "allow_double_spacing          27134 non-null int64\n",
      "duration                      406 non-null float64\n",
      "pull_off_date                 406 non-null object\n",
      "direction                     1997 non-null object\n",
      "grammar_qp_id                 0 non-null float64\n",
      "is_deleted                    27134 non-null int64\n",
      "dtypes: float64(10), int64(8), object(10)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "user_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Tokenization of answers ###\n",
    "\n",
    "Tokenizing the text in answer.csv to allow for further analysis, e.g., of bigrams.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I met my friend Nife while I was studying in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ten years ago, I met a women on the train betw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\r\\r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text\n",
       "answer_id                                                   \n",
       "1          I met my friend Nife while I was studying in a...\n",
       "2          Ten years ago, I met a women on the train betw...\n",
       "3          In my country we usually don't use tea bags. F...\n",
       "4                      I organized the instructions by time.\n",
       "5          First, prepare a port, loose tea, and cup.\\r\\r..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#column to tokenize\n",
    "answer_df[['text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>directory</th>\n",
       "      <th>is_doublespaced</th>\n",
       "      <th>is_plagiarized</th>\n",
       "      <th>is_deleted</th>\n",
       "      <th>toks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>eq0</td>\n",
       "      <td>7505</td>\n",
       "      <td>I met my friend Nife while I was studying in a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, met, my, friend, Nife, while, I, was, stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>am8</td>\n",
       "      <td>7506</td>\n",
       "      <td>Ten years ago, I met a women on the train betw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Ten, years, ago, ,, I, met, a, women, on, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>dk5</td>\n",
       "      <td>7507</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[In, my, country, we, usually, do, n't, use, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>dk5</td>\n",
       "      <td>7507</td>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, organized, the, instructions, by, time, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>ad1</td>\n",
       "      <td>7508</td>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\r\\r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[First, ,, prepare, a, port, ,, loose, tea, ,,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id anon_id  user_file_id  \\\n",
       "answer_id                                      \n",
       "1                    5     eq0          7505   \n",
       "2                    5     am8          7506   \n",
       "3                   12     dk5          7507   \n",
       "4                   13     dk5          7507   \n",
       "5                   12     ad1          7508   \n",
       "\n",
       "                                                        text directory  \\\n",
       "answer_id                                                                \n",
       "1          I met my friend Nife while I was studying in a...       NaN   \n",
       "2          Ten years ago, I met a women on the train betw...       NaN   \n",
       "3          In my country we usually don't use tea bags. F...       NaN   \n",
       "4                      I organized the instructions by time.       NaN   \n",
       "5          First, prepare a port, loose tea, and cup.\\r\\r...       NaN   \n",
       "\n",
       "           is_doublespaced  is_plagiarized  is_deleted  \\\n",
       "answer_id                                                \n",
       "1                        0               0           0   \n",
       "2                        0               0           0   \n",
       "3                        0               0           0   \n",
       "4                        0               0           0   \n",
       "5                        0               0           0   \n",
       "\n",
       "                                                        toks  \n",
       "answer_id                                                     \n",
       "1          [I, met, my, friend, Nife, while, I, was, stud...  \n",
       "2          [Ten, years, ago, ,, I, met, a, women, on, the...  \n",
       "3          [In, my, country, we, usually, do, n't, use, t...  \n",
       "4             [I, organized, the, instructions, by, time, .]  \n",
       "5          [First, ,, prepare, a, port, ,, loose, tea, ,,...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating 'toks' column and changing NaN to empty strings\n",
    "answer_df = answer_df[answer_df['text'].notnull()]\n",
    "answer_df['toks'] = answer_df.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\n",
    "\n",
    "answer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Bigrams###\n",
    "\n",
    "Creating a bigram columns from the tok column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>directory</th>\n",
       "      <th>is_doublespaced</th>\n",
       "      <th>is_plagiarized</th>\n",
       "      <th>is_deleted</th>\n",
       "      <th>toks</th>\n",
       "      <th>bigrams</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>eq0</td>\n",
       "      <td>7505</td>\n",
       "      <td>I met my friend Nife while I was studying in a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, met, my, friend, Nife, while, I, was, stud...</td>\n",
       "      <td>[(I, met), (met, my), (my, friend), (friend, N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id anon_id  user_file_id  \\\n",
       "answer_id                                      \n",
       "1                    5     eq0          7505   \n",
       "\n",
       "                                                        text directory  \\\n",
       "answer_id                                                                \n",
       "1          I met my friend Nife while I was studying in a...       NaN   \n",
       "\n",
       "           is_doublespaced  is_plagiarized  is_deleted  \\\n",
       "answer_id                                                \n",
       "1                        0               0           0   \n",
       "\n",
       "                                                        toks  \\\n",
       "answer_id                                                      \n",
       "1          [I, met, my, friend, Nife, while, I, was, stud...   \n",
       "\n",
       "                                                     bigrams  \n",
       "answer_id                                                     \n",
       "1          [(I, met), (met, my), (my, friend), (friend, N...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a column of bigrams from the 'toks' column\n",
    "\n",
    "answer_df['bigrams'] = answer_df.toks.apply(lambda x: list(nltk.bigrams(x)))\n",
    "answer_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Corpus frequency dictionary ###\n",
    "\n",
    "Create a frequency dictionary for all toks from answer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I met my friend Nife while I was studying in a middle school. I was happy when I met him because he '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['I', 'met', 'my', 'friend', 'Nife', 'while', 'I', 'was', 'studying', 'in', 'a', 'middle', 'school', '.', 'I', 'was', 'happy', 'when', 'I', 'met']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Joining all the answers before tokenizing them to create a corpus of tokens\n",
    "\n",
    "answer_corpus = ' '.join(answer_df['text'])\n",
    "answer_corpus[:100]\n",
    "answer_corpus_tok = nltk.word_tokenize(answer_corpus)\n",
    "answer_corpus_tok[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('friend=', 1), ('Vegetables', 23), ('hugged', 16), ('Booking', 3), ('disorders', 59)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dictionary from the answer_corpus\n",
    "\n",
    "answer_dict = nltk.FreqDist(answer_corpus_tok)\n",
    "random.sample(list(answer_dict.items()),5) #random 5-item sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Bigram frequency dictionary ###\n",
    "Create a bigram frequency dictionary from answer_corpus_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'met'), ('met', 'my'), ('my', 'friend'), ('friend', 'Nife'), ('Nife', 'while'), ('while', 'I'), ('I', 'was'), ('was', 'studying'), ('studying', 'in'), ('in', 'a')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating bigrams from the answer_corpus_tok\n",
    "\n",
    "answer_corpus_bigrams = list(nltk.bigrams(answer_corpus_tok))\n",
    "answer_corpus_bigrams[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('think', 'taking'), 2), (('coffee', 'when'), 4), (('Accent', 'coaches'), 1), (('unhappy', 'on'), 4), (('odor', '.'), 19)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Again creating a dictionary, this time a bigram dictionary\n",
    "\n",
    "answer_bigram_dict = nltk.FreqDist(answer_corpus_bigrams)\n",
    "random.sample(list(answer_bigram_dict.items()),5) #random 5-item sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Mutual Information\n",
    "\n",
    "Creating a function to calculate Mutual Information (MI), a useful measure of two-way collocation\n",
    "\n",
    "(from https://corpus.byu.edu/mutualInformation.asp)  \n",
    "\n",
    "Mutual Information is calculated as follows:  \n",
    "MI = log ( (AB * sizeCorpus) / (A * B * span) ) / log (2)  \n",
    "\n",
    "Suppose we are calculating the MI for the collocate color near purple in BYU-BNC.  \n",
    "\n",
    "A = frequency of node word (e.g. purple): 1262  \n",
    "B = frequency of collocate (e.g. color): 115  \n",
    "AB = frequency of collocate near the node word (e.g. color near purple): 24  \n",
    "sizeCorpus= size of corpus (# words; in this case the BNC): 96,263,399  \n",
    "span = span of words (e.g. 3 to left and 3 to right of node word): 6  \n",
    "log (2) is literally the log10 of the number 2: .30103  \n",
    "\n",
    "MI = 11.37 = log ( (24 * 96,263,399) / (1262 * 115 * 6) ) / .30103  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The above formula turned into python code\n",
    "\n",
    "import math\n",
    "from math import log\n",
    "\n",
    "def MI(word1, word2):\n",
    "  prob_word1 = answer_dict[word1] / float(sum(answer_dict.values()))\n",
    "  prob_word2 = answer_dict[word2] / float(sum(answer_dict.values()))\n",
    "  prob_word1_word2 = answer_bigram_dict[word1, word2] / float(sum(answer_bigram_dict.values()))\n",
    "  return math.log(prob_word1_word2/float(prob_word1*prob_word2),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1605"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24516"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of MI:\n",
    "\n",
    "#This is a collocation which should have a medium strength MI (between 4-7)\n",
    "answer_bigram_dict['young', 'people']\n",
    "answer_dict['young']\n",
    "answer_dict['people']\n",
    "\n",
    "#'young' collocates strongly with 'people' (about 25% of time) but 'people' doesn't collocate strongly with 'young'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.840354713355728"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MI('young','people')\n",
    "\n",
    "#That is the standard range for a M1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "171927"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1547"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.1986947748534735"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example #2 with two words that have a weaker MI\n",
    "\n",
    "answer_bigram_dict['the', 'man']\n",
    "answer_dict['the']\n",
    "answer_dict['man']\n",
    "\n",
    "MI('the', 'man')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Combo dataframe\n",
    "- joins answer_df, user_df, and course_df\n",
    "- removes unnecessary columns\n",
    "- narrows results down to only answers from writing classes and first versions of their work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#join answer_df and user_df along 'user_file_id' column\n",
    "combo_df = answer_df.join(user_df, on='user_file_id', lsuffix='user_file_id')\n",
    "\n",
    "#now join this new df with course_df along 'course_id' column\n",
    "combo_df = combo_df.join(course_df, on='course_id', lsuffix='user_file_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dropping unnecessary columns (there are a lot)\n",
    "combo_df = combo_df.drop(['directoryuser_file_id', 'is_doublespaced', 'is_plagiarized', 'is_deleteduser_file_id',\n",
    "                            'modifiedby', 'modifieddate', 'allow_submit_after_duedate', 'anon_id', 'file_type_id',\n",
    "                            'file_info_id', 'user_file_parent_id', 'createdby', 'session_id',\n",
    "                           'document_id','filename', 'content_text', 'createddate', 'allow_multiple_accesses',\n",
    "                           'directoryuser_file_id', 'is_doublespaced', 'is_plagiarized', 'is_deleteduser_file_id',\n",
    "                           'modifiedby', 'modifieddate', 'allow_submit_after_duedate','activity', 'order_num', \n",
    "                            'due_date', 'post_date', 'assignment_name', 'directory', 'activity', 'semester',\n",
    "                            'order_num', 'due_date', 'post_date', 'assignment_name', 'allow_double_spacing',\n",
    "                           'duration', 'pull_off_date', 'direction', 'grammar_qp_id', 'is_deleted',\n",
    "                            'section', 'course_description'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keeping only 1st versions of students' work\n",
    "combo_df = combo_df.loc[combo_df['version'] == 1]\n",
    "\n",
    "#'version' column now unnecessary\n",
    "combo_df = combo_df.drop(['version'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keeping only answers from writing classes (class_id = 2)\n",
    "combo_df = combo_df.loc[combo_df['class_id'] == 2]\n",
    "\n",
    "#'class_id' column now unnecessary\n",
    "combo_df = combo_df.drop(['class_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>bigrams</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>7507</td>\n",
       "      <td>dk5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>[In, my, country, we, usually, do, n't, use, t...</td>\n",
       "      <td>[(In, my), (my, country), (country, we), (we, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>7507</td>\n",
       "      <td>dk5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "      <td>[I, organized, the, instructions, by, time, .]</td>\n",
       "      <td>[(I, organized), (organized, the), (the, instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>7508</td>\n",
       "      <td>ad1</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\r\\r...</td>\n",
       "      <td>[First, ,, prepare, a, port, ,, loose, tea, ,,...</td>\n",
       "      <td>[(First, ,), (,, prepare), (prepare, a), (a, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>7508</td>\n",
       "      <td>ad1</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>By time</td>\n",
       "      <td>[By, time]</td>\n",
       "      <td>[(By, time)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>7509</td>\n",
       "      <td>eg5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>First, prepare your cup, loose tea or bag tea,...</td>\n",
       "      <td>[First, ,, prepare, your, cup, ,, loose, tea, ...</td>\n",
       "      <td>[(First, ,), (,, prepare), (prepare, your), (y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id  user_file_id anon_id  level_id  course_id  \\\n",
       "answer_id                                                           \n",
       "3                   12          7507     dk5         4        115   \n",
       "4                   13          7507     dk5         4        115   \n",
       "5                   12          7508     ad1         4        115   \n",
       "6                   13          7508     ad1         4        115   \n",
       "7                   12          7509     eg5         4        115   \n",
       "\n",
       "                                                        text  \\\n",
       "answer_id                                                      \n",
       "3          In my country we usually don't use tea bags. F...   \n",
       "4                      I organized the instructions by time.   \n",
       "5          First, prepare a port, loose tea, and cup.\\r\\r...   \n",
       "6                                                    By time   \n",
       "7          First, prepare your cup, loose tea or bag tea,...   \n",
       "\n",
       "                                                        toks  \\\n",
       "answer_id                                                      \n",
       "3          [In, my, country, we, usually, do, n't, use, t...   \n",
       "4             [I, organized, the, instructions, by, time, .]   \n",
       "5          [First, ,, prepare, a, port, ,, loose, tea, ,,...   \n",
       "6                                                 [By, time]   \n",
       "7          [First, ,, prepare, your, cup, ,, loose, tea, ...   \n",
       "\n",
       "                                                     bigrams  \n",
       "answer_id                                                     \n",
       "3          [(In, my), (my, country), (country, we), (we, ...  \n",
       "4          [(I, organized), (organized, the), (the, instr...  \n",
       "5          [(First, ,), (,, prepare), (prepare, a), (a, p...  \n",
       "6                                               [(By, time)]  \n",
       "7          [(First, ,), (,, prepare), (prepare, your), (y...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just change the order of columns to something more logical and rename some columns\n",
    "combo_df = combo_df[['question_id','user_file_id', 'anon_iduser_file_id', 'level_id', 'course_id', 'text', 'toks', 'bigrams']]\n",
    "combo_df.rename(columns={'anon_iduser_file_id':'anon_id'}, inplace=True)\n",
    "\n",
    "#finished result =  much cleaner\n",
    "combo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 3, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([4, 5, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove level 2 (too few to be usefully analyzed)\n",
    "\n",
    "combo_df.level_id.unique()\n",
    "\n",
    "combo_df = combo_df.loc[combo_df['level_id'] != 2]\n",
    "\n",
    "combo_df.level_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#updated MI formula with combo_dict\n",
    "\n",
    "def MI(word1, word2):\n",
    "  prob_word1 = combo_unigram_dict[word1] / float(sum(combo_unigram_dict.values()))\n",
    "  prob_word2 = combo_unigram_dict[word2] / float(sum(combo_unigram_dict.values()))\n",
    "  prob_word1_word2 = combo_bigram_dict[word1, word2] / float(sum(combo_bigram_dict.values()))\n",
    "  return math.log(prob_word1_word2/float(prob_word1*prob_word2),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a column for total number of bigrams per text\n",
    "\n",
    "combo_df['bigram_len'] = [len(x) for x in combo_df['bigrams']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>bigram_len</th>\n",
       "      <th>bigrams_lower</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>7507</td>\n",
       "      <td>dk5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>[In, my, country, we, usually, do, n't, use, t...</td>\n",
       "      <td>[(In, my), (my, country), (country, we), (we, ...</td>\n",
       "      <td>67</td>\n",
       "      <td>[(in, my), (my, country), (country, we), (we, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>7507</td>\n",
       "      <td>dk5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "      <td>[I, organized, the, instructions, by, time, .]</td>\n",
       "      <td>[(I, organized), (organized, the), (the, instr...</td>\n",
       "      <td>6</td>\n",
       "      <td>[(i, organized), (organized, the), (the, instr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id  user_file_id anon_id  level_id  course_id  \\\n",
       "answer_id                                                           \n",
       "3                   12          7507     dk5         4        115   \n",
       "4                   13          7507     dk5         4        115   \n",
       "\n",
       "                                                        text  \\\n",
       "answer_id                                                      \n",
       "3          In my country we usually don't use tea bags. F...   \n",
       "4                      I organized the instructions by time.   \n",
       "\n",
       "                                                        toks  \\\n",
       "answer_id                                                      \n",
       "3          [In, my, country, we, usually, do, n't, use, t...   \n",
       "4             [I, organized, the, instructions, by, time, .]   \n",
       "\n",
       "                                                     bigrams  bigram_len  \\\n",
       "answer_id                                                                  \n",
       "3          [(In, my), (my, country), (country, we), (we, ...          67   \n",
       "4          [(I, organized), (organized, the), (the, instr...           6   \n",
       "\n",
       "                                               bigrams_lower  \n",
       "answer_id                                                     \n",
       "3          [(in, my), (my, country), (country, we), (we, ...  \n",
       "4          [(i, organized), (organized, the), (the, instr...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a column of lowercase bigrams to use with MI\n",
    "combo_df['bigrams_lower'] = [[(x.lower(), y.lower()) for x, y in element] for element in combo_df['bigrams']]\n",
    "combo_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the MI_sum column, i.e. the total MI of all the bigrams in each answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create new freq dicts for combo_df (unigrams and bigrams) using same \n",
    "#code as earlier versions with answer_df\n",
    "\n",
    "combo_corpus = ' '.join(combo_df['text'])\n",
    "combo_corpus_tok = nltk.word_tokenize(combo_corpus)\n",
    "combo_corpus_tok = list(map(lambda x:x.lower(),combo_corpus_tok)) #making everything lowercase\n",
    "combo_unigram_dict = nltk.FreqDist(combo_corpus_tok)\n",
    "\n",
    "combo_corpus_bigrams = list(nltk.bigrams(combo_corpus_tok))\n",
    "combo_bigram_dict = nltk.FreqDist(combo_corpus_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#updated MI formula with combo_dict and workaround to avoid math domain errors\n",
    "def MI(word1, word2):\n",
    "  prob_word1 = combo_unigram_dict[word1] / sum(combo_unigram_dict.values())\n",
    "  prob_word2 = combo_unigram_dict[word2] / sum(combo_unigram_dict.values())\n",
    "  prob_word1_word2 = combo_bigram_dict[word1, word2] / sum(combo_bigram_dict.values())\n",
    "  y = prob_word1*prob_word2\n",
    "  x = (prob_word1_word2/y) if y != 0 else 0\n",
    "  if x != 0:\n",
    "    return math.log(x,2)\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create list of all text_MI scores (takes a while)\n",
    "\n",
    "row = 0\n",
    "text_MI = []\n",
    "\n",
    "for x in combo_df['bigrams_lower']:\n",
    "    y = [round(sum(MI(x[0], x[1]) for x in combo_df.iloc[row][9]),2)]\n",
    "    row += 1\n",
    "    text_MI.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[181.28], [7.65], [228.84], [-0.24], [120.11], [102.94], [269.31], [11.61], [229.97], [19.53], [160.22], [96.46], [188.73], [125.52], [74.17], [254.38], [190.67], [7.85], [407.79], [8.22]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_MI[:20] #check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12702"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "12702"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "12702"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combo_df['bigrams_lower'])\n",
    "len(text_MI)\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_MI = pd.Series(text_MI) #turn the list into a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>bigram_len</th>\n",
       "      <th>bigrams_lower</th>\n",
       "      <th>MI_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>7507</td>\n",
       "      <td>dk5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>[In, my, country, we, usually, do, n't, use, t...</td>\n",
       "      <td>[(In, my), (my, country), (country, we), (we, ...</td>\n",
       "      <td>67</td>\n",
       "      <td>[(in, my), (my, country), (country, we), (we, ...</td>\n",
       "      <td>181.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>7507</td>\n",
       "      <td>dk5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "      <td>[I, organized, the, instructions, by, time, .]</td>\n",
       "      <td>[(I, organized), (organized, the), (the, instr...</td>\n",
       "      <td>6</td>\n",
       "      <td>[(i, organized), (organized, the), (the, instr...</td>\n",
       "      <td>7.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>7508</td>\n",
       "      <td>ad1</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\r\\r...</td>\n",
       "      <td>[First, ,, prepare, a, port, ,, loose, tea, ,,...</td>\n",
       "      <td>[(First, ,), (,, prepare), (prepare, a), (a, p...</td>\n",
       "      <td>73</td>\n",
       "      <td>[(first, ,), (,, prepare), (prepare, a), (a, p...</td>\n",
       "      <td>228.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id  user_file_id anon_id  level_id  course_id  \\\n",
       "answer_id                                                           \n",
       "3                   12          7507     dk5         4        115   \n",
       "4                   13          7507     dk5         4        115   \n",
       "5                   12          7508     ad1         4        115   \n",
       "\n",
       "                                                        text  \\\n",
       "answer_id                                                      \n",
       "3          In my country we usually don't use tea bags. F...   \n",
       "4                      I organized the instructions by time.   \n",
       "5          First, prepare a port, loose tea, and cup.\\r\\r...   \n",
       "\n",
       "                                                        toks  \\\n",
       "answer_id                                                      \n",
       "3          [In, my, country, we, usually, do, n't, use, t...   \n",
       "4             [I, organized, the, instructions, by, time, .]   \n",
       "5          [First, ,, prepare, a, port, ,, loose, tea, ,,...   \n",
       "\n",
       "                                                     bigrams  bigram_len  \\\n",
       "answer_id                                                                  \n",
       "3          [(In, my), (my, country), (country, we), (we, ...          67   \n",
       "4          [(I, organized), (organized, the), (the, instr...           6   \n",
       "5          [(First, ,), (,, prepare), (prepare, a), (a, p...          73   \n",
       "\n",
       "                                               bigrams_lower  MI_sum  \n",
       "answer_id                                                             \n",
       "3          [(in, my), (my, country), (country, we), (we, ...  181.28  \n",
       "4          [(i, organized), (organized, the), (the, instr...    7.65  \n",
       "5          [(first, ,), (,, prepare), (prepare, a), (a, p...  228.84  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a total of MI scores for each text (for machine learning later)\n",
    "combo_df['MI_sum'] = [x[0] for x in text_MI]\n",
    "\n",
    "combo_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create an avg_bigram_MI scores for each text\n",
    "\n",
    "combo_df['avg_bigram_MI'] = combo_df['MI_sum'] / combo_df['bigram_len'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>bigram_len</th>\n",
       "      <th>bigrams_lower</th>\n",
       "      <th>MI_sum</th>\n",
       "      <th>avg_bigram_MI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>7507</td>\n",
       "      <td>dk5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>[In, my, country, we, usually, do, n't, use, t...</td>\n",
       "      <td>[(In, my), (my, country), (country, we), (we, ...</td>\n",
       "      <td>67</td>\n",
       "      <td>[(in, my), (my, country), (country, we), (we, ...</td>\n",
       "      <td>181.28</td>\n",
       "      <td>2.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>7507</td>\n",
       "      <td>dk5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "      <td>[I, organized, the, instructions, by, time, .]</td>\n",
       "      <td>[(I, organized), (organized, the), (the, instr...</td>\n",
       "      <td>6</td>\n",
       "      <td>[(i, organized), (organized, the), (the, instr...</td>\n",
       "      <td>7.65</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>7508</td>\n",
       "      <td>ad1</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\r\\r...</td>\n",
       "      <td>[First, ,, prepare, a, port, ,, loose, tea, ,,...</td>\n",
       "      <td>[(First, ,), (,, prepare), (prepare, a), (a, p...</td>\n",
       "      <td>73</td>\n",
       "      <td>[(first, ,), (,, prepare), (prepare, a), (a, p...</td>\n",
       "      <td>228.84</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>7508</td>\n",
       "      <td>ad1</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>By time</td>\n",
       "      <td>[By, time]</td>\n",
       "      <td>[(By, time)]</td>\n",
       "      <td>1</td>\n",
       "      <td>[(by, time)]</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>7509</td>\n",
       "      <td>eg5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>First, prepare your cup, loose tea or bag tea,...</td>\n",
       "      <td>[First, ,, prepare, your, cup, ,, loose, tea, ...</td>\n",
       "      <td>[(First, ,), (,, prepare), (prepare, your), (y...</td>\n",
       "      <td>49</td>\n",
       "      <td>[(first, ,), (,, prepare), (prepare, your), (y...</td>\n",
       "      <td>120.11</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id  user_file_id anon_id  level_id  course_id  \\\n",
       "answer_id                                                           \n",
       "3                   12          7507     dk5         4        115   \n",
       "4                   13          7507     dk5         4        115   \n",
       "5                   12          7508     ad1         4        115   \n",
       "6                   13          7508     ad1         4        115   \n",
       "7                   12          7509     eg5         4        115   \n",
       "\n",
       "                                                        text  \\\n",
       "answer_id                                                      \n",
       "3          In my country we usually don't use tea bags. F...   \n",
       "4                      I organized the instructions by time.   \n",
       "5          First, prepare a port, loose tea, and cup.\\r\\r...   \n",
       "6                                                    By time   \n",
       "7          First, prepare your cup, loose tea or bag tea,...   \n",
       "\n",
       "                                                        toks  \\\n",
       "answer_id                                                      \n",
       "3          [In, my, country, we, usually, do, n't, use, t...   \n",
       "4             [I, organized, the, instructions, by, time, .]   \n",
       "5          [First, ,, prepare, a, port, ,, loose, tea, ,,...   \n",
       "6                                                 [By, time]   \n",
       "7          [First, ,, prepare, your, cup, ,, loose, tea, ...   \n",
       "\n",
       "                                                     bigrams  bigram_len  \\\n",
       "answer_id                                                                  \n",
       "3          [(In, my), (my, country), (country, we), (we, ...          67   \n",
       "4          [(I, organized), (organized, the), (the, instr...           6   \n",
       "5          [(First, ,), (,, prepare), (prepare, a), (a, p...          73   \n",
       "6                                               [(By, time)]           1   \n",
       "7          [(First, ,), (,, prepare), (prepare, your), (y...          49   \n",
       "\n",
       "                                               bigrams_lower  MI_sum  \\\n",
       "answer_id                                                              \n",
       "3          [(in, my), (my, country), (country, we), (we, ...  181.28   \n",
       "4          [(i, organized), (organized, the), (the, instr...    7.65   \n",
       "5          [(first, ,), (,, prepare), (prepare, a), (a, p...  228.84   \n",
       "6                                               [(by, time)]   -0.24   \n",
       "7          [(first, ,), (,, prepare), (prepare, your), (y...  120.11   \n",
       "\n",
       "           avg_bigram_MI  \n",
       "answer_id                 \n",
       "3                   2.71  \n",
       "4                   1.28  \n",
       "5                   3.13  \n",
       "6                  -0.24  \n",
       "7                   2.45  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_df[['avg_bigram_MI']] = combo_df[['avg_bigram_MI']].apply(lambda x: pd.Series.round(x, 2)) #round to 2 decimals\n",
    "combo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>bigram_len</th>\n",
       "      <th>bigrams_lower</th>\n",
       "      <th>MI_sum</th>\n",
       "      <th>avg_bigram_MI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>7507</td>\n",
       "      <td>dk5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>[In, my, country, we, usually, do, n't, use, t...</td>\n",
       "      <td>[(In, my), (my, country), (country, we), (we, ...</td>\n",
       "      <td>67</td>\n",
       "      <td>[(in, my), (my, country), (country, we), (we, ...</td>\n",
       "      <td>181.28</td>\n",
       "      <td>2.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>7508</td>\n",
       "      <td>ad1</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\r\\r...</td>\n",
       "      <td>[First, ,, prepare, a, port, ,, loose, tea, ,,...</td>\n",
       "      <td>[(First, ,), (,, prepare), (prepare, a), (a, p...</td>\n",
       "      <td>73</td>\n",
       "      <td>[(first, ,), (,, prepare), (prepare, a), (a, p...</td>\n",
       "      <td>228.84</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>7509</td>\n",
       "      <td>eg5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>First, prepare your cup, loose tea or bag tea,...</td>\n",
       "      <td>[First, ,, prepare, your, cup, ,, loose, tea, ...</td>\n",
       "      <td>[(First, ,), (,, prepare), (prepare, your), (y...</td>\n",
       "      <td>49</td>\n",
       "      <td>[(first, ,), (,, prepare), (prepare, your), (y...</td>\n",
       "      <td>120.11</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>7509</td>\n",
       "      <td>eg5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>I organized the instructions by time, beacause...</td>\n",
       "      <td>[I, organized, the, instructions, by, time, ,,...</td>\n",
       "      <td>[(I, organized), (organized, the), (the, instr...</td>\n",
       "      <td>38</td>\n",
       "      <td>[(i, organized), (organized, the), (the, instr...</td>\n",
       "      <td>102.94</td>\n",
       "      <td>2.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>7511</td>\n",
       "      <td>fv6</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>To make tea, nothing is easier, even if someti...</td>\n",
       "      <td>[To, make, tea, ,, nothing, is, easier, ,, eve...</td>\n",
       "      <td>[(To, make), (make, tea), (tea, ,), (,, nothin...</td>\n",
       "      <td>98</td>\n",
       "      <td>[(to, make), (make, tea), (tea, ,), (,, nothin...</td>\n",
       "      <td>269.31</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id  user_file_id anon_id  level_id  course_id  \\\n",
       "answer_id                                                           \n",
       "3                   12          7507     dk5         4        115   \n",
       "5                   12          7508     ad1         4        115   \n",
       "7                   12          7509     eg5         4        115   \n",
       "8                   13          7509     eg5         4        115   \n",
       "11                  12          7511     fv6         4        115   \n",
       "\n",
       "                                                        text  \\\n",
       "answer_id                                                      \n",
       "3          In my country we usually don't use tea bags. F...   \n",
       "5          First, prepare a port, loose tea, and cup.\\r\\r...   \n",
       "7          First, prepare your cup, loose tea or bag tea,...   \n",
       "8          I organized the instructions by time, beacause...   \n",
       "11         To make tea, nothing is easier, even if someti...   \n",
       "\n",
       "                                                        toks  \\\n",
       "answer_id                                                      \n",
       "3          [In, my, country, we, usually, do, n't, use, t...   \n",
       "5          [First, ,, prepare, a, port, ,, loose, tea, ,,...   \n",
       "7          [First, ,, prepare, your, cup, ,, loose, tea, ...   \n",
       "8          [I, organized, the, instructions, by, time, ,,...   \n",
       "11         [To, make, tea, ,, nothing, is, easier, ,, eve...   \n",
       "\n",
       "                                                     bigrams  bigram_len  \\\n",
       "answer_id                                                                  \n",
       "3          [(In, my), (my, country), (country, we), (we, ...          67   \n",
       "5          [(First, ,), (,, prepare), (prepare, a), (a, p...          73   \n",
       "7          [(First, ,), (,, prepare), (prepare, your), (y...          49   \n",
       "8          [(I, organized), (organized, the), (the, instr...          38   \n",
       "11         [(To, make), (make, tea), (tea, ,), (,, nothin...          98   \n",
       "\n",
       "                                               bigrams_lower  MI_sum  \\\n",
       "answer_id                                                              \n",
       "3          [(in, my), (my, country), (country, we), (we, ...  181.28   \n",
       "5          [(first, ,), (,, prepare), (prepare, a), (a, p...  228.84   \n",
       "7          [(first, ,), (,, prepare), (prepare, your), (y...  120.11   \n",
       "8          [(i, organized), (organized, the), (the, instr...  102.94   \n",
       "11         [(to, make), (make, tea), (tea, ,), (,, nothin...  269.31   \n",
       "\n",
       "           avg_bigram_MI  \n",
       "answer_id                 \n",
       "3                   2.71  \n",
       "5                   3.13  \n",
       "7                   2.45  \n",
       "8                   2.71  \n",
       "11                  2.75  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's also remove very short texts of less than 10 words which are not 'essays'\n",
    "\n",
    "combo_df = combo_df.loc[combo_df['bigram_len'] >= 10]\n",
    "combo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Occurrences per million ###\n",
    "- Create function for calculating occurrences per million  \n",
    "- For unigrams and bigrams  \n",
    "\n",
    "Formula:\n",
    "\n",
    "FN = FO(1,000,000) / C\n",
    "\n",
    "FN = normalized frequency\n",
    "FO = observed frequency\n",
    "C = corpus size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2549012"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2549011"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total number of unigrams\n",
    "total_unigrams = len(combo_corpus_tok)\n",
    "\n",
    "#total number of bigrams\n",
    "total_bigrams = len(combo_corpus_bigrams)\n",
    "\n",
    "total_unigrams\n",
    "total_bigrams\n",
    "\n",
    "#different by one a bigrams will be naturally be unigrams - 1 (for the first one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create function where you enter the unigram and it tells you the frequency in the corpus per million tokens\n",
    "\n",
    "def unigram_per_M(unigram):\n",
    "   return (combo_unigram_dict[unigram]*1000000) / total_unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create function where you enter the bigram and it tells you the frequency in the corpus per million tokens\n",
    "\n",
    "def bigram_per_M(word1, word2):\n",
    "   return (combo_bigram_dict[word1, word2]*1000000) / total_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. bigram_df ###\n",
    "\n",
    "Create bigram_df showing relevant info based on above formulas\n",
    "\n",
    "- columns for this dataframe:\n",
    "    - default index\n",
    "    - bigrams\n",
    "    - MI scores\n",
    "    - occurrences per million\n",
    "    - normalized percentage used at each proficiency level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(in, my)</td>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(my, country)</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(country, we)</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(we, usually)</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(usually, do)</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bigram  tokens\n",
       "0       (in, my)    2629\n",
       "1  (my, country)     875\n",
       "2  (country, we)      17\n",
       "3  (we, usually)      80\n",
       "4  (usually, do)      53"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating bigrams and tokens columns\n",
    "\n",
    "bigram_df = pd.DataFrame.from_dict(combo_bigram_dict,orient='index')\n",
    "bigram_df = bigram_df.reset_index()\n",
    "bigram_df = bigram_df.rename(columns = {0:'tokens', 'index': 'bigram'})\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Changing bigram tuples to lists for easier manipulation\n",
    "\n",
    "bigram_df['bigram'] = [list(x) for x in bigram_df['bigram']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating MI column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creating MI column (takes a few hours)\n",
    "\n",
    "bigram_df['MI'] = [MI(x[0], x[1]) for x in bigram_df['bigram']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>tokens</th>\n",
       "      <th>MI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[in, my]</td>\n",
       "      <td>2629</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[my, country]</td>\n",
       "      <td>875</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[country, we]</td>\n",
       "      <td>17</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[we, usually]</td>\n",
       "      <td>80</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[usually, do]</td>\n",
       "      <td>53</td>\n",
       "      <td>3.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bigram  tokens    MI\n",
       "0       [in, my]    2629  3.13\n",
       "1  [my, country]     875  5.50\n",
       "2  [country, we]      17  0.36\n",
       "3  [we, usually]      80  3.41\n",
       "4  [usually, do]      53  3.07"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rounding results to two decimal places\n",
    "\n",
    "bigram_df[['MI']] = bigram_df[['MI']].apply(lambda x: pd.Series.round(x, 2))\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating per_million column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_df['per_million'] = [bigram_per_M(x[0], x[1]) for x in bigram_df['bigram']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>tokens</th>\n",
       "      <th>MI</th>\n",
       "      <th>per_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[in, my]</td>\n",
       "      <td>2629</td>\n",
       "      <td>3.13</td>\n",
       "      <td>1031.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[my, country]</td>\n",
       "      <td>875</td>\n",
       "      <td>5.50</td>\n",
       "      <td>343.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[country, we]</td>\n",
       "      <td>17</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[we, usually]</td>\n",
       "      <td>80</td>\n",
       "      <td>3.41</td>\n",
       "      <td>31.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[usually, do]</td>\n",
       "      <td>53</td>\n",
       "      <td>3.07</td>\n",
       "      <td>20.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bigram  tokens    MI  per_million\n",
       "0       [in, my]    2629  3.13      1031.38\n",
       "1  [my, country]     875  5.50       343.27\n",
       "2  [country, we]      17  0.36         6.67\n",
       "3  [we, usually]      80  3.41        31.38\n",
       "4  [usually, do]      53  3.07        20.79"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rounding to two decimal places\n",
    "\n",
    "bigram_df[['per_million']] = bigram_df[['per_million']].apply(lambda x: pd.Series.round(x, 2))\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating 'normalized toks per level' and 'relative percentage per level' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create level dataframes\n",
    "level_3 = combo_df.loc[combo_df['level_id'] == 3, :] \n",
    "level_4 = combo_df.loc[combo_df['level_id'] == 4, :] \n",
    "level_5 = combo_df.loc[combo_df['level_id'] == 5, :] \n",
    "\n",
    "#create frequency dictionaries for each level\n",
    "level_3_corpus = ' '.join(level_3['text'])\n",
    "level_3_tok = nltk.word_tokenize(level_3_corpus)\n",
    "level_3_tok = list(map(lambda x:x.lower(),level_3_tok))\n",
    "level_3_bigrams = list(nltk.bigrams(level_3_tok))\n",
    "level_3_bigram_dict = nltk.FreqDist(level_3_bigrams)\n",
    "\n",
    "level_4_corpus = ' '.join(level_4['text'])\n",
    "level_4_tok = nltk.word_tokenize(level_4_corpus)\n",
    "level_4_tok = list(map(lambda x:x.lower(),level_4_tok))\n",
    "level_4_bigrams = list(nltk.bigrams(level_4_tok))\n",
    "level_4_bigram_dict = nltk.FreqDist(level_4_bigrams)\n",
    "\n",
    "level_5_corpus = ' '.join(level_5['text'])\n",
    "level_5_tok = nltk.word_tokenize(level_5_corpus)\n",
    "level_5_tok = list(map(lambda x:x.lower(),level_5_tok))\n",
    "level_5_bigrams = list(nltk.bigrams(level_5_tok))\n",
    "level_5_bigram_dict = nltk.FreqDist(level_5_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12.06%'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'12.06%'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'40.50%'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'47.01%'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "99.99000000000001"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of what each cell should contain in the level_3 column\n",
    "#level_3_bigram_dict divided by the value from combo_bigram_dict\n",
    "\n",
    "#for example\n",
    "\"{0:.2f}%\".format(level_3_bigram_dict['in', 'the'] / combo_bigram_dict['in', 'the'] * 100)\n",
    "\n",
    "#totals for all 3 levels should add up to 100%\n",
    "\"{0:.2f}%\".format(level_3_bigram_dict['in', 'the'] / combo_bigram_dict['in', 'the'] * 100)\n",
    "\"{0:.2f}%\".format(level_4_bigram_dict['in', 'the'] / combo_bigram_dict['in', 'the'] * 100)\n",
    "\"{0:.2f}%\".format(level_5_bigram_dict['in', 'the'] / combo_bigram_dict['in', 'the'] * 100)\n",
    "\n",
    "12.17 + 40.75 + 47.07 #close enough!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create updated freq dicts for combo_df (unigrams and bigrams)\n",
    "\n",
    "combo_corpus = ' '.join(combo_df['text'])\n",
    "combo_corpus_tok = nltk.word_tokenize(combo_corpus)\n",
    "combo_corpus_tok = list(map(lambda x:x.lower(),combo_corpus_tok))\n",
    "combo_unigram_dict = nltk.FreqDist(combo_corpus_tok)\n",
    "\n",
    "combo_corpus_bigrams = list(nltk.bigrams(combo_corpus_tok))\n",
    "combo_bigram_dict = nltk.FreqDist(combo_corpus_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1347"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4525"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5252"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11124"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11124"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking that level bigram dicts add up to existing total bigram dict\n",
    "level_3_bigram_dict['in', 'the']\n",
    "level_4_bigram_dict['in', 'the']\n",
    "level_5_bigram_dict['in', 'the']\n",
    "\n",
    "level_3_bigram_dict['in', 'the'] + level_4_bigram_dict['in', 'the'] + level_5_bigram_dict['in', 'the']\n",
    "\n",
    "combo_bigram_dict['in', 'the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24625775830595106"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4115553121577218"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3421869295363271"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.08707557502738225"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.07822197882438847"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.008853596202993808"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#also necessary to normalize as different number of responses at each level\n",
    "\n",
    "#weighting for each level\n",
    "level_3_weighting = len(level_3.index) / len(combo_df.index)\n",
    "level_4_weighting = len(level_4.index) / len(combo_df.index)\n",
    "level_5_weighting = len(level_5.index) / len(combo_df.index)\n",
    "\n",
    "level_3_weighting\n",
    "level_4_weighting\n",
    "level_5_weighting\n",
    "\n",
    "level_3_weighting+level_4_weighting+level_5_weighting #should equal 100\n",
    "\n",
    "#difference between observed and expected, i.e. expected weighting (.33) -  actual weighting (level_N_percent)\n",
    "level_3_change = (1/3) - level_3_weighting\n",
    "level_4_change = (1/3) - level_4_weighting\n",
    "level_5_change = (1/3) - level_5_weighting\n",
    "\n",
    "level_3_change\n",
    "level_4_change\n",
    "level_5_change\n",
    "\n",
    "round(level_3_change + level_4_change + level_5_change, 2) # should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1347"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4525"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5252"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11124"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2315.6286966046"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3654.8587075575024"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5153.512595837897"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11124.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of normalizing with ['in', 'the'] bigram\n",
    "\n",
    "#un-normalized number\n",
    "level_3_bigram_dict['in', 'the']\n",
    "level_4_bigram_dict['in', 'the']\n",
    "level_5_bigram_dict['in', 'the']\n",
    "combo_bigram_dict['in', 'the']\n",
    "\n",
    "#normalized number\n",
    "n3 = level_3_bigram_dict['in', 'the'] + (combo_bigram_dict['in', 'the'] * level_3_change)\n",
    "n4 = level_4_bigram_dict['in', 'the'] + (combo_bigram_dict['in', 'the'] * level_4_change)\n",
    "n5 = level_5_bigram_dict['in', 'the'] + (combo_bigram_dict['in', 'the'] * level_5_change)\n",
    "\n",
    "n3\n",
    "n4\n",
    "n5\n",
    "\n",
    "n3 + n4 + n5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2315"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3654"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5153"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a function for the above\n",
    "\n",
    "def norm_toks_level3(word1, word2):\n",
    "    return int((level_3_bigram_dict[word1,word2] + (combo_bigram_dict[word1,word2] * level_3_change)))\n",
    "\n",
    "def norm_toks_level4(word1, word2):\n",
    "    return int((level_4_bigram_dict[word1,word2] + (combo_bigram_dict[word1,word2] * level_4_change)))\n",
    "            \n",
    "def norm_toks_level5(word1, word2):\n",
    "    return int((level_5_bigram_dict[word1,word2] + (combo_bigram_dict[word1,word2] * level_5_change)))\n",
    "\n",
    "#Examples:\n",
    "norm_toks_level3('in', 'the')\n",
    "norm_toks_level4('in', 'the')\n",
    "norm_toks_level5('in', 'the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.82"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "32.86"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "46.33"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And as a comparative percentage\n",
    "def norm_percent_level3(word1, word2):\n",
    "    return(round(100*((level_3_bigram_dict[word1,word2] + (combo_bigram_dict[word1,word2] * level_3_change))\n",
    "                      / (combo_bigram_dict[word1, word2]) if combo_bigram_dict[word1, word2] != 0 else 0),2))\n",
    "\n",
    "def norm_percent_level4(word1, word2):\n",
    "    return(round(100*((level_4_bigram_dict[word1,word2] + (combo_bigram_dict[word1,word2] * level_4_change))\n",
    "                      / (combo_bigram_dict[word1, word2]) if combo_bigram_dict[word1, word2] != 0 else 0),2))\n",
    "\n",
    "def norm_percent_level5(word1, word2):\n",
    "    return(round(100*((level_5_bigram_dict[word1,word2] + (combo_bigram_dict[word1,word2] * level_5_change))\n",
    "                      / (combo_bigram_dict[word1, word2]) if combo_bigram_dict[word1, word2] != 0 else 0),2))\n",
    "\n",
    "#Examples:\n",
    "norm_percent_level3('in', 'the')\n",
    "norm_percent_level4('in', 'the')\n",
    "norm_percent_level5('in', 'the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>tokens</th>\n",
       "      <th>MI</th>\n",
       "      <th>per_million</th>\n",
       "      <th>lv3_norm_toks</th>\n",
       "      <th>lv4_norm_toks</th>\n",
       "      <th>lv5_norm_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[in, my]</td>\n",
       "      <td>2629</td>\n",
       "      <td>3.13</td>\n",
       "      <td>1031.38</td>\n",
       "      <td>687</td>\n",
       "      <td>1124</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[my, country]</td>\n",
       "      <td>875</td>\n",
       "      <td>5.50</td>\n",
       "      <td>343.27</td>\n",
       "      <td>249</td>\n",
       "      <td>321</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[country, we]</td>\n",
       "      <td>17</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.67</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[we, usually]</td>\n",
       "      <td>80</td>\n",
       "      <td>3.41</td>\n",
       "      <td>31.38</td>\n",
       "      <td>14</td>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[usually, do]</td>\n",
       "      <td>53</td>\n",
       "      <td>3.07</td>\n",
       "      <td>20.79</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bigram  tokens    MI  per_million  lv3_norm_toks  lv4_norm_toks  \\\n",
       "0       [in, my]    2629  3.13      1031.38            687           1124   \n",
       "1  [my, country]     875  5.50       343.27            249            321   \n",
       "2  [country, we]      17  0.36         6.67              2             10   \n",
       "3  [we, usually]      80  3.41        31.38             14             51   \n",
       "4  [usually, do]      53  3.07        20.79              6             26   \n",
       "\n",
       "   lv5_norm_toks  \n",
       "0            805  \n",
       "1            298  \n",
       "2              3  \n",
       "3             13  \n",
       "4             19  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalized tokens pplied to the whole dataframe\n",
    "\n",
    "bigram_df['lv3_norm_toks'] = [norm_toks_level3(x[0], x[1]) for x in bigram_df['bigram']]\n",
    "bigram_df['lv4_norm_toks'] = [norm_toks_level4(x[0], x[1]) for x in bigram_df['bigram']]\n",
    "bigram_df['lv5_norm_toks'] = [norm_toks_level5(x[0], x[1]) for x in bigram_df['bigram']]\n",
    "\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>tokens</th>\n",
       "      <th>MI</th>\n",
       "      <th>per_million</th>\n",
       "      <th>lv3_norm_toks</th>\n",
       "      <th>lv4_norm_toks</th>\n",
       "      <th>lv5_norm_toks</th>\n",
       "      <th>lv3_rel_%</th>\n",
       "      <th>lv4_rel_%</th>\n",
       "      <th>lv5_rel_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[in, my]</td>\n",
       "      <td>2629</td>\n",
       "      <td>3.13</td>\n",
       "      <td>1031.38</td>\n",
       "      <td>687</td>\n",
       "      <td>1124</td>\n",
       "      <td>805</td>\n",
       "      <td>26.28</td>\n",
       "      <td>42.94</td>\n",
       "      <td>30.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[my, country]</td>\n",
       "      <td>875</td>\n",
       "      <td>5.50</td>\n",
       "      <td>343.27</td>\n",
       "      <td>249</td>\n",
       "      <td>321</td>\n",
       "      <td>298</td>\n",
       "      <td>28.71</td>\n",
       "      <td>37.01</td>\n",
       "      <td>34.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[country, we]</td>\n",
       "      <td>17</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.67</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>14.59</td>\n",
       "      <td>62.77</td>\n",
       "      <td>22.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[we, usually]</td>\n",
       "      <td>80</td>\n",
       "      <td>3.41</td>\n",
       "      <td>31.38</td>\n",
       "      <td>14</td>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "      <td>18.71</td>\n",
       "      <td>64.68</td>\n",
       "      <td>16.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[usually, do]</td>\n",
       "      <td>53</td>\n",
       "      <td>3.07</td>\n",
       "      <td>20.79</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>12.48</td>\n",
       "      <td>50.67</td>\n",
       "      <td>36.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bigram  tokens    MI  per_million  lv3_norm_toks  lv4_norm_toks  \\\n",
       "0       [in, my]    2629  3.13      1031.38            687           1124   \n",
       "1  [my, country]     875  5.50       343.27            249            321   \n",
       "2  [country, we]      17  0.36         6.67              2             10   \n",
       "3  [we, usually]      80  3.41        31.38             14             51   \n",
       "4  [usually, do]      53  3.07        20.79              6             26   \n",
       "\n",
       "   lv5_norm_toks  lv3_rel_%  lv4_rel_%  lv5_rel_%  \n",
       "0            805      26.28      42.94      30.78  \n",
       "1            298      28.71      37.01      34.29  \n",
       "2              3      14.59      62.77      22.64  \n",
       "3             13      18.71      64.68      16.61  \n",
       "4             19      12.48      50.67      36.85  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And now the comparative percentages\n",
    "\n",
    "bigram_df['lv3_rel_%'] = [norm_percent_level3(x[0], x[1]) for x in bigram_df['bigram']]\n",
    "bigram_df['lv4_rel_%'] = [norm_percent_level4(x[0], x[1]) for x in bigram_df['bigram']]\n",
    "bigram_df['lv5_rel_%'] = [norm_percent_level5(x[0], x[1]) for x in bigram_df['bigram']]\n",
    "\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating level per_million columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create per_million columns for each level\n",
    "\n",
    "bigram_df['lv3_per_M'] = round(bigram_df['lv3_norm_toks']*1000000/total_bigrams, 2)\n",
    "bigram_df['lv4_per_M'] = round(bigram_df['lv4_norm_toks']*1000000/total_bigrams, 2)\n",
    "bigram_df['lv5_per_M'] = round(bigram_df['lv5_norm_toks']*1000000/total_bigrams, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>tokens</th>\n",
       "      <th>MI</th>\n",
       "      <th>per_million</th>\n",
       "      <th>lv3_norm_toks</th>\n",
       "      <th>lv4_norm_toks</th>\n",
       "      <th>lv5_norm_toks</th>\n",
       "      <th>lv3_rel_%</th>\n",
       "      <th>lv4_rel_%</th>\n",
       "      <th>lv5_rel_%</th>\n",
       "      <th>lv3_per_M</th>\n",
       "      <th>lv4_per_M</th>\n",
       "      <th>lv5_per_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[in, my]</td>\n",
       "      <td>2629</td>\n",
       "      <td>3.13</td>\n",
       "      <td>1031.38</td>\n",
       "      <td>687</td>\n",
       "      <td>1124</td>\n",
       "      <td>805</td>\n",
       "      <td>26.28</td>\n",
       "      <td>42.94</td>\n",
       "      <td>30.78</td>\n",
       "      <td>269.52</td>\n",
       "      <td>440.96</td>\n",
       "      <td>315.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[my, country]</td>\n",
       "      <td>875</td>\n",
       "      <td>5.50</td>\n",
       "      <td>343.27</td>\n",
       "      <td>249</td>\n",
       "      <td>321</td>\n",
       "      <td>298</td>\n",
       "      <td>28.71</td>\n",
       "      <td>37.01</td>\n",
       "      <td>34.29</td>\n",
       "      <td>97.68</td>\n",
       "      <td>125.93</td>\n",
       "      <td>116.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[country, we]</td>\n",
       "      <td>17</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.67</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>14.59</td>\n",
       "      <td>62.77</td>\n",
       "      <td>22.64</td>\n",
       "      <td>0.78</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[we, usually]</td>\n",
       "      <td>80</td>\n",
       "      <td>3.41</td>\n",
       "      <td>31.38</td>\n",
       "      <td>14</td>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "      <td>18.71</td>\n",
       "      <td>64.68</td>\n",
       "      <td>16.61</td>\n",
       "      <td>5.49</td>\n",
       "      <td>20.01</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[usually, do]</td>\n",
       "      <td>53</td>\n",
       "      <td>3.07</td>\n",
       "      <td>20.79</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>12.48</td>\n",
       "      <td>50.67</td>\n",
       "      <td>36.85</td>\n",
       "      <td>2.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>7.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bigram  tokens    MI  per_million  lv3_norm_toks  lv4_norm_toks  \\\n",
       "1       [in, my]    2629  3.13      1031.38            687           1124   \n",
       "2  [my, country]     875  5.50       343.27            249            321   \n",
       "3  [country, we]      17  0.36         6.67              2             10   \n",
       "4  [we, usually]      80  3.41        31.38             14             51   \n",
       "5  [usually, do]      53  3.07        20.79              6             26   \n",
       "\n",
       "   lv5_norm_toks  lv3_rel_%  lv4_rel_%  lv5_rel_%  lv3_per_M  lv4_per_M  \\\n",
       "1            805      26.28      42.94      30.78     269.52     440.96   \n",
       "2            298      28.71      37.01      34.29      97.68     125.93   \n",
       "3              3      14.59      62.77      22.64       0.78       3.92   \n",
       "4             13      18.71      64.68      16.61       5.49      20.01   \n",
       "5             19      12.48      50.67      36.85       2.35      10.20   \n",
       "\n",
       "   lv5_per_M  \n",
       "1     315.81  \n",
       "2     116.91  \n",
       "3       1.18  \n",
       "4       5.10  \n",
       "5       7.45  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_df.index += 1 #frequency lists look better starting at 1\n",
    "\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>bigram_len</th>\n",
       "      <th>bigrams_lower</th>\n",
       "      <th>MI_sum</th>\n",
       "      <th>avg_bigram_MI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>7507</td>\n",
       "      <td>dk5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>[In, my, country, we, usually, do, n't, use, t...</td>\n",
       "      <td>[(In, my), (my, country), (country, we), (we, ...</td>\n",
       "      <td>67</td>\n",
       "      <td>[(in, my), (my, country), (country, we), (we, ...</td>\n",
       "      <td>181.28</td>\n",
       "      <td>2.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>7508</td>\n",
       "      <td>ad1</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\r\\r...</td>\n",
       "      <td>[First, ,, prepare, a, port, ,, loose, tea, ,,...</td>\n",
       "      <td>[(First, ,), (,, prepare), (prepare, a), (a, p...</td>\n",
       "      <td>73</td>\n",
       "      <td>[(first, ,), (,, prepare), (prepare, a), (a, p...</td>\n",
       "      <td>228.84</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>7509</td>\n",
       "      <td>eg5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>First, prepare your cup, loose tea or bag tea,...</td>\n",
       "      <td>[First, ,, prepare, your, cup, ,, loose, tea, ...</td>\n",
       "      <td>[(First, ,), (,, prepare), (prepare, your), (y...</td>\n",
       "      <td>49</td>\n",
       "      <td>[(first, ,), (,, prepare), (prepare, your), (y...</td>\n",
       "      <td>120.11</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>7509</td>\n",
       "      <td>eg5</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>I organized the instructions by time, beacause...</td>\n",
       "      <td>[I, organized, the, instructions, by, time, ,,...</td>\n",
       "      <td>[(I, organized), (organized, the), (the, instr...</td>\n",
       "      <td>38</td>\n",
       "      <td>[(i, organized), (organized, the), (the, instr...</td>\n",
       "      <td>102.94</td>\n",
       "      <td>2.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>7511</td>\n",
       "      <td>fv6</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>To make tea, nothing is easier, even if someti...</td>\n",
       "      <td>[To, make, tea, ,, nothing, is, easier, ,, eve...</td>\n",
       "      <td>[(To, make), (make, tea), (tea, ,), (,, nothin...</td>\n",
       "      <td>98</td>\n",
       "      <td>[(to, make), (make, tea), (tea, ,), (,, nothin...</td>\n",
       "      <td>269.31</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           question_id  user_file_id anon_id  level_id  course_id  \\\n",
       "answer_id                                                           \n",
       "3                   12          7507     dk5         4        115   \n",
       "5                   12          7508     ad1         4        115   \n",
       "7                   12          7509     eg5         4        115   \n",
       "8                   13          7509     eg5         4        115   \n",
       "11                  12          7511     fv6         4        115   \n",
       "\n",
       "                                                        text  \\\n",
       "answer_id                                                      \n",
       "3          In my country we usually don't use tea bags. F...   \n",
       "5          First, prepare a port, loose tea, and cup.\\r\\r...   \n",
       "7          First, prepare your cup, loose tea or bag tea,...   \n",
       "8          I organized the instructions by time, beacause...   \n",
       "11         To make tea, nothing is easier, even if someti...   \n",
       "\n",
       "                                                        toks  \\\n",
       "answer_id                                                      \n",
       "3          [In, my, country, we, usually, do, n't, use, t...   \n",
       "5          [First, ,, prepare, a, port, ,, loose, tea, ,,...   \n",
       "7          [First, ,, prepare, your, cup, ,, loose, tea, ...   \n",
       "8          [I, organized, the, instructions, by, time, ,,...   \n",
       "11         [To, make, tea, ,, nothing, is, easier, ,, eve...   \n",
       "\n",
       "                                                     bigrams  bigram_len  \\\n",
       "answer_id                                                                  \n",
       "3          [(In, my), (my, country), (country, we), (we, ...          67   \n",
       "5          [(First, ,), (,, prepare), (prepare, a), (a, p...          73   \n",
       "7          [(First, ,), (,, prepare), (prepare, your), (y...          49   \n",
       "8          [(I, organized), (organized, the), (the, instr...          38   \n",
       "11         [(To, make), (make, tea), (tea, ,), (,, nothin...          98   \n",
       "\n",
       "                                               bigrams_lower  MI_sum  \\\n",
       "answer_id                                                              \n",
       "3          [(in, my), (my, country), (country, we), (we, ...  181.28   \n",
       "5          [(first, ,), (,, prepare), (prepare, a), (a, p...  228.84   \n",
       "7          [(first, ,), (,, prepare), (prepare, your), (y...  120.11   \n",
       "8          [(i, organized), (organized, the), (the, instr...  102.94   \n",
       "11         [(to, make), (make, tea), (tea, ,), (,, nothin...  269.31   \n",
       "\n",
       "           avg_bigram_MI  \n",
       "answer_id                 \n",
       "3                   2.71  \n",
       "5                   3.13  \n",
       "7                   2.45  \n",
       "8                   2.71  \n",
       "11                  2.75  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>tokens</th>\n",
       "      <th>MI</th>\n",
       "      <th>per_million</th>\n",
       "      <th>lv3_norm_toks</th>\n",
       "      <th>lv4_norm_toks</th>\n",
       "      <th>lv5_norm_toks</th>\n",
       "      <th>lv3_rel_%</th>\n",
       "      <th>lv4_rel_%</th>\n",
       "      <th>lv5_rel_%</th>\n",
       "      <th>lv3_per_M</th>\n",
       "      <th>lv4_per_M</th>\n",
       "      <th>lv5_per_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[in, my]</td>\n",
       "      <td>2629</td>\n",
       "      <td>3.13</td>\n",
       "      <td>1031.38</td>\n",
       "      <td>687</td>\n",
       "      <td>1124</td>\n",
       "      <td>805</td>\n",
       "      <td>26.28</td>\n",
       "      <td>42.94</td>\n",
       "      <td>30.78</td>\n",
       "      <td>269.52</td>\n",
       "      <td>440.96</td>\n",
       "      <td>315.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[my, country]</td>\n",
       "      <td>875</td>\n",
       "      <td>5.50</td>\n",
       "      <td>343.27</td>\n",
       "      <td>249</td>\n",
       "      <td>321</td>\n",
       "      <td>298</td>\n",
       "      <td>28.71</td>\n",
       "      <td>37.01</td>\n",
       "      <td>34.29</td>\n",
       "      <td>97.68</td>\n",
       "      <td>125.93</td>\n",
       "      <td>116.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[country, we]</td>\n",
       "      <td>17</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.67</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>14.59</td>\n",
       "      <td>62.77</td>\n",
       "      <td>22.64</td>\n",
       "      <td>0.78</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[we, usually]</td>\n",
       "      <td>80</td>\n",
       "      <td>3.41</td>\n",
       "      <td>31.38</td>\n",
       "      <td>14</td>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "      <td>18.71</td>\n",
       "      <td>64.68</td>\n",
       "      <td>16.61</td>\n",
       "      <td>5.49</td>\n",
       "      <td>20.01</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[usually, do]</td>\n",
       "      <td>53</td>\n",
       "      <td>3.07</td>\n",
       "      <td>20.79</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>12.48</td>\n",
       "      <td>50.67</td>\n",
       "      <td>36.85</td>\n",
       "      <td>2.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>7.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bigram  tokens    MI  per_million  lv3_norm_toks  lv4_norm_toks  \\\n",
       "1       [in, my]    2629  3.13      1031.38            687           1124   \n",
       "2  [my, country]     875  5.50       343.27            249            321   \n",
       "3  [country, we]      17  0.36         6.67              2             10   \n",
       "4  [we, usually]      80  3.41        31.38             14             51   \n",
       "5  [usually, do]      53  3.07        20.79              6             26   \n",
       "\n",
       "   lv5_norm_toks  lv3_rel_%  lv4_rel_%  lv5_rel_%  lv3_per_M  lv4_per_M  \\\n",
       "1            805      26.28      42.94      30.78     269.52     440.96   \n",
       "2            298      28.71      37.01      34.29      97.68     125.93   \n",
       "3              3      14.59      62.77      22.64       0.78       3.92   \n",
       "4             13      18.71      64.68      16.61       5.49      20.01   \n",
       "5             19      12.48      50.67      36.85       2.35      10.20   \n",
       "\n",
       "   lv5_per_M  \n",
       "1     315.81  \n",
       "2     116.91  \n",
       "3       1.18  \n",
       "4       5.10  \n",
       "5       7.45  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_df.head()\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. levels_df ###\n",
    "\n",
    "Create and overall numbers mini dataframe called levels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To see overall types and tokens by level\n",
    "\n",
    "#first find length of sub-corpora\n",
    "lv3_unigrams = len(level_3_tok)\n",
    "lv4_unigrams = len(level_4_tok)\n",
    "lv5_unigrams = len(level_5_tok)\n",
    "\n",
    "lv3_bigrams = len(level_3_bigrams)\n",
    "lv4_bigrams = len(level_4_bigrams)\n",
    "lv5_bigrams = len(level_5_bigrams)\n",
    "\n",
    "unigram_toks = pd.Series([lv3_unigrams, lv4_unigrams, lv5_unigrams, total_unigrams], index=['Level 3', 'Level 4', 'Level 5', 'Total'])\n",
    "bigram_toks = pd.Series([lv3_bigrams, lv4_bigrams, lv5_bigrams, total_bigrams], index=['Level 3', 'Level 4', 'Level 5', 'Total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find number of types for each level and overall\n",
    "\n",
    "total_unigram_types = len(set(combo_corpus_tok))\n",
    "lv3_unigram_types = len(set(level_3_tok))\n",
    "lv4_unigram_types = len(set(level_4_tok))\n",
    "lv5_unigram_types = len(set(level_5_tok))\n",
    "\n",
    "total_bigram_types = len(set(combo_corpus_bigrams))\n",
    "lv3_bigram_types = len(set(level_3_bigrams))\n",
    "lv4_bigram_types = len(set(level_4_bigrams))\n",
    "lv5_bigram_types = len(set(level_5_bigrams))\n",
    "\n",
    "unigram_types = pd.Series([lv3_unigram_types, lv4_unigram_types, lv5_unigram_types, total_unigram_types], index=['Level 3', 'Level 4', 'Level 5', 'Total'])\n",
    "bigram_types = pd.Series([lv3_bigram_types, lv4_bigram_types, lv5_bigram_types, total_bigram_types], index=['Level 3', 'Level 4', 'Level 5', 'Total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find total number of texts at each level and overall\n",
    "\n",
    "total_texts = len(combo_df.index)\n",
    "lv3_texts = len(combo_df.loc[combo_df['level_id'] == 3, :])\n",
    "lv4_texts = len(combo_df.loc[combo_df['level_id'] == 4, :])\n",
    "lv5_texts = len(combo_df.loc[combo_df['level_id'] == 5, :])\n",
    "\n",
    "texts = pd.Series([lv3_texts, lv4_texts, lv5_texts, total_texts], index=['Level 3', 'Level 4', 'Level 5', 'Total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unigram_toks</th>\n",
       "      <th>unigram_types</th>\n",
       "      <th>bigram_toks</th>\n",
       "      <th>bigram_types</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Level 3</th>\n",
       "      <td>282844</td>\n",
       "      <td>11816</td>\n",
       "      <td>282843</td>\n",
       "      <td>81209</td>\n",
       "      <td>2698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Level 4</th>\n",
       "      <td>1193172</td>\n",
       "      <td>23231</td>\n",
       "      <td>1193171</td>\n",
       "      <td>236467</td>\n",
       "      <td>4509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Level 5</th>\n",
       "      <td>1060753</td>\n",
       "      <td>23667</td>\n",
       "      <td>1060752</td>\n",
       "      <td>236637</td>\n",
       "      <td>3749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>2549012</td>\n",
       "      <td>39016</td>\n",
       "      <td>2549011</td>\n",
       "      <td>430738</td>\n",
       "      <td>10956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         unigram_toks  unigram_types  bigram_toks  bigram_types  texts\n",
       "Level 3        282844          11816       282843         81209   2698\n",
       "Level 4       1193172          23231      1193171        236467   4509\n",
       "Level 5       1060753          23667      1060752        236637   3749\n",
       "Total         2549012          39016      2549011        430738  10956"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe\n",
    "\n",
    "levels_df = pd.concat([unigram_toks, unigram_types, bigram_toks, bigram_types, texts], axis = 1)\n",
    "levels_df.columns = ['unigram_toks', 'unigram_types', 'bigram_toks', 'bigram_types', 'texts']\n",
    "levels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Pickling ###\n",
    "\n",
    "Saving pickles of dataframes and MI dict in order to save time in future and to use in other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram_df.pkl pickled.\n",
      "bigram_df.csv written out.\n"
     ]
    }
   ],
   "source": [
    "#save bigram_df as a pickle file and csv for later use\n",
    "\n",
    "outfile = 'bigram_df.pkl'\n",
    "bigram_df.to_pickle(outfile)\n",
    "print(outfile, 'pickled.')\n",
    "\n",
    "outfile = 'bigram_df.csv'\n",
    "bigram_df.to_csv(outfile)\n",
    "print(outfile, 'written out.')\n",
    "\n",
    "#to read in later, use: pandas.read_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combo_df.pkl pickled.\n",
      "combo_df.csv written out.\n"
     ]
    }
   ],
   "source": [
    "#save combo_df as a pickle file and csv for later use\n",
    "\n",
    "outfile = 'combo_df.pkl'\n",
    "combo_df.to_pickle(outfile)\n",
    "print(outfile, 'pickled.')\n",
    "\n",
    "outfile = 'combo_df.csv'\n",
    "combo_df.to_csv(outfile)\n",
    "print(outfile, 'written out.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "levels_df.pkl pickled.\n",
      "levels_df.csv written out.\n"
     ]
    }
   ],
   "source": [
    "#save levels_df as a pickle file and csv for later use\n",
    "\n",
    "outfile = 'levels_df.pkl'\n",
    "levels_df.to_pickle(outfile)\n",
    "print(outfile, 'pickled.')\n",
    "\n",
    "outfile = 'levels_df.csv'\n",
    "levels_df.to_csv(outfile)\n",
    "print(outfile, 'written out.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MI_dict.pkl written out.\n"
     ]
    }
   ],
   "source": [
    "#Make and pickle an MI_dict\n",
    "import pickle\n",
    "\n",
    "MI_dict = dict(zip(str(bigram_df.bigram), bigram_df.MI))\n",
    "\n",
    "with open('MI_dict.pkl', 'wb') as handle:\n",
    "    pickle.dump(MI_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print('MI_dict.pkl written out.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Visualizations\n",
    "\n",
    "Visualizations based on this data can be found in a separate notebook:\n",
    "\n",
    "https://github.com/Data-Science-for-Linguists/Bigram-analysis-of-writing-from-the-ELI/tree/master/Visualizations.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
